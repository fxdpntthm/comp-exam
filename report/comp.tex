\newif\ifcomments\commentstrue

\RequirePackage[svgnames,dvipsnames,prologue,x11names]{xcolor}
\documentclass[screen,nonacm,manuscript,review]{acmart} % TODO make it 10pt

\usepackage{comp}

\title{Practical Functional Programming with \SFC and its Extensions}

\author{Apoorv Ingle}
   \orcid{0000-0002-7399-9762}
   \affiliation{%
  \institution{University of Iowa} \department{Department of Computer Science} \streetaddress{McLean Hall} \city{Iowa City} \state{Iowa} \country{USA}}
% \keywords{typeclass, type family}

%%% TODO:
%%% [ ]. Shorten Sentences
%%% [ ]. Fix Puntuations: commas and semicolons
%%% [ ]. How do the articles work?


\begin{document}
\begin{abstract}
  Programming languages are a primary interface between humans
  and computers. This makes it crucial to understand their principles of design
  and implementation. Programming languages need to encode unambiguous yet
  expressive instructions for computers. The
  features of a typed programming language strive to provide machine
  verified guarantees about the programs by following the  ``correct
  by construction'' philosophy. In this monograph, we study the practical
  (type system) and meta-theoretical (formalization) aspects of a
  modern, statically typed, declarative, and functional
  programming language. We focus on how one single construct,
  explicit type equality, gives a unified account of several seemingly
  unrelated language features. As a consequence, we obtain a typed
  intermediate language that is an easy to
  reason about and implement. We also
  study important extensions of this language and identify notable open
  research problems.
\end{abstract}

\maketitle
\section{Introduction}\label{sec:introduction}
Constructive mathematics and computer programming have an elegant
correspondence: they both involve solving a problem by
identifying and then exploiting the right level of abstraction.
The difference is in the direction.
Mathematicians work from top to bottom; they first build the abstractions
and then enrich them to represent real world
problems. Programmers turn the process on its head.
They first write a software program that solves a very specific
task and then build the right level of abstraction by means of
iterative code refactoring. This phenomenon is a well established
observation in computer science: Curry-Howard or the
Brouwer–Heyting–Kolmogorov correspondence~\cite{wadler_propositions_2015,han_deep_2023}
and it forms the basis for the field of type
theory~\cite{barendregt_lambda_2013,hottbook_2013,nordstrom_programming_1990}.

A programming language compiler, like any other software,
evolves by means of extensions. A new language feature
is implemented in two steps. First, the abstract syntax tree (AST)---the
data structure that encodes the surface syntax of the language---is
extended to represent the new feature. Second, the operations
performed on the AST are extended to cater for this new feature. These
operations transform the AST into an intermediate language internal to the
compiler~\cite{siek_compilation_2023}. The intermediate language is more suitable
representation of the surface level AST to perform code analysis and
runtime optimizations~\cite{aho_compilers_1986}.
If there is a way of encoding the new language feature by using
existing language features, the second step can be
skipped. However, not all language features can be encoded
into existing language features. In such cases, the compiler writer, needs
to enrich the intermediate language to support the
new language feature. Extensions to the intermediate language,
however, do not scale. Multiple extensions to the intermediate
language makes it difficult to maintain, and reason about its correctness.
The intermediate language requires a reformulation,
which amounts to finding the right
abstraction that can encode the different high level language features
into a simplified intermediate language.

In a compiler for statically typed programming languages, the
typechecker, is the gate keeper. Its purpose is to ensure that it does
not let \emph{bad} programs pass, and flag the appropriate offending
parts of programs to the programmer. This gate keeping is desirable;
it aids the programmer, by guaranteeing that a class of program
errors, such as runtime null pointer exceptions due to incorrect
function arguments, can never occur. They can then concentrate on the
other, more important aspects of the program, which cannot be verified
by the typechecker. On the other hand, the typechecker needs to allow
the \emph{good} programs---the ones that are definitely bug free---to
pass without the programmer's intense struggle. For
this reason, the type structure needs to be sufficiently rich
to express programmer's complex ideas and invariants.
The examples below illustrate the invariants
that the programmers may like to capture within the type structure:
\begin{enumerate}
\item In an AST where the compiler writer wants to enforce the
  sub-term to always be of a fixed typed. This avoids the need to
  explicitly check them in the code.
  More concretely, the AST representing the control structures, such
  as !if! or !while! loop, is well formed only when the sub-term
  representing the condition is of type !Boolean!.
\item In a multi-stage compiler, the AST is gradually enriched with
  more information after each analysis stage. The type structure can
  enforce that the information is accessed only after it is populated,
  or it raises a type error~\cite{peyton_jones_trees_2017}.
\end{enumerate}

The thesis of this monograph is: \emph{using explicit type
  equality, a novel construct, in the intermediate language is an
  appropriate abstraction to encode semantic invariants without
  compromising safety or efficiency.}
Type equalities denote explicit proofs in the system which assert when
two types can be considered synonymous. The monograph
is arranged in four parts:
\begin{enumerate}
\item[Part I] serves as a reminder of the essential features
  of a statically typed functional programming language. This gives
  the \emph{programmers' view} of the language motivated using real
  world examples.
\item[Part II] formalizes the syntax and operational semantics of
  \SFC which in essence is \SF extended with typed equality. This part
  gives the \emph{compiler writers' view} of the language. To this
  effect, we show how the language features described in Part I can be
  trivially encoded within \SFC.
\item[Part III] describes two important extensions of vanilla \SFC
  which make it even more expressive:
  (1) \SFR makes type equality finer grained while
  providing stronger type soundness guarantees and
  (2) \SFK squashes the distinction between
  types and kinds making the type (and kind) level computation even
  more expressive. Both of these extensions are formalized along with
  their correctness argument sketch.
\item[Part IV] describes notable open problems in the area.
  It is followed by important work adjacent to the principal topic
  of this monograph, and concluding remarks.
\end{enumerate}

\part{I: The Landscape}\label{part:I}%%%%%%%%%
\section{Program Behavior}
\subsection{Functions}
There can be no functional programming language without a support for first class
functions. Functions capture the essence of the program execution by encoding the logic of
transforming data. An example of a function declaration in Haskell is that of an identity
function, !idI! over integers and !idC! over characters shown below.

\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
idI :: Int -> Int
idI i = i
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
idC :: Char -> Char
idC i = i
\end{code}
\end{CenteredBox}
\end{minipage}

The type signature !idI :: Int -> Int! specifies the input-output behavior of the
function: !idI! accepts an argument of type !Int! and returns a value of
type !Int!. The definition !idI i = i! specifies how the function satisfies the
typing specification: it takes an argument !i!
and returns it unmodified. Functions declared in a
functional programming language resemble mathematical functions
in two ways: first, they are referentially transparent,
i.e. invoking a function with the same
arguments will always return the same result:
the expression, !idI 3!, will always evaluate to !3!.
Second, they are declarative, in a sense they abstract away the
implementation and execution details of how the function executes on the
actual underlying hardware; there is no mention of allocating
and freeing program memory or even an explicit return.

\subsection{Parametric Polymorphism}
Re-usablity of programs improves the programming experience. For example, an
identity function over !Char!, !idC! has the exact same
definition as !idI! over !Int!. The functions that work on base types,
such as !Int!, are called monomorphic functions.
To enhance re-usability of programs, it is necessary to
abstract over types.

\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
id :: t -> t
id a = a
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
($\circ$) :: (a -> b) -> (b -> c) -> (a -> c)
f $\circ$ g  = \ x -> f (g x)
\end{code}
\end{CenteredBox}
\end{minipage}

The function !id!, shown above, abstracts over all types by an implicit universal
quantification over the type variable !t!. Such functions are called
\emph{parametrically polymorphic} functions~\cite{strachey_fundamental_2000}.
The compiler can deduce which instance of the polymorphic function is required when
an argument of a concrete type is passed as an argument to a
polymorphic function. The language is said
to support functions as first class citizens when they can be
used as arguments to other functions, new functions can be declared
locally and also be able to compose without saturating them. For
example, in the function declaration, which composes any two suitable
functions, ($\circ$), illustrates all these three properties. The
arguments !f! and !g! are functions used as arguments, it declares an
local anonymous function which binds the parameter !x!, !\ x -> f (g x)!.
ML~\cite{milner_logic_1975,milner_theory_1978}
was the pioneer among the functional programming languages in
introducing a declarative style implicit parametric polymorphism.

\subsection{Adhoc Polymorphism}
Consider the following two terms, !addI! and !addF!:

\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
addI :: Int = 1 + 2
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
addF :: Float = 1.1 + 2.3
\end{code}
\end{CenteredBox}
\end{minipage}

In the definition of !addI!, the operator (!+!) is applied to two
integers, but in the definition of !addF!, the operator (!+!) is
applied to two floating point numbers (!Float!). Although the
programmer uses the same symbol, the meanings of the two terms are
distinct: !addI! adds two !Int!s and returns an !Int! while the !addF!
adds two !Float!s and returns a !Float!. The low level compiler generated code
for each of them would also differ as they would make a call to two
different built-in subroutines. This name punning technique, which is dependent on the
type of arguments, or the context of where the function appears, is called \emph{adhoc
polymorphism}~\cite{strachey_fundamental_2000}, while the functions
themselves are referred to as adhoc polymorphic functions. Implicit
operator overloading is a mechanism to support adhoc polymorphism.
The compiler resolves the overloaded operator (!+!) to
the actual operator (!int_plus! or !float_plus!) during the typechecking phase.

\begin{figure}[ht]
\centering
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
class Num a where
  (<=) :: a -> a -> Bool
  (==) :: a -> a -> Bool
  (+) :: a -> a -> a
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
instance Num Int where
  (<=) = int_le
  (==) = int_eq
  (+) = int_plus
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
instance Num Float where
  (<=) = float_le
  (==) = float_eq
  (+) = float_plus
\end{code}
\end{CenteredBox}
\end{minipage}
\caption{\lstinline{Num} typeclass and instances}
\Description[Num typeclass and instances]{Num typeclass and instances}
\label{fig:tc-num}
\end{figure}

To make implicit overloading usable in functional programming
languages, the type checker should be able to rule out terms such
!id + id!---summing 2 parametrically polymorphic functions is meaningless.
Functions like !(+)! act only on some specific class of constrained or qualified
types~\cite{jones_qualified_1994}:  The addition function
(!+!), more precisely, has the type !Num t => t -> t -> t!. This means that the
function can only be used on those types !t! which satisfy the !Num t!
constraint. This !Num t! constraint is declared by the programmer as a
typeclass. The instances of the typeclass specify when the typeclass
constraint holds, and what is the intended behavior at that type. For
example, the !Num! typeclass and its instances are shown in the
\pref{fig:tc-num}. The use of the function (!+!), say for
example in the definition of !addF!, the typechecker needs to justify
its type correctness. This amounts to satisfying the constraint !Num Float!.
which in turn can only be satisfied, if the typechecker can find a declaration of the
the instance declaration !Num Float!.

The idea of typeclasses originates from
~\citet{wadler_polymorphism_1989} which modeled typeclass instances as
dictonaries. The implicit class constraints---such as !Num t!---are
elaborated into special data called dictonaries~\cite{hall_type_1994} internally by the
compiler. Mathematically, typeclasses can be viewed as relations
over types~\cite{morris_simple_2014}. Every typeclass instance
declaration extends that relation. The typeclass !Num! represents a unary relation
for those types whose values behave like numbers, they can be compared
(!<=!, !==!) and added together (!+!). The declarations in the
\pref{fig:tc-num} can be interpreted as an evidence of fact that
!Float! and !Int! belong to the unary relation !Num!,
$\{$ !Int!, !Float! $\} \subseteq$ !Num!.


\section{Program Data}
\subsection{Algebraic Datatypes}
The other important aspect of any programming language, the first
being transformations of data described in the previous section, is
that of organizing related data in a logical fashion for the ease of
access and update. The data structures store the information by
encoding the domain elements via an appropriate representation in
memory. The transformation on these structures models the program
logic. Algebraic datatypes (ADT) are a primary way
to define such new structures in a functional programming language. They are called
algebraic because they can be viewed as composite datatype of (named)
sums of products. As an example, consider modeling a simple calculator
application which performs addition operation on integers. The domain,
in this case, are arithmetic expressions and can be represented using an
ADT in Haskell as:
\begin{figure}
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
data AlgExp where
   Value :: Int    -> AlgExp
   Plus  :: AlgExp -> AlgExp -> AlgExp
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: AlgExp -> Int
eval (Value i) = i
eval (Plus x y) = eval x + eval y
\end{code}
\end{CenteredBox}
\end{minipage}
    \caption{\texttt{AlgExp} and its evaluation}
    \Description{AlgExp and its evaluation}
    \label{fig:algexp-data}
\end{figure}

The !data! keyword defines a new user defined datatype with name
!AlgExp! as shown in \pref{fig:algexp-data}. The data constructor
!Value! stores !Int! values, while !Plus! encodes addition
of two !AlgExp! expressions. The function of the
calculator---to compute expressions---is simulated
by evaluating the encoded expression performed by an !eval!
function defined recursively.

The declarative style of programming allows us to write the !eval!
function on a case by case basis via pattern
matching. There are exactly two ways in which we could have obtained a
value of type !AlgExp!. The first case says
that if we have a !Value i!, we can deduce that
!i! is an !Int! and return it. In the second case, !Plus!, we first
evaluate the expressions !x! and !y! recursively, and then return the
addition of the two results. Another advantage of having a declarative
style is that extending the calculator application, say to include
operations such as multiplication and division operation, is
straightforward. The required code changes would be to add the
associated data constructors, !Mult! and !Div!, in the datatype
declaration followed by extending the !eval! function with cases for
!Mult!, which multiplies, and !Div! that divides.
In a typed setting the typechecker can identify and reject programs
with ill-structured data. The pattern expression !eval (Plus x)! is
ill-typed as !Plus! requires 2 arguments of type !AlgExp!.

The declarative style of defining algebraic datatypes
and pattern matching was introduced in
Hope~\cite{burstall_proving_1969, burstall_hope_1980} and has become an
essential feature of all modern typed functional programming languages.

\subsection{Newtypes}\label{subsubsec:gen-abs-types}
A special case of algebraic datatype is when there is only
one data constructor for the user defined datatype. This wrapping
of an existing type is to achieve data hiding.
Newtype provides the mechanism which confines the
visibility of the representation details of a type
exclusively within a module. External to the module type
representation is opaque to the client
module. Consider an !HTML! module as shown in the \pref{fig:html-generative-type}.

\begin{figure}[ht]
\centering
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
module HTML (Html, mkHtml, unMkHtml)
where

newtype Html = Html String

mkHtml :: String -> HTML
mkHtml = Html . escapeString

unMkHtml :: HTML -> String
unMkHtml (Html s) = s
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
module Client
where

import HTML

page :: HTML
page = mkHTML "<html><body>Text</body></html>"





\end{code}
\end{CenteredBox}
\end{minipage}
\caption{HTML as a generative type}
\Description{HTML as a generative type}
\label{fig:html-generative-type}
\end{figure}

Within the scope of !Html! module, the types !String! and !HTML! are
synonymous, however the type !Html! will be opaque for any
external client using the type !HTML!. The !Client! module will not be
able to directly manipulate a value of type !Html!---unless
of course by using the specific functions exposed in the
signature. Inhibiting manipulations and views of the data
representation is useful to avoid leaking information in
secure computation contexts. A naive abstraction, however,
will incur a runtime cost. !Html! and !String!, need to be explicitly
converted from one form into another using pattern matching.
This explicit conversion is redundant as they have the same
representation in memory, but the compiler cannot use this
information to perform any optimization on the generated code.
Is it possible for the runtime semantics of the code be liberated from
the extra overhead?

The idea of newtypes can be traced back to
generative abstract types, which first appeared in work of
~\citet{leroy_applicative_1995} and ~\citet{milner_definition_1997}
in the context of ML module systems. Generative abstract types in the
context of Haskell are similar to ~\cite{montagu_modeling_2009}. The idea of
abstract types is even older due to \citet{TODO}

\subsection{Generalized Algebraic Datatypes}
Consider extending the previously defined !AlgExp! from~\pref{fig:algexp-data} to also
include a data constructor !IsZero!. The intention of the constructor is to encode the
check if the expression of type !AlgExp! is evaluated to zero.

\begin{figure}[ht]
\centering
\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
data AlgExp where
  Value  :: Int              -> AlgExp
  Plus   :: AlgExp -> AlgExp -> AlgExp
  IsZero :: AlgExp           -> AlgExp
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: AlgExp -> Int
eval (Value i) = i
eval (Plus x y) = (eval x) + (eval y)
eval (IsZero x) = (eval x) == 0 -- type error!
\end{code}
\end{CenteredBox}
\end{minipage}
\caption{Extending the \texttt{AlgExp} datatype and \texttt{eval} function}
\Description[AlgExp]{AlgExp is inexpressive}
\label{fig:algexp-eval}
\end{figure}

How should the !eval! function handle the !IsZero! case? The naive
definition, !(eval x) == 0! as shown in \pref{fig:algexp-eval},
fails to type check as the !eval! function requires the return
type of the expression to be an !Int! but
it is of type !Bool!. A possible solution is to change the return type
of the the !eval! function to be !Either Int Bool!. This would mean
that the evaluator either returns an !Int! or a !Bool!. While this works as
expected, it requires a complete rewrite of the !eval! function. The
situation of maintaining this !eval! function becomes even more
cumbersome if later we wanted to add a new facility, say, to store and use user
defined functions. Extending !AlgExp! with new constructs would mean
nesting of !Either! datatype and then checking at each recursive
call the value returned is the one that we expect as shown below:

\begin{minipage}{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
data Either a b where
    Left  :: a  -> Either a b
    Right :: b  -> Either a b

\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}{0.6\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: AlgExp -> Either Bool Int
eval (Value i) = Right i
eval (Plus x y) =
  case (eval x, eval y) of
    (Right x', Right y') -> Right (x' + y')
    _                    -> error "should not happen"
eval (IsZero x) = case (eval x) of
                    Left i -> Left (i == 0)
                    _      -> error "should not happen"
\end{code}
\end{CenteredBox}
\end{minipage}

To reflect on the situation: the programmer
expects the !eval! function to compositionally evaluate an
expression, then why should they be bothered to wrap the
evaluated values of the !AlgExp! into an !Either! datatype?
There needs to be an appropriate abstraction to handle
this wrapping and unwrapping automatically.
It is important to note that, in full generality,
the evaluation of the expression may not result in the same type.
In our case, the !IsZero! evaluates
an expression to a Boolean value, while the !Plus! operator evaluates
to an Integer. Thus, the type signature of the !eval! function should
abstract over the expression result type:
!eval :: FORALL a. AlgExp a -> a!. The problem
would resolve if we were to constrain the return type of each of the
data constructors to agree to the type of the value expected after
evaluating the value of type !AlgExp!. This constrained return type
can be used as a tag to convince the typechecker that !eval! function
is indeed type safe. This formulation is shown in
\pref{fig:galgexp-eval} with the datatype !GAlgExp! along with the !eval!
function which evaluates it.

\begin{figure}[ht]
\centering
\begin{minipage}[ht]{0.6\linewidth}
\begin{CenteredBox}
\begin{code}
data GAlgExp a where
  Value  :: Int                        -> GAlgExp Int
  Plus   :: GAlgExp Int -> GAlgExp Int -> GAlgExp Int
  IsZero :: GAlgExp Int                -> GAlgExp Bool
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.4\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: GAlgExp a -> a
eval (Value i) = i                    --(1)
eval (Plus x y) = (eval x) + (eval y) --(2)
eval (IsZero x) = (eval x) == 0       --(3)
                   -- typechecks okay!
\end{code}
\end{CenteredBox}
\end{minipage}%
\caption{\texttt{GAlgExp} datatype and \texttt{eval} function}
\Description[GAlgExp]{GAlgExp datatype and \eval function}
\label{fig:galgexp-eval}
\end{figure}

In each of the case alternative branches, the type of the right hand side of a
pattern match agrees with the type constraint introduced by the
pattern. For example, in the alternative case branch labeled (2)
in the \pref{fig:galgexp-eval}, the
pattern !Plus x y! is of type !GAlgExp Int! and the type of the
resultant on the right hand side of the equation is of type !Int!.
Similarly, in the alternative branch labeled (3) with the pattern
!IsZero x! is of type !AlgExp Bool! is on the left hand of the
equation, has a right hand side of the equation
of type !Bool!, which agrees with the type of its right hand side.

GADTs can further help in identifying dead code and code
optimizations~\cite{xi_dead_1998,graf_lower_2020,nilsson_dynamic_2005}.
For example, consider the function !isZero! shown below:

\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
isZero :: AlgExp -> Bool
isZero (Value i) = i == 0
isZero (Plus x y) = isZero x && isZero y
isZero (IsZero x) = error "impossible"
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
isZero :: GAlgExp Int -> Bool
isZero (Value i) = i == 0
isZero (Plus x y) = isZero x && isZero y
\end{code}
\end{CenteredBox}
\end{minipage}

The typechecker has the necessary information to identify that the case
!IsZero x! is impossible as it is of type !GAlgExp Bool! while the
function only expects an argument of type !GAlgExp Int!. If we were to
define the same function for !AlgExp!, the function
would have to include an impossible case for !IsZero x!.

\begin{minipage}[ht]{0.6\linewidth}
\begin{CenteredBox}
\begin{code}
data GAlgExp a where
  ...
  Equals :: GAlgExp a -> GAlgExp a -> GAlgExp Bool
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.4\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: GAlgExp a -> a
...
eval (Equals x y) = (eval x) == (eval y)
                           -- Type error!
\end{code}
\end{CenteredBox}
\end{minipage}

Consider a generalization of !IsZero x! namely, !Equals x y! as shown
in the above code block. The intention of !Equals x y! to
represent comparing the arguments !x! and !y! and decide if they are
equal. The !eval! function case that evaluates !Equals x y! fails
to type check. The problem is not that the return type does not match,
it is indeed !Bool!, but there is no reason to believe that
!eval x! and !eval y! can be compared using the !(==)! operator. The
only information we can infer from the pattern match is that
the type of !eval x! and !eval y! are of some generic type variable
!a!. Such types are called existential as they do not appear in
the return type. The arugments to !Equal! need to be only those that can be compared.
By constraining the type variable to only those which satisfy
the !Eq! typeclass, we can convince the typechecker that the
term !(eval x) == (eval y)! is well typed.


\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
data GAlgExp a where
...
   Equals :: Eq a => GAlgExp a -> GAlgExp a
                  -> GAlgExp Bool
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.4\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: GAlgExp a -> a
...
eval (Equals x y) = (eval x) == (eval y)
                              -- Okay!
\end{code}
\end{CenteredBox}
\end{minipage}

To summarize GADTs generalize the notion of algebraic datatypes in two
distinct ways by uniformly supporting:
\begin{enumerate}
\item phantom or tagged types, where the return type of the data
  constructor is no longer a generic type variable and it is refined
  to be a fixed type;
\item existential types, where it is possible for the type variables
  that appear in the types of the arguments to the data
  constructors to not appear in the return type.
\end{enumerate}

While there is a rich literature of GADTs (inductive type families)
for dependently typed languages~\cite{dybjer_inductive_1991,
  dybjer_inductive_1994}, the idea of GADTs for non-dependently typed
languages appeared under different names such as indexed
types~\cite{zenger_indexed_1997}, first class phantom
types~\cite{cheney_first-class_2003}, guarded recursive
datatypes~\cite{xi_guarded_2003}, equality qualified
types~\cite{sheard_meta-programming_2008}. GHC/Haskell was the only
language compiler that supported GADTs~\cite{peyton_jones_wobbly_2004}
until recently OCaml 4.0~\cite{garrigue_gadt_2011} and
Scala 3~\cite{xu_implementing_2021} started supporting them.

\section{Type Computation}\label{sec:type-computation}
\subsection{Multiparameter Typeclasses}\label{sec:multiparam-typeclasses}
While single parameter typeclasses model unary
relations over types, multiparameter typeclasses generalize single
parameter typeclasses by modeling n-ary relations
over types. For example, ~\citet{jones_tcfd_2000} uses the
typeclass !Con e c! to unify the treatment of
different containers and their contained elements as shown in
the \pref{fig:tc-collection}. The type variable !e! stands in for the
element type of the container while !c! stands in for the container
type. The behavior of the containers is captured by the typeclass methods:
!empty!, which returns the empty container, and !insert!,
which inserts the element of type !e! in to the container of type !c!.
We can imagine having instances for such a typeclass as
!Con Int [Int]! that says that the container list of integers has
integers as its elements, !Con Word (Tree Chars)! that says that a
container tree of !Char! contains !Word!s as its
elements. Viewing them as relations,
we have $\{$ !(Int, [Int])!, !(Int, Tree Int)! $\}$ $\in$ !Con!.

\begin{figure}[ht]
\centering
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
class Con e c
where
  empty :: c
  insert :: e -> c -> c
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
instance Con Int [Int]
where
  empty = ...
  insert = ...
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
instance Con Word (Tree Char)
where
  empty = ...
  insert = ...
\end{code}
\end{CenteredBox}
\end{minipage}
\caption[\lstinline{Con} typeclass]{\lstinline{Con} typeclass and its instances}
\Description[Con Typeclass]{Con Typeclass and instances}
\label{fig:tc-collection}
\end{figure}

The use of !empty! in a polymorphic setting, however, leads to ambiguity during
compilation. The type of empty is inferred as !empty! as !Con e c => c!.  This type
in ambiguous as a free type variable !e! which appears only in the constraint.
Ambiguous types do not have well defined semantics as the compiler cannot
resolve the typeclass constraint to a unique instance and hence cannot
choose the right implementation to use. Further,
if the intention of the programmer is to allow only homogeneous containers,
multiparameter typeclasses are insufficient. Consider the term !con3a!
which claims to insert both an !Int! value and a !Char! value into
the argument !con!.

\begin{CenteredBox}
\begin{code}
con3a con = insert 3 (insert 'a' con)
\end{code}
\end{CenteredBox}

The typechecker infers the type of !con3a! as
!(Con Int c, Con Char c) => c -> c!. However, a use of this term
to a container which contains only !Int! or !Char! will raise a type error.
If the intention of the programmer was to allow only homogeneous containers,
it would be helpful for the definition of the term !con3a! to be rejected,
rather than a type error to appear at its use site.

\subsection{Functional Dependencies}
The problem with multiparameter typeclasses is that there is a
mismatch between the programmers intention and the expressivity of the
typeclass machinery. Continuing with the above example, the
programmers intention might be to have a functional relation between !c! and
!e! of the typeclass !Con e c!: fixing the type
parameter !c! also fixes the the type parameter !e!. In general,
there can be arbitrary functional relation between the type parameters
of the typeclass.
\begin{figure}[ht]
\begin{CenteredBox}
\begin{code}
class Con e c | c ~> e where
  empty :: c
  insert :: e -> c -> c
\end{code}
\end{CenteredBox}
\caption[\lstinline{Con} typeclass]{The \lstinline{Con} Typeclass with Functional Dependency}
\Description[Con typeclass]{The Con Typeclass with Functional Dependency}
\label{fig:tc-collection-fd}
\end{figure}
As seen in the \pref{fig:tc-collection-fd}, the new annotation !c ~> e!
on the typeclass definition captures the functional dependency of the typeclass
!Con e c!. It is read as: \emph{for a given type parameter} !c!,
\emph{the type parameter} !e! \emph{can be uniquely
determined}. The parameter !c! is called the determiner, while
the parameter !e! is called the determinant of the
functional dependency. This extension is attractive
as there is a minimal change to the typeclass syntax, and it is
backwards compatible with no change to typeclass instance declarations.
The typechecker needs to verify that the new instance declarations do
not violate the functional dependency: we cannot allow both the typeclass instances,
!Con Int [Int]! and !Con Float [Int]! to exist together.

~\citet{jones_tcfd_2000} introduced functional dependencies as a
conservative extension to the typeclass language feature. His
inspiration stems from relational algebra. Later,
~\citet{jones_language_2008} raise questions about language designs in
presence of functional dependencies, answer some of them while also
clarifying the misunderstandings which had seeped deep into the
functional programming community.

\subsection{Associated Types}
Another way of introducing a functional relation on types, or simply
type functions, is via associating the determinant of the
functional dependency within the class definition.
Using the previous !Con c e! example, if we have a functional
dependency !c ~> e! then, a type function, !Elem c!, can be used where ever
the type parameter !e! appears.

\begin{figure}[ht]
\begin{center}
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
class Con c where
  type Elem c
  empty :: c
  insert :: Elem c -> c -> c
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
instance Con [Int] where
  type Elem [Int] = Int
  empty = ...
  insert = ...
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.3\linewidth}
\begin{CenteredBox}
\begin{code}
instance Con (Tree Char) where
  type Elem (Tree Char) = Word
  empty = ...
  insert = ...
\end{code}
\end{CenteredBox}
\end{minipage}
\end{center}
\caption[Con typeclass]{\lstinline{Con} Typeclass with an Associated Type}
\Description[Con typeclass]{Con Typeclass with an Associated Type}
\label{fig:assoc-types}
\end{figure}

In the \pref{fig:assoc-types}, the typeclass !Con! needs only one
parameter, !c!, for the container type, with an additional field for
the type function !Elem! that depends on the type parameter !c! of the
typeclass. As a cascading effect, the type signature of !insert!,
now only depends on the type parameter !c!,
and the !Elem c! stands for the element
type of container. In the instance declaration, the !Elem [Int]! is mapped to
!Int!, meaning, the element of the list of integers is of type !Int!.
To circumvent the problem of ambiguous types,
the multiparameter typeclass can be
rewritten by replacing all the determinants of the functional
dependency by the associated type applied to the determiners.

Associated types were introduced by ~\citet{chakravarty_associated_2005}
as an alternative for functional dependencies because of a more
direct syntax: functional programmers are accustomed to writing
functions and not relations as in logic programming.

\part{II: \SFC}\label{part:II}
\section{History and Motivation}
Haskell~\cite{haskell_2010} is statically typed.
This has practical and theoretical implications.
In practice, only those terms whose types can be verified by the
typechecker can be compiled to the core intermediate language, and in theory,
terms without types have no meanings.
The Glasgow Haskell Compiler (GHC)~\cite{ghc_2020}, is the de facto
Haskell language compiler. The former iterations of GHC,
used \SF~\cite{girard_proofs_1989, reynolds_towards_1974} with extensions,
as its core intermediate language. In the
rest of this section, we will briefly see how \SF, with extensions
encoded the language features but was insufficient for encoding newtypes.

GHC is based on Hindley-Milner type system~\cite{milner_theory_1978}.
It can be viewed as a restricted version of \SF where all the types
are in prenex form: the type variables
are universally quantified at the outermost level and there are no
explicitly existentially quantified types.
The advantage of this system is that the term language
is expressive enough to allow programmers write non-trivial programs
while not burdening them with annotating every term with an explicit
type. There is a decidable and complete algorithm
which computes a most general unique type for a term.

The basic language features can be encoded in \SF~\cite{burstall_hope_1980}.
The encoding amounts to making the implicit type in the surface level language
explicit in function definitions and function applications.
For example, the polymorphic function definition !id! is elaborated to:

\begin{CenteredBox}
\begin{code}
id :: FORALL t. t -> t
id A x = x
\end{code}
\end{CenteredBox}

The term !id 3! written by the programmer is elaborated to !id Int 3!.
Typeclasses or implicit adhoc polymorphism, is encoded via means of
special terms called dictionaries~\cite{wadler_polymorphism_1989, hall_type_1994}.
The typeclass instances are dictionaries which contain a reference
to actual the method implementations.
Elaboration of implicit adhoc polymorphism amounts to finding
the right dictionary to be applied to the function as an explicit
argument in the elaborated version of the function application.

The data constructors introduced by user defined datatypes are treated as
term constants. Consider a pathological datatype declaration as shown
below:

\begin{CenteredBox}
\begin{code}
  data T a where MkT :: a -> T a
\end{code}
\end{CenteredBox}

The data constructor !MkT! is of type !FORALL a. a -> T a! in the
core language. The programmer written term !MkT 42! for the type
!T Int! is elaborated to !MkT Int 42!.

\SFC~\cite{sulzmann_system_2007} was designed as an
alternative to having separate extensions for
each language feature. The key insight is that each language feature
is, in a sense, trying to encode some notion of type equality
($\tau\sim\sigma$). GADTs introduce type refinements, as seen in
!eval! example, are type equality constraints exposed after a pattern
is matched. Instances of associated types introduce a type equality
between the instantiated associated type and the concrete type
(!Elem [Int] ~ Int!). The newtype introduces
type equalities between the new defined type and its representation
(!Html ~ String!). Consider a the following declaration:

\begin{CenteredBox}
\begin{code}
newtype Fun = MkFun (Fun -> Fun)
\end{code}
\end{CenteredBox}

This newtype definition could not be encoded in the intermediate
\SF without using adhoc machinery. However, in \SFC this is achieved
by introducing a type equality axiom: !Fun ~ Fun -> Fun!

In the following sections we describe the meta-theory
of the core intermediate language followed by details
of how each of the language features
GADTs (in the \pref{sec:fc-encodes-gadts}), newtypes
 (\pref{sec:fc-encodes-newtypes}), and associated
types (\pref{sec:fc-encodes-assoctypes}), and also a unique feature of
the system, open type functions (\pref{sec:fc-encodes-opentypefun}) are
encoded in \SFC using \emph{coercions} and \emph{coercion
  axioms} which embody the notion of type equality.

\section{Syntax}\label{sec:sfc-syntax}
\begin{figure}[ht]
 \centering
 \begin{syntax}
 \text{Type Variables} &\TyVar,\beta,\Co &\qquad\text{Type Constants} &T \\
 \text{Term Variables} &x,y &\qquad\text{Type Functions} &F\\
 \text{Coercion Vars} &c &\qquad\text{Indices} &i,n \in \mathbb{N}
 \end{syntax}
 \begin{syntax}
 \text{Kinds} &&\kappa \bnfeq& \star \bnfor \kappa \to \kappa \bnfor \shl{\sigma \sim \tau}\\
 \text{Types} &&\tau,\sigma \bnfeq& \TyVar \bnfor T \bnfor \tau \to \tau \bnfor \tau\App\tau \bnfor \Forall {\TyVar\co\kappa} \tau \bnfor \shl{F_n\App\many\tau} \bnfor \shl{\Co}\\
 \shl{\text{Coercions}} &&\nu,\Co \bnfeq& c \bnfor \Refl\tau \bnfor \Sym\Co \bnfor \Trans\nu\Co % equiv relation
 \bnfor \Forall {\TyVar\co\kappa} \Co \bnfor \Co\At\tau % abstraction instantiation
 \bnfor \nu\App\Co \bnfor \Left \Co \bnfor \Right \Co\\  % compose/decompose
 \text{Types/Coercions} && \phi \bnfeq& \tau \bnfor \Co\\
 \text{Patterns} &&P \bnfeq& H\App \many{\beta\co\kappa}\App{\many{x\co\tau}} \\
 \text{Terms} &&M,N \bnfeq& x \bnfor \Lam {x\co\tau} M \bnfor M\App N \bnfor \TLam{\phi\co\kappa} M \bnfor M\App \tau \bnfor H \bnfor \Case M \many{P \to M} \bnfor \shl{\Cast \Tm \Co}\\

 \end{syntax}
 \begin{syntax}
 \text{Typing Context} &&\TEnv,\Delta \bnfeq& \empt \bnfor \TEnv,x\co\tau \bnfor \TEnv,H\co\tau \bnfor \TEnv,F_n\App\many\tau\co\kappa \bnfor \TEnv,\TyVar\co\kappa  \bnfor \TEnv, c \co \tau\sim\sigma\\
 \text{Substitutions} &&\Subst \bnfeq& \empt \bnfor \Set{\many{\TyVar \mapsto \tau}}
 \end{syntax}

 \begin{syntax}
 \text{Program} &&P_{gm} \bnfeq& \many{D_{cl}} \mathrel{;} \many{x = \Tm}\\
 \text{Data Declarations} &&D_{cl} \bnfeq& \textbf{\texttt{data }}\App T\co\many{\kappa} \to \star\App \textbf{\texttt{ where }}\App \many{C_{trs}(T)} \\
 && \bnfor& \textbf{\texttt{type }}\App F : \many\kappa \to \kappa\\
 && \bnfor& \textbf{\texttt{axiom }}\App c\App \many{\TyVar\co\kappa} : \sigma_1 \sim \sigma_2\\
 \text{Data Constructors} &&C_{trs}(T) \bnfeq& H : \Forall {\many{\TyVar\co\kappa}} {\Forall {\many{\beta\co\kappa'}} \many\sigma \to T\many\TyVar}\\
 \end{syntax}

 \caption{The Syntax of \SFC}
 \Description{The Syntax of \SFC}
 \label{fig:sfc-syntax}
\end{figure}

The complete syntax of \SFC is shown in \pref{fig:sfc-syntax}. The
system is classified into three sub-languages or levels: (1) kinds,
(2) types, and (3) terms. The kind language sits at the highest
abstraction level. It consists of base kind ($\STAR$), higher kinds
($\kappa \to \kappa$), and the novel construct for expressing type
equality ($\shl{\tau \sim \sigma}$).
Kinds classify types. The type language contains
type variables ($\alpha$), type constructors $T$,
function type $\tau\to\sigma$,
and polytypes ($\Forall \alpha \tau)$ which support polymorphic functions.
The type constant ranges over builtin types such as !Int!
and user defined types.
The system allows defining higher kinded types and
inductive algebraic datatypes such as !List!s and !Tree!s.

The type equality coercion, $\shl{\Co}$, is the novel type level construct.
It is classified by kind level type equality predicate,
$\shl{\tau\sim\sigma}$. Coercions are first class at the level of types:
they can be constructed, applied to and passed in as arguments, and also
abstracted over by using the special coercion infrastructure.
\SFC supports a coercion calculus where
each syntactic construct corresponds to a logical equation between two
types. In practice coercions are types, and $\phi$ ranges over both
types and coercions. The type function constants $F_n$ need to appear fully
saturated in types to be well formed, $F_n\App\many\tau$.
The subscript $n$ specifies the arity of the type function,
but it is elided when the context makes it clear.
Coercions can also be introduced as equality axioms which can be
thought as a templatized type equation.
For example, an axiom $\Forall \alpha {F\App a \sim a}$
says that for all types, !F a! can be treated exactly as !a!, and vice
versa. We distinguish user defined datatypes $T$
from type function constructors $F$. We use a special syntax $\tau_1 \sim \tau_2 \then \sigma$
to abreviate $\Forall {\_ \co \tau_1 \sim \tau_2} \sigma$, meaning the coercion
variable does not occur in the type $\sigma$.


Finally, types classify the terms of the system.
The novel term construct of the system is $\shl{\Cast \Tm \Co}$.
It denotes that if a term $M$ is of type $\tau$
and we have a coercion, $\Co$, which says that $\tau\sim\sigma$
then, the term, $\Cast M \Co$, justifies treating $M$ as if it has type
$\sigma$. Alternatively, the type equality coercion can be thought of
as: if $\Co$ justifies $\tau \sim \sigma$ and $\Tm$ is of type $\tau$
then, within a context that expects a term of type $\sigma$,
the term $\Cast M \Co$ can be freely used,
without worrying that the term will get stuck or crash during runtime.
The ``will not crash'' guarantee is called as the \emph{type
  soundness property} of the system. The type coercions introduced
in the system should be thought of as axiomatic type equality,
similar to axiomatic functional extensionality.
However, the type soundness argument of the system, as we
will see later, does not rely on any specific
semantic notion of type equality.

The system has the usual term constructs: variables `$x$',
abstractions `$\Lam {x\co\tau} \Tm$' and applications `$M \App N$',
type level abstraction `$\TLam \TyVar \Tm$' and type applications
`$\Tm\App\sigma$'. Declaration of algebraic datatypes introduces data
constructors $H$, the types of which are of the form:
\[
H \co \Forall {\many{\TyVar\co\kappa}} {\Forall {\many{\beta\co\kappa}} \many{\sigma} \to T\App\many\TyVar}
\]
Here, the type variables, $\many\TyVar$, appear in the same order as in
the algebraic datatype declarations, $T\App\many\TyVar$.
The type variables $\many\beta$ are special; they
do not appear in the return type, $\many\TyVar \cap \many\beta = \emptyset$.
This characterization of splitting the type variables into $\many\alpha$
and $\many\beta$ plays a crucial role in representing GADTs and
existential types.
The $\Case M {\overline{P \to N}}$
discriminates on the shape of the term $M$ and chooses one of the
alternatives $N$ after a successful match on the one of the patterns
$P$.

\subsection{Static Semantics}\label{sec:sfc-static-sem}

\newcommand\KReflCo{
 \ib{\irule[\trule{co-refl}]
 {\TyKinding \TEnv \tau \kappa};
 {\CoKinding \TEnv {\Refl \tau} {\tau \sim \tau}}
 }
}

\newcommand\KSymCo{
 \ib{\irule[\trule{co-sym}]
 {\CoKinding \TEnv \Co {\tau \sim \sigma}};
 {\CoKinding \TEnv {\Sym \Co} {\sigma \sim \tau}}
 }
}

\newcommand\KTransCo{
 \ib{\irule[\trule{co-trans}]
 {\CoKinding\TEnv {\Co_1} {\tau \sim \tau_2}}
 {\CoKinding\TEnv {\Co_2} {\tau_2 \sim \sigma}};
 {\CoKinding\TEnv {\Trans {\Co_1} \Co_2} {\tau \sim \sigma}}
 }
}

\newcommand\KInstCo{
 \ib{\irule[\trule{co-$\E\forall$}]
 {\CoKinding\TEnv \Co {\Forall\TyVar\tau_1 \sim \Forall\beta\tau_2}}
 {\Subst_1 = \Sub\TyVar\sigma}{\Subst_2 = \Sub\beta\sigma};
 {\CoKinding\TEnv {\Co\At\sigma} {\Subst_1\tau_1 \sim \Subst_2\tau_2}}
 }
}

\newcommand\KForallCo{
 \ib{\irule[\trule{co-$\I\forall$}]
 {\CoKinding {\TEnv,\TyVar\co\kappa} \Co {\tau_1 \sim \tau_2}}{\fresh\alpha\TEnv};
 {\CoKinding \TEnv {\Forall {\TyVar\co\kappa} \Co} {\Forall {\TyVar\co\kappa}\tau_1 \sim \Forall {\TyVar\co\kappa}\tau_2}}
 }
}

\newcommand\KCoComp{
 \ib{\irule[\trule{co-comp}]
 {\CoKinding \TEnv {\Co_1} {\tau_1 \sim \tau_2}}
 {\CoKinding \TEnv {\Co_2} {\sigma_1 \sim \sigma_2}}
 {\TyKinding \TEnv {\tau_i\App \sigma_i} \kappa};
 {\CoKinding \TEnv {\Co_1\App \Co_2} {\tau_1\App \sigma_1 \sim \tau_2\App \sigma_2}}
 }
}

\newcommand\KCoFComp{
 \ib{\irule[\trule{co-F-comp}]
 {\many{\CoKinding \TEnv \Co {\sigma \sim \tau}}^n}
 {\TyKinding \TEnv {F\App \many\sigma^n} \kappa};
 {\CoKinding \TEnv {F \App \many\Co^n} {F\App\many\sigma^n \sim F\App\many\tau^n}}
 }
}

\newcommand\KLeftCo{
 \ib{\irule[\trule{co-left}]
 {\CoKinding \TEnv {\Co} {\tau_1 \App \sigma_1 \sim \tau_2 \App \sigma_2}};
 {\CoKinding \TEnv {\Left \Co} {\tau_1 \sim \tau_2}}
 }
}

\newcommand\KRightCo{
 \ib{\irule[\trule{co-right}]
 {\CoKinding \TEnv {\Co} {\tau_1 \App \sigma_1 \sim \tau_2 \App \sigma_2}};
 {\CoKinding \TEnv {\Right \Co} {\sigma_1 \sim \sigma_2}}
 }
}

\newcommand\KCastCo{
 \ib{\irule[\trule{co-leftc}]
 {\CoKinding \TEnv \Co {\kappa_1 \then \tau_1 \sim \kappa_2 \then \tau_2}};
 {\CoKinding \TEnv {\Cast {\Co_1} \Co_2} {\tau_1 \sim \tau_2}}
 }
}

\newcommand\KCoAx{
 \ib{\irule[\trule{co-ax}]
 {\CoKinding \TEnv \Co {\kappa_1 \then \tau_1 \sim \kappa_2 \then \tau_2}};
 {\CoKinding \TEnv {\Cast {\Co_1} \Co_2} {\tau_1 \sim \tau_2}}
 }
}

\newcommand{\KTyVar}{
 \ib{\irule[\trule{ty-var}]
 {\TyVar\co\kappa \in \TEnv};
 {\TyKinding \TEnv \TyVar \kappa}
 }
}
\newcommand{\KTyApp}{
 \ib{\irule[\trule{ty-app}]
 {\TyKinding \TEnv \sigma {\kappa' \to \kappa}}
 {\TyKinding \TEnv \tau \kappa'};
 {\TyKinding \TEnv {\sigma\App\tau} \kappa}
 }
}
\newcommand{\KFCon}{
 \ib{\irule[\trule{ty-fcon}]
 {F_n \co \many \kappa^n \to \kappa' \in \TEnv}
 {\many {\TyKinding \TEnv {\sigma} {\kappa}}^n};
 {\TyKinding \TEnv {F_n \many\sigma^n} {\kappa'}}
 }
}
\newcommand{\KTyCon}{
 \ib{\irule[\trule{ty-con}]
 {T \co \kappa \in \TEnv};
 {\TyKinding \TEnv {T} {\kappa}}
 }
}
\newcommand{\KTyAll}{
 \ib{\irule[\trule{ty-all}]
 {\TyKinding {\TEnv,\TyVar\co\kappa} {\sigma} \star}
 {\TyVar\not\in \dom\TEnv};
 {\TyKinding \TEnv {\Forall {\TyVar\co\kappa} \sigma} \star}
 }
}
\newcommand{\KCoConst}{
 \ib{\irule[\trule{co-var}]
 {c\co{\tau \sim\sigma}\in\TEnv};
 {\CoKinding \TEnv c {\tau \sim\sigma}}
 }
}

\begin{figure}[ht]
 \begin{gather*}
 \fbox{$\CoKinding \TEnv \Co \kappa$}\\
 \KReflCo \rsp \KSymCo \rsp \KTransCo \\
 \KForallCo \rsp \KInstCo \\
 \KCoComp \rsp \KCoFComp\\
 \KLeftCo \rsp \KRightCo \\
 \KCoConst
 \end{gather*}
 \caption{Coercion Kinding Judgements: Excerpt of Static Semantics of \SFC}
 \Description{Coercion Kinding Judgements: Excerpt of Static Semantics of \SFC}
 \label{fig:sfc-typing-co}
\end{figure}

The judgements in \pref{fig:sfc-typing-co} formalize the intuitions of how coercions ought to behave.
Coercions are types such that their
kinds say which what types considered equal.
The coercion kinding judgment \fbox{$\CoKinding \TEnv \Co \kappa$}
is read as, ``under the assumptions in
$\TEnv$, the coercion $\Co$ is (provably) of kind $\kappa$''.
The kinding rules \trule{co-refl}, \trule{co-sym} and \trule{co-trans}
makes type equality an equivalence relation.
The reflexivity construct `$\Refl\tau$' says that the type $\tau$
is equal to itself. The construct `$\Sym\Co$' flips
the direction of equality while transitivity `$\Trans {\Co_1}{\Co_2}$'
chains two coercions $\Co_1$ and $\Co_2$.

The rules \trule{co-$\E\forall$} and
\trule{co-$\I\forall$} justifies coercions between polytypes and their
instantiations. If two polytypes are equal, then their instantiations
with equal types are also equal by the rule \trule{co-$\E\forall$}.
The substitutions $\Subst_1$ and $\Subst_2$ maps the free type variables
$\alpha$ and $\beta$ to type $\sigma$.
If two types, with a free type variable, are equal then type
abstraction on both the types yields equal polytypes by the rule
\trule{co-$\I\forall$}. A necessary condition to avoid variable capture
is that $\fresh\alpha\TEnv$ meaning, the variable $\alpha$
is fresh in the the environment.
The rule \trule{co-comp} enables combining
coercions for higher kinded types and enable reasoning of equalities
between them and similarly the rule \trule{co-F-comp} enables coercion
lifting for fully saturated type functions.

% Coercions can also be composed and decomposed using the
%`$\nu\App\Co$', and `$\Left\Co$' and `$\Right\Co$' constructs
%respectively. Only the saturated application of $F$ can appear on the left hand
%side of a coercion axiom head.

\begin{figure}[ht]
\begin{gather*}
 \fbox{$\TyKinding \TEnv \tau \kappa$}\\
 \KTyVar \rsp \KTyApp \\
 \KTyCon \rsp \KFCon \rsp \KTyAll
\end{gather*}
 \caption{Kinding Judgments: Excerpt of Static Semantics of \SFC}
 \Description{Kinding Judgments: Excerpt of Static Semantics of \SFC}
 \label{fig:sfc-typing-ki}
\end{figure}

The kinding rules for types, \fbox{$\TyKinding \TEnv \tau \kappa$},
which are not coercions, are listed in \pref{fig:sfc-typing-ki}.
They are fairly standard in comparison to \SF.
The kinding judgment rules $\trule{ty-fcon}$
and $\trule{ty-con}$ are distinct as only fully saturated type
function constructors are valid types in the system. The impredicative
nature of \SFC is evident from the rule $\trule{ty-all}$: type
quantification is a closed operation over types in the universe of kinds.
Polytypes---the types with explicit type abstraction---and
monotypes---the types with no explicit type abstraction---
both are of kind $\STAR$.

To illustrate usefulness of coercion composition, consider a higher
kinded algebraic type !Tree! and a coercion
$\Co\co\sigma_1\sim\sigma_2$, then using $\tau_1$ and $\tau_2$ to be
equal to !Tree!, we have that $\Refl{\texttt{Tree}} \App\Co :
\texttt{Tree}\App\sigma_1 \sim \texttt{Tree}\App\sigma_2$. On the
other hand, if we have a coercion $\texttt{Tree}\App\sigma_1 \sim
\texttt{Tree}\App\sigma_1$ then we can recover the coercion components
using the \trule{co-left} and \trule{co-right}, for the higher kinded
type and its arguments respectively. In full generality, the lifting
operation is defined in \pref{def:sfc-coercion-lifting}
and the property is formailzed in \pref{lem:sfc-coercion-lifting}.

\begin{defn}[Coercion Lifting]\label{def:sfc-coercion-lifting}
Let $\Subst = \Sub{\alpha}{\Co}$\\
\begin{minipage}{0.5\linewidth}
\begin{flalign*}
\Subst c &:= c\\
\Subst T &:= T\\
\Subst\Refl{\beta} &:= \texttt{if}~ \alpha = \beta~ \texttt{then}~ \Co~ \texttt{else}~\Refl\beta\\
\Subst\Sym\nu     &:= \Sym{\Subst\nu}\\
\Subst\Trans\nu{\nu'} &= \Trans{\Sub\alpha\Co\nu}{\Sub\alpha\Co\nu'}\\
\Subst\Right\nu     &:= \Right\Subst\nu
\end{flalign*}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{flalign*}
\Subst{\beta} &:= \texttt{if}~ \alpha = \beta~ \texttt{then}~ \Co~ \texttt{else}\beta\\
\Subst(\tau\to\sigma)  &:= (\Subst\tau)\to(\Subst\sigma)\\
\Subst(\tau\App\sigma) &:= (\Subst\tau)\App(\Subst\sigma)\\
\Subst(\Forall {\beta\co\kappa}\tau) &:= \Forall {\beta\co\kappa}{(\Subst\tau)}\\
\Subst(\nu\At\tau)     &:= (\Subst\nu)\At(\Subst\tau)\\
\Subst\Left\nu     &:= \Left\Subst\nu\\
\Subst(F\App\many\tau) &= F\App\Subst\many\tau
\end{flalign*}
\end{minipage}
\end{defn}


\begin{theorem}[Coercion Lifting Lemma]\label{lem:sfc-coercion-lifting}
 If $\TyKinding {\TEnv,\TyVar\co\kappa'}\phi\kappa$, where $\TyVar$ is free in $\phi$
 and does not appear free in $\TEnv$,
 $\CoKinding\TEnv\Co{\sigma_1\sim\sigma_2}$, and $\TyKinding\TEnv{\sigma_i}\kappa'$
 then, $\CoKinding\TEnv{\Set{\TyVar\mapsto \Co}\Refl\phi}
 {\Set{\TyVar\mapsto\sigma_1}\phi\sim\Set{\TyVar\mapsto\sigma_2}\phi}$
\end{theorem}
\begin{proof}[Proof Sketch \pref{lem:sfc-coercion-lifting}]
 Proof is by induction on the derivation of the well kinded type
 $\phi$. In each of the four cases, whenever in the original
 derivation the rule \trule{co-refl} was used, it is replaced by the
 derivation of $\CoKinding \TEnv \Co {\sigma_1\sim\sigma_2}$.
\end{proof}

\newcommand\TVar{
 \ib{\irule[\trule{var}]
 {x\co\tau \in \TEnv};
 {\Typing \TEnv x \tau}
 }
}

\newcommand\TAbs{
 \ib{\irule[\trule{\I\to}]
 {\Typing {\TEnv,x\co\sigma} {M} {\tau}};
 {\Typing \TEnv {\Lam x M} {\sigma \to \tau}}
 }
}
\newcommand\TApp{
 \ib{\irule[\trule{\E\to}]
 {\Typing \TEnv \Tm {\sigma \to \tau}}
 {\Typing \TEnv N \sigma};
 {\Typing \TEnv {\Tm \App N} {\tau}}
 }
}
\newcommand\TTyApp{
 \ib{\irule[\trule{\E\forall}]
 {\Typing  \TEnv \Tm {\Forall {\alpha\co\kappa} \tau}}
 {\Kinding \TEnv \sigma \kappa};
 {\Typing  \TEnv {M\App\sigma} {\tau}}
 }
}

\newcommand\TTyAbs{
 \ib{\irule[\trule{\I\forall}]
   {\Typing {\TEnv,\alpha\co\kappa} \Tm \tau}
   {\alpha\#\TEnv};
   {\Typing \TEnv {\Forall {\alpha\co\kappa} \Tm} {\tau}}
 }
}

\newcommand\TAlt{
 \ib{\irule[\trule{alt}]
 {H\co{\Forall{\many{\alpha\co\kappa}}{\Forall{\many{\beta\co\iota}}{\many\sigma \to T\many\alpha}}}\in{\TEnv}}
 {\Subst = \Set{\many{\alpha \mapsto \tau'}}}
 {\Typing {\TEnv, \many{\beta\co\Subst\iota}, \many{x\co\Subst\sigma}} {N} {\tau} };
 {\Typing \TEnv {H\App\many{\beta\co\Subst\kappa}\App\many{x\co\Subst\sigma} \to N} {T\many{\tau'} \to \tau}}
 }
}

\newcommand\TCast{
 \ib{\irule[\trule{cast}]
 {\Typing \TEnv {\Tm} {\tau}}
 {\CoKinding \TEnv \Co {\tau \sim \sigma}};
 {\Typing \TEnv {\Cast \Tm \Co} {\sigma}}
 }
}
\newcommand\TCase{
 \ib{\irule[\trule{case}]
 {\Typing \TEnv {\Tm} {\sigma}}
 {\many{\Typing \TEnv {P \to N} {\sigma \to \tau}}};
 {\Typing \TEnv {\Case \Tm {\many{P \to N}}} {\tau}}
 }
}

\begin{figure}[ht]
\begin{gather*}
  \fbox{$\Typing \TEnv M \tau$}\\
  \TVar   \rsp \TAbs \rsp \TApp\\
  \TTyAbs \rsp \TTyApp \\
  \TCast  \rsp \TCase \\
\fbox{$\Typing \TEnv {P \to N} {\tau \to \sigma}$}\\
  \TAlt
\end{gather*}

 \caption{Typing Judgments: Excerpt of Static Semantics of \SFC}
 \Description{Typing Judgments: Excerpt of Static Semantics of \SFC}
 \label{fig:sfc-typing-ty}
\end{figure}

A typing rule for terms, \fbox{$\Typing \TEnv \Tm \tau$}, is
shown in \pref{fig:sfc-typing-ty}. The rules inherited from \SF
are $\trule{var}$, $\trule{\I\to}$, $\trule{\E\to}$,
$\trule{\I\forall}$, and $\trule{\E\forall}$. The novel rule
$\trule{cast}$ transforms a term $M\co\tau$ to a term $\Cast M \Co : \sigma$ with
a witness coercion $\Co\co\tau\sim\sigma$.

The two typing rules worth discussing are the ones for typing case
statements $\trule{ty-case}$ and typing alternatives
$\trule{ty-alt}$. A case statement can only be well typed if the
discriminant is of type $\sigma$ and each of the alternatives $P \to
N$ have the same type $\sigma \to \tau$. For alternatives, if the
pattern is a data constructor, only the existential type variables
$\many\beta$ are brought into scope explicitly in the pattern.
The reason to do this is to ensure that the continuation term, $N$, can use
the existentially bounded variables. However, we should be careful to
not let the existential variables escape their scope. This invariant
also needs to be enforced by the elaboration step from surface syntax into
the core language. For example, consider the data constructor
!IsEquals! and its type with explicit kind annotations from
the previous section.

\begin{CenteredBox}
\begin{code}
IsEquals :: FORALL (a :: *). FORALL (b :: *). DEq b -> b -> b -> GAlgExp a
\end{code}
\end{CenteredBox}

Inside a case term the alternative has the form

\begin{CenteredBox}
\begin{code}
(IsEquals (b :: *). (d :: Eq b) (x :: b) (y :: b)) -> N
\end{code}
\end{CenteredBox}

where, $N$ is the continuation term if the discriminant matches the pattern
!IsEquals!, and the existential variable !d! the dictionary for the !Eq!
typeclass, instances of which implements equality behavior over types.
This type transformation is sound as the type of !IsEquals! is
isomorphic to the following type:

\begin{CenteredBox}
\begin{code}
FORALL (a :: *). (EXISTS (b :: *). (Eq b, b, b)) -> GAlgExp a
\end{code}
\end{CenteredBox}

\subsection{Operational Semantics}\label{sec:sfc-op-sem}
\newcommand{\Beta}{
 \ib{\irule[\trule{$\beta$}]
 {};
 {$\stepsto {(\Lam {x\co\tau} M) \App N} {\Set{x\mapsto N}M}$}
 }
}
\newcommand{\TBeta}{
 \ib{\irule[\trule{Ty-$\beta$}]
 {};
 {$\stepsto {(\TLam \TyVar M) \App \tau} {\Set{\TyVar\mapsto \tau}M}$}
 }
}
\newcommand{\CaseE}{
 \ib{\irule[\trule{case}]
 {};
 {\stepsto {\Case {(H\App\many\sigma\App\many\phi\App\many\Tm)} {\Set{...; H\App\many\beta\App\many x \to N; ...}}} {\Set{\many {\beta\mapsto\phi}, \many{x\mapsto\Tm}}N}}
 }
}
\newcommand{\CoTransE}{
 \ib{\irule[\trule{Co-Trans}]
 {};
 {$\stepsto {\Cast {(\Cast \Val \Co)} {\nu}} {\Cast \Val {(\Trans{\Co} {\nu})}}$}
 }
}

\newcommand{\TyPush}{
 \ib{\irule[\trule{ty-push}];
    % {\Co : {\Forall {c\co\kappa} \tau} \sim \Forall {c\co\kappa} \tau'};
 {$\stepsto {(\Cast{\TLam {\TyVar\co\kappa} M}\Co)\App \tau} {({\TLam {\TyVar\co\kappa} (\Cast M {\Co\At\TyVar})})\App \tau}$}
 }
}

\newcommand{\CoPush}{
 \ib{\irule[\trule{co-push}]
 {\substack {\mathlarger{\nu\co \sigma_1' \sim \sigma_2'}\\
 \mathlarger{\Co_1 : \sigma_1 \sim \sigma_1' = \Left {(\Left \Co)}}}}
 {\substack {\mathlarger{\Co\co (\sigma_1 \sim \sigma_2 \then \sigma_3) \sim (\sigma_1' \sim \sigma_2' \then \sigma_3')}\\
 \mathlarger{{\Co_2: \sigma_2 \sim \sigma_2' = \Right{(\Left\Co)}\quad{\Co_3:\sigma_3\sim\sigma_3' = \Right\Co}}}}};
 {$\stepsto {(\Cast{\TLam {\TyVar\co(\sigma_1\sim\sigma_2)} M}\Co)\App \nu} {\Cast {(\TLam {\TyVar\co(\sigma_1\sim\sigma_2)} M)\App (\Co_1 \circ \nu \circ \Sym \Co_2)} {\Co_3}} $}
 }
}

\newcommand{\Push}{
 \ib{\irule[\trule{push}]
 {\Co : \tau_1 \to \tau_2 \sim \tau_1' \to \tau_2'}
 {\Co_1 = \Right (\Left \Co)}
 {\Co_2 = \Right \Co};
 {$\stepsto {({\Cast {(\Lam x M)} {\Co}}) \App N} {\Cast {(({\Lam x M})\App {(\Cast N {\Sym \Co_1})})} \Co_2}$}
 }
}

\newcommand{\HPush}{
 \ib{\irule[\trule{h-push}]
 {\substack{\mathlarger{\Co : T\App\many\sigma \sim T\App\many\tau}\\
 \mathlarger{H : \Forall {\many{\TyVar\co\kappa}} {\Forall {\many{\beta\co\kappa'}} \many\rho \to T\App\many\TyVar^n}}}}
 {\substack{\mathlarger{{\Subst = \Set{\many{\TyVar_i \mapsto \Co_i}, \many{\beta_i \mapsto \phi_i}}}}\\
 \mathlarger{\Tm'_i = \Cast {\Tm_i} {\Subst\rho_i}}\\
 \mathlarger{\Co_i = \Right (\Left^{n-i}\Co) }}}
 {\phi' =
 \begin{cases}
 \Cast {\phi_i} \Subst(v_1 \sim v_2) &\text{if }\beta_i:v_1 \sim v_2\\
 \phi_i\quad &\text{otherwise}
 \end{cases}
 };
 {$\stepsto {\Case {(\Cast {H\App \many\sigma\App\many\phi\App\many\Tm} \Co)} {\many{\Ptrns \to N}} }
 {\Case {(H\App \many\tau\App\many{\phi'}\App\many{\Tm'})} {\many{\Ptrns \to N}} }$}
 }
}

\begin{figure}[ht]
 \centering
 \begin{syntax}
% \text{Value Types} && T\Val &::= T \bnfor \tau \to \tau \bnfor \Forall {\TyVar\co\kappa}\\
 \text{Plain Values} && \Val &::= H \bnfor \Lam {x\co\tau} \Tm \bnfor \TLam {\TyVar\co\kappa} \Tm \\
 \text{CValues} && C\Val &::= \Val \bnfor \Cast \Val \Co
%
% \text{Evaluation Contexts} && \EvalCtxt &::= \EvalCtxtHole{-} \bnfor \EvalCtxt\App M \bnfor \EvalCtxt\App \tau \bnfor \Cast \EvalCtxt \Co \bnfor \Case \EvalCtxt {\many{P}}\\
 \end{syntax}
 \Description{Term values and evaluation contexts}
\end{figure}
The operational semantics formalizes the runtime behavior of the
terms of the language. The value terms fall into two
categories: plain values,  $\Val$, or coercion values, $C\Val$,
which are values with coercion casts.  Value terms denote the ``good''
terms of the language which do not evaluate. For example, !True!, of
type !Bool! is a value term. Coercion values, or cvalues, are needed
to maintain the type preservation property.
%We use $\EvalCtxt$ notation to identify which sub-term reduces in the next step.
%This presentation uses call by need semantics, but it may as well use call
%by value without affecting any meta-theoretic properties.
The terms involving coercions can step in one of the four interesting
ways given by the rules \trule{push}, \trule{ty-push},
\trule{co-push}, or \trule{h-push} shown in the \pref{fig:op-sem-sfc}.
\begin{figure}[ht]
 \centering
 \begin{gather*}
 \fbox{$\stepsto M N$}\\
 \Push \rsp \TyPush\\
 \CoPush\\
 \HPush\\
 \Beta \rsp \TBeta\\
 \CaseE \rsp \CoTransE
 \end{gather*}
 \caption{Operational Semantics of \SFC}
 \Description{Operational Semantics of \SFC}
 \label{fig:op-sem-sfc}
\end{figure}

In the rule \trule{push}, the coercion $\Co$, which is applied to the
lambda term, is decomposed into two coercions; the first coercion,
`$\Co_1$', is used in the coercion applied to the argument, the second
coercion `$\Co_2$', is used to apply the complete term. Applying this
transformation rule exposes a \trule{$\beta$}-redux. This shows that
coercions do not interfere with the function applications. The rule
\trule{ty-push} for type application moves the coercion inside a type
abstraction instantiated at the type variable. The rule
\trule{co-push} is just like \trule{push} but for moving coercions
inside a coercion abstraction. Just like in the rule \trule{push}, we see that
the rule \trule{ty-push} enables evaluation for type functions applied
to a coercion. The rule \trule{co-push} is similar to the rule
\trule{ty-push} but works on coercion abstractions. The type and
coercion calculation ensures that the types are
preserved when we push the coercions inside the body of a lambda bound term.

The most complex rule, \trule{h-push}, pushes the coercion within
the case term scrutinee. This rule is best illustrated with an example.
Consider the term:

\begin{CenteredBox}
\begin{code}
Cons (T Bool) x xs /> c
\end{code}
\end{CenteredBox}

where !T! is a type constant, !Cons : FORALL a. a -> List a -> List a!,
and !c : List (T Bool) ~ List Int!.
The cast transforms the term from type !List (T Bool)! to type !List Int!
while pushing the coercion into its sub-components with
$\Subst = \Sub a {\Right c}$
\[
\stepsto {\Cast {(\texttt{Cons}\App \texttt{(T Bool)}\App \texttt{x}\App
                              \texttt{xs})} c}
         {\texttt{Cons} \App \texttt{Int}\App
                   (\Cast {\texttt{x}} \Right c)
                   (\Cast {\texttt{xs}} {\Refl{\texttt{List}}\App (\Right c)})}
\]
After this transformation, the term is no longer is a
coercion term, but a data constructor. If the original term
was the case scrutinee, then the rule \trule{case}
can be applied only after the coercion has been pushed
in to make progress in evaluation. The notation $\Left^k \Co$
stands for $\Left{}$ applied $k$ times to $\Co$.
Coercion lifting plays an important role: it ensures that the term
sub-components $\Cast {M_i} {\Subst}\rho_i$ are of
the appropriate type. Finally, the rule \trule{co-trans}
flattens a chain of two coercions, $\Co$ and $\nu$, into a casted term
with one coercion, $\Trans\Co\nu$.

The other rules, \trule{$\beta$}, \trule{ty-$\beta$} and \trule{case}
are carried over from \SF~\cite{pierce_tapl_2002}. As a short hand to chain
multiple rules of the operational semantics defined in~\pref{fig:op-sem-sfc},
we define a  multi-step reduction relation: $\manystepsto\bullet\bullet$. It is a
reflexive transitive closure of the single step operational semantics,
$\stepsto \Tm N$.

\newcommand\MultiStepRefl{
    \ib{\irule[\trule{$\rightsquigarrow^*-r$}];
      {\manystepsto \Tm \Tm}
    }
}
\newcommand\MultiStepLift{
    \ib{\irule[\trule{$\rightsquigarrow^*-r$}]
      {\stepsto \Tm N};
      {\manystepsto \Tm N}
    }
}
\newcommand\MultiStepTrans{
    \ib{\irule[\trule{$\rightsquigarrow^*-t$}]
      {\stepsto \Tm {\Tm'}}
      {\manystepsto {\Tm'} N};
      {\manystepsto \Tm N}
    }
}

The operational calculus of coercions is not required during runtime.
They are required to prove the soundness property of the calculus.

\subsection{Meta-theory}
The above formalization of static and operational semantics
help us to answer the two important questions about the system:
\begin{enumerate}
\item Do the static semantics effectively weed out
    all the programs that may fail at runtime?
\item If we forget all the coercion and type annotations
    from the well typed term, can the same operational semantics be simulated?
\end{enumerate}

The first question is answered by proving the syntactic soundness property~\cite{wright_syntactic_1994},
and the second, by showing that the system respects phase distinction~\cite{harper_higher-order_1989}.

\subsubsection{Soundness}
\begin{claim}[Progress and Subject Reduction]\label{claim:sfc-ty-safety}
 If $\Typing \TEnv \Tm \tau$ then, either $\Tm \in C\Val$ or, $\stepsto \Tm \Tm'$ and
 $\Typing \TEnv {\Tm'} \tau$
\end{claim}

Informally, if we have a well typed term $\Tm$, with type $\tau$, then
either the term is a value, and it cannot evaluate any further, or
it can evaluate using one of the rules given by the operational semantics.
Further, the type of the term never changes during evaluation.
In practice, all those terms that may get a stuck
are rejected by the typechecker as they will be ill-typed.

An important step while proving subject reduction is to ensure
that anything obviously wrong such as
!coBAD : Int ~ Bool! can never be derived in the
system at the top level. Consider the term:
\[ f = \TLam{c:Int \sim Bool}{not\App (\Cast 5 c)}\]
with the environment $\Delta = \TEnv, not\co\texttt{Bool} \to \texttt{Bool}$.
If it was possible to derive !coBad! using $\Delta$
then, $f$ can be invoked, and it will
crash the program. However, if the system prohibits derivation
of such inconsistent coercions, $f$ can never be invoked.
The \pref{claim:sfc-ty-safety} thus needs to be strengthened
using an appropriate restriction on $\TEnv$.
\SFC uses a conservative check which is sufficient to
ensure coercions like !coBad! can never be derived.

\begin{definition}[$\Good\TEnv$]
 A type environment, $\TEnv$, is $\Good\TEnv$ when it satisfies
 the following properties:
 \begin{itemize}
 \item If $\CoKinding \TEnv \Co {T \many\sigma \sim \tau}$ and $\tau$
   is a value type, then $\tau$ is of the form $T\App\many\sigma'$
 \item If $\CoKinding \TEnv \Co {(\sigma' \to \sigma) \sim \tau}$ and
   $\tau$ is a value type, then $\tau$ is of the form $\tau' \to \tau''$
 \item If $\CoKinding \TEnv \Co {\Forall {\TyVar\co\kappa} \sigma \sim
     \tau}$ and $\tau$ is a value type, then $\tau$ is of the form
   $\Forall {\TyVar\co\kappa} \sigma'$
 \end{itemize}
 Where a type is a value type if it is of the form $T\many\tau$,
 $\tau\to\sigma$, or $\Forall{\alpha\co\kappa}{\tau\sim\sigma}$
\end{definition}

\begin{theorem}[Progress and Subject Reduction]\label{thm:progress-sfc}
 If $\Good \TEnv$ and $\Typing \TEnv \Tm \tau$ then, either $\Tm \in
 C\Val$ or, $\stepsto \Tm \Tm'$ and $\Typing \TEnv {\Tm'} \tau$
\end{theorem}
\begin{corollary}[Syntactic Soundness]
\label{thm:soundness-sfc}
 If $\Good \TEnv$ and $\Typing \TEnv \Tm \tau$ then, one of the cases holds:
 \begin{enumerate}
    \item $\manystepsto \Tm {C\Val}$ and $\Typing \TEnv {C\Val} \tau$, or;
    \item evaluation of $\Tm$ diverges
 \end{enumerate}
\end{corollary}

\subsubsection{Phase Distinction}
The system also has the property where types do not
interfere with the execution of the program. In other words,
the types do not hold any computational significance,
they are merely a compile time artifact.
Even if all the type are erased from a well typed term,
the term will not get stuck at runtime.
Phase distinction is important as it provides formal
guarantee that the efficient representation of the terms will not
change its meaning. We formalize this in
\pref{cor:sfc-erasure-soundness}.

The erasure function, $\Erased{-}$, is defined on the term structure.
It erases all the type and coercion annotations from a \SFC term and
maps it to an ``efficient'' untyped lambda calculus term. The term, $\Unit$, is a
special constant. It contains no computational information and is
used to simulate application of type level lambdas.

\begin{defn}[Erasure of a \SFC Terms and Patterns]\label{defn:term-erasure}\hfill{}\\
Erasure of terms \Erased{\Tm}:

  \begin{CenteredBox}
    \begin{minipage}[ht]{0.5\linewidth}
      \begin{flalign*}
        \Erased{x\co\tau}            &= x\\
        \Erased{\Lam {x\co\tau} \Tm} &=\Lam x\Erased{\Tm}\\
        \Erased{\TLam {\alpha\co\kappa} \Tm}    &= \Lam \alpha {\Erased \Tm}\\
        \Erased{\Case N {\many{\Ptrns \to \Tm}}} &= \Case {\Erased{N}}
                                               {\many{\Erased{\Ptrns} \to \Erased{\Tm}}}
      \end{flalign*}
    \end{minipage}%
    \begin{minipage}[ht]{0.5\linewidth}
      \begin{flalign*}
        \Erased{\Cast \Tm \Co} &= \Erased \Tm\\
        \Erased{\Tm\App N} &= \Erased{\Tm}\App\Erased{N}\\
        \Erased{\Tm \App \phi} &= \Erased{\Tm}\App\Unit\\
        \Erased{H} &= H
      \end{flalign*}
    \end{minipage}
  \end{CenteredBox}

Erasure of Patterns $\Erased\Ptrns$:

  \begin{CenteredBox}
    \begin{minipage}{1.0\linewidth}
      \begin{flalign*}
        \Erased{H\App\many{\beta\co\kappa}\App\many{x\co\tau}} = H\App\many\beta\App \many x
      \end{flalign*}
    \end{minipage}
  \end{CenteredBox}
\end{defn}

\begin{theorem}
  If $\Good\TEnv$ and $\Typing \TEnv \Tm \tau$
  then one of the cases hold:
  \begin{enumerate}
      \item if $\Tm$ is a $C\Val$ then $\Erased\Tm$ is a $\Val$
      \item if $\stepsto \Tm {\Tm'}$ then,
      $\stepsto {\Erased\Tm}{\Erased{\Tm'}}$ or
      ${\Erased\Tm} = {\Erased{\Tm'}}$
  \end{enumerate}
\end{theorem}

\begin{corollary}[Erasure Soundness]\label{cor:sfc-erasure-soundness}
  If $\Good\TEnv$ and $\Typing \TEnv \Tm \tau$
  then $\manystepsto \Tm {\Tm'}$ if and only if $\manystepsto {\Erased\Tm} {\Erased{\Tm'}}$
\end{corollary}

% reason for divergence is that we have datatypes!

\section{Encoding Language Features in \SFC}\label{sec:sfc-encoding-features}%%%%%%%%%
\subsection{GADTs}\label{sec:fc-encodes-gadts}
Before formalizing how terms containting GADTs data constructors can be encoded into \SFC,
it is illustrative to see how the data constructors themselves are represented in \SFC.
Recall the definition of !GAlgExp a! from \pref{fig:galgexp-eval}, its \SFC encoding is
shown in \pref{fig:galgexp-sfc-encode}. The type tag of the return type of each data constructor
is generalized to a generic type variable,
with an additional type equality constraint that the generic type variable is equal
to the type tag. The type tag in the case of !Value! is !Int!. This is the
``Henry Ford'' encoding~\cite{chapman_gentle_2010}:
the type of !Value 0! is !GAlgExp a! as long as !a! is !Int!.

\begin{figure}[ht]
\centering
\begin{minipage}[ht]{0.6\linewidth}
\begin{CenteredBox}
\begin{code}
data GAlgExp a where
  Value  :: Int         -> GAlgExp Int
  Plus   :: GAlgExp Int
         -> GAlgExp Int -> GAlgExp Int
  IsZero :: GAlgExp Int
                        -> GAlgExp Bool
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.4\linewidth}
\begin{CenteredBox}
\begin{code}

Value :: FORALL(a :: TYPE). a ~ Int => Int -> GAlgExp a
Plus  :: FORALL(a :: TYPE). a ~ Int => GAlgExp Int
      -> GAlgExp Int -> GAlgExp a
IsZero :: FORALL(a :: TYPE). a ~ Bool => GAlgExp Int
       -> GAlgExp a
\end{code}
\end{CenteredBox}
\end{minipage}%
\caption{\texttt{GAlgExp} datatype (left) and and its \SFC elaboration (right)}
\Description[GAlgExp]{GAlgExp datatype and its \SFC elaboration}
\label{fig:galgexp-sfc-encode}
\end{figure}


Suppose the programmer writes the following term: !e = Value 0!.
The elaboration of !e! in \SFC makes the types and coercions explicit in the term.
Thus the term in \SFC will be !Value Int <Int> 0!. The coercion argument
is instantiated with the unique coercion !<Int> :: Int ~ Int!.

Although \SFC does not distinguish
between monotypes and polytypes, the surface level syntax does.
In \pref{fig:encoding-gadts}, the constraints, $C$, are named type equality
predicates. The monotypes, $\tau$, can be constrained using these type
equality constraints. The polytypes, $\pi$, are quantified constrained types.

\newcommand\GADTVar{
 \ib{\irule[\trule{g-var}]
 {x\co\pi \in \TEnv};
 {\GTranslate C \TEnv x {\pi} x}
 }
}
\newcommand\GADTEq{
 \ib{\irule[\trule{g-eq}]
 {\GTranslate C \TEnv \Tm \tau \Tm'}
 {\CoKinding C \Co {\tau \sim \tau'}};
 {\GTranslate C \TEnv \Tm {\tau'} {\Cast {\Tm'} \Co}}
 }
}
\newcommand\GADTForallI{
 \ib{\irule[\trule{g-$\I\forall$}]
 {\GTranslate C \TEnv \Tm \pi \Tm'}
 {\fresh \TyVar {C, \TEnv}};
 {\GTranslate C \TEnv \Tm {\Forall {\TyVar\co\star} \pi} {\TLam {\TyVar\co\star} \Tm'}}
 }
}
\newcommand\GADTForallE{
 \ib{\irule[\trule{g-$\E\forall$}]
 {\GTranslate C \TEnv \Tm {\Forall {\TyVar\co\star} \pi} \Tm'};
 {\GTranslate C \TEnv \Tm {\Set{\TyVar\mapsto\tau}\pi} {\Tm'\App \tau}}
 }
}
\newcommand\GADTCI{
 \ib{\irule[\trule{g-$\I C$}]
 {\GTranslate {C,c:\tau\sim\tau'} \TEnv \Tm {\eta} \Tm'};
 {\GTranslate C \TEnv \Tm {\tau\sim\tau'\then\eta} {\TLam {(c\co\tau\sim\tau')} \Tm'}}
 }
}
\newcommand\GADTCE{
 \ib{\irule[\trule{g-$\E C$}]
 {\GTranslate {C} \TEnv \Tm {\tau\sim\tau'\then\eta} \Tm'}
 {\CoKinding C \Co \tau\sim\tau'};
 {\GTranslate C \TEnv \Tm {\eta} {\Tm'\App\Co}}
 }
}
\newcommand\GADTAlt{
 \ib{\irule[\trule{g-alt}]
 {\substack{
 \mathlarger{H\co \Forall {\many\TyVar} {\Forall {\many\beta} {\many{\tau'\sim\tau''} \then \many\tau \to T\many\TyVar}}}\quad
 \mathlarger{\many\TyVar \cap \many\beta = \varnothing}\quad
 \mathlarger{\fvs{\many\tau, \many{\tau'}, \many{\tau''}} = \fvs{\many\TyVar, \many\beta}}\quad
 \mathlarger{\Subst = \Set{\many{\TyVar\mapsto v}}}\quad
 \mathlarger{\fresh {\many{c}} {C, \TEnv}}\\
 \mathlarger{\GTranslate {C,\many{c\co\Subst{\tau'}\sim\Subst\tau''}\,} {\,\TEnv,\many{x\co\Subst\tau}\,} \Tm {\tau'} \Tm'} }};
 {\GTranslate C \TEnv {H\App\many x \to \Tm} {T\App\many v \to \tau'}
 {H\App(\many{\beta\co\star})\App(\many{c\co\Subst\tau'\sim\Subst\tau''})\App(\many{x\co\Subst\tau}) \to \Tm' }}
 }
}

\begin{figure}[ht]
\centering
\begin{syntax}
\text{Constraints} && C \bnfeq& \empt \bnfor C, c\co\tau\sim\tau'\\
\text{Monotypes} && v,\tau \bnfeq& \TyVar \bnfor \tau\to\tau \bnfor T\App\many\tau\\
\text{Constrained Types} && \eta \bnfeq& \tau \bnfor C \then \eta\\
\text{Polytypes} && \pi \bnfeq& \eta \bnfor \Forall\TyVar\pi
\end{syntax}
 \begin{gather*}
 \fbox{$\GTranslate C \TEnv {\Tm} {\pi} {\Tm'}$}\\
 \GADTVar \rsp \GADTEq\\
 \GADTForallI \rsp \GADTForallE\\
 \GADTCI \rsp \GADTCE
 \end{gather*}
 \begin{gather*}
 \fbox{$\GTranslate C \TEnv {p \to \Tm} {\pi \to \pi} {p' \to e'}$}\\
 \GADTAlt
 \end{gather*}
 \caption[Encoding GADTs]{Type Syntax and Type-directed Translation of GADTs in \SFC}
 \Description[Encoding GADTs]{Type-directed Translation of GADTs in \SFC}
 \label{fig:encoding-gadts}
\end{figure}

The typing-cum-elaboration judgment
\fbox{$\GTranslate C \TEnv \Tm \pi \Tm'$} denotes that: given a well
typed surface level term $\Tm$ with type $\pi$, it is elaborated to a
term $\Tm'$ in \SFC under the constraints C and typing environment
$\TEnv$. The key observation is that the type equality
constraints, $\tau\sim\tau'$, are elaborated to coercions in \SFC.
The rules \trule{g-var}, $\trule{g-\I\forall}$ and \trule{g-$\E\forall$} are
standard rules used for elaborating Hindley-Milner style
system~\cite{wadler_polymorphism_1989} to \SF. The rules \trule{g-$\I C$}
and \trule{g-$\E C$} reminiscent of elaborating typeclass
constraints. However, unlike typeclasses, the equality constraints
are elaborated to types (coercions) and not term level constructs (dictonaries).
The complex looking rule \trule{g-alt} elaborates
case statements into \SFC. Each surface level data constructor is
elaborated to the \SFC data constructor with explicit existential
coercions as pattern variables. The rule $\trule{g-eq}$ is the same as
\trule{cast} rule. In the rules $\trule{g-eq}$ and \trule{g-$\E C$},
the coercion, $\Co$, is built using the context $C$. Constructing the appropriate $\Co$
algorithmically is possible by using a unification algorithm
based on ~\citet{lassez_unification_1988}.

We can now demystify the type magic that the !eval! function
performed by elaborating the definition of the eval function into \SFC as shown in \pref{fig:encoding-eval}.

\begin{figure}[h]
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: GAlgExp a -> a
eval (Value i) = i
eval (Plus x y)
   = (eval x) + (eval y)
eval (IsZero x)
   = eval x == 0
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
eval :: FORALL a. GAlgExp a -> a
eval a (Value Int co x) = x /> sym co
eval a (Plus Int co x y)
   = ((eval Int x) + eval Int y) /> sym co
eval a (IsZero Bool co x)
   = (eval Int x == 0) /> sym co
\end{code}
\end{CenteredBox}
\end{minipage}
\caption[Encoding eval]{The \texttt{eval} function (left) and its elaboration in \SFC (right)}
 \Description[Encoding GADTs]{Elaborating function eval in \SFC}
 \label{fig:encoding-eval}
\end{figure}

In the case alternative for !Value!, the argument to the constructor is !Int!,
It is casted to the return type, !a!, using the coercion !sym co :: Int ~ a!.
In the case alternative of !IsZero!, an existential
coercion, !co :: a ~ Bool!, is brought into scope. The coercion, !co!, refines
the result type of the expression !(eval Int x == 0)!
from the actual type !Bool! to the generic variable !a!. The !Plus! case
can be read systematically: each argument,
!x! and !y!, is first evaluated at type !Int!. The sum of the evaulations
is returned after casting it with the coercion, !sym co!, to match it
with the return type of the function.

We want to ensure that the subject reduction property proved
in \pref{thm:progress-sfc} holds with this extension.
The following lemmas are extensions of the meta-theoretic properties
discussed in the previous section.

\begin{lemma}[Type Preservation]\label{lem:gadt-type-preservation}
 If $\GTranslate C \empt \Tm \pi {\Tm'}$ then $\Typing {C;\empt} {\Tm'} \pi$
\end{lemma}
Type preservation is an important sanity check: the elaboration of a closed term
does not change its type.

\begin{theorem}[GADT Consistency]\label{thm:gadt-consistency}
 If $\Good\TEnv$ and $\dom\TEnv$ does not contain type variables and coercion
 constants, and $\CoKinding \TEnv \Co {\tau\sim\tau'}$
 then, $\tau$ and $\tau'$ are syntactically identical.
\end{theorem}
\pref{thm:gadt-consistency} says that if two base types, or type
function free types, are provably equal, then they must be
syntactically identical. This is an important property which says makes
it possible to use coercions safely. For example, the value !co!
in !Val Int co! from \pref{fig:encoding-eval}, can only be a $\Refl{Int}$, the
trivial coercion construct.

Finally, all GADT programs are sound in \SFC due to \pref{lem:gadt-type-preservation},
\pref{thm:gadt-consistency} and \pref{cor:sfc-erasure-soundness}
\begin{corollary}[GADT Soundness]
 If $\GTranslate \empt \empt \Tm \tau \Tm'$, then $\manystepsto {\Tm'}
 \Val$ iff $\manystepsto {\Erased\Tm} \Val$ where $\Val$ is a
 value of a ground type.
\end{corollary}

\subsection{Newtypes}\label{sec:fc-encodes-newtypes}
Newtypes have a trivial translation into
\SFC. Each surface level type declaration gives rise to an coercion
axiom. For example, consider the !newtype HTML! example from
\pref{fig:html-generative-type}.
The axiom !coHtml! can be used freely to cast any term with a type
!HTML! to be used in the context that expects a !String!. The
attractiveness of this encoding is that it enables type safety at zero
runtime cost.

\begin{figure}[ht]
\centering
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
newtype Html = MkHtml String

mkHtml :: String -> Html
mkHtml x = Html (escapeString x)

unHtml :: Html -> String
unHtml x = case x of HTML y -> y
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
coHtml :: Html ~ String

mkHtml :: String -> Html
mkHtml x = (escapeString x) /> (sym coHTML)

unHtml :: Html -> String
unHtml x = x /> coHtml
\end{code}
\end{CenteredBox}
\end{minipage}
\caption[\lstinline{HTML}]{\lstinline{newtype HTML} functions (left) and its elaboration in \SFC (right)}
\Description[\lstinline{HTML}]{\lstinline{newtype HTML} functions (left) and its elaboration in \SFC (right)}
\label{fig:newtype-html-example}
\end{figure}

For example, the function !mkHTML!
as shown in \pref{fig:newtype-html-example}, the elaborated \SFC
code will have a type cast instead of explicit boxing with a data constructor.
In the elaborated !unHTML! function, code would contain
a type cast instead of explicit unboxing using a !case! statement as shown above.
Further, due to coercion lifting, this zero cost abstraction can be factored through
compositionally to complex data types as well: !List Html! is treated exactly as !List String!
as the coercion !List coHtml! justifies it.

A a new category of datatypes, separate from vanilla data constructors, is needed
to formalize the above elaboration procedure using a type directed translation.
As shown in \pref{fig:newtypes-syntax-sfc}, this new category of newtype datatypes,
$T_N$, has only one associated data constructor $D_N$. It specifies the newtypes representation.

\begin{figure}[ht]
  \centering
  \begin{syntax}
    \text{Newtype Type Constructors} & T_N\\
    \text{Newtype Data Constructors} & D_N
  \end{syntax}
  \begin{syntax}
    \text{Types}               && \tau,\sigma \bnfeq& \alpha \bnfor \cdots \bnfor T_N\\
    \text{Newtype Declaration} && D_{cl} \bnfeq& \texttt{\textbf{newtype}}~ T_{N}~\many\alpha = D_N\App\tau\\
  \end{syntax}
  \caption{Extension Syntax for \lstinline{newtype} in \SFC}
  \Description{Extension Syntax for \lstinline{newtype} in \SFC}
  \label{fig:newtypes-syntax-sfc}
\end{figure}

The type directed translation of the surface level datatype definition is shown in
\pref{fig:nt-elaboration}. The rule \trule{nt-ax} generates an axiom along with the
type and term constants.

\newcommand\NTAx{
 \ib{\irule[\trule{nt-ax}];
 {\NTranslate \TEnv {\texttt{newtype}~ T_N~ \many{\alpha} = D_N~ \Set
     {x : \tau}}
   {\substack {\mathlarger{\TEnv, D_N : \tau \to T_N\App\many\alpha, x : T_N\many\alpha \to \tau,}\\
     \mathlarger{\texttt{axiom}~coT_N : \Forall {\many{\alpha}}{T_N~\many\alpha \sim \tau}}
   }}}
 }
}

\newcommand\NTElab{
 \ib{\irule[\trule{nt-pack}]
 {\NTTranslate \TEnv M \tau {M'}};
 {\NTTranslate \TEnv {D_N\App M} {T_N\many\tau} {\Cast {M'} {\texttt{sym}~(coT_N \At \many\tau)}}}
 }
}

\newcommand\NTPatElab{
 \ib{\irule[\trule{nt-unpack}]
   {\NTTranslate \TEnv \Tm \tau {\Tm'}}
 {\NTTranslate {\TEnv, x\co\tau} N \sigma {N'}};
 {\NTTranslate \TEnv {\Case {D_N\App \Tm} {\Set {D_N\App x \to N}}}
   {\sigma} {{\Set{x \mapsto ({\Cast {\Tm'} {coT_N \At \many\tau}})} N'}}}
 }
}

\begin{figure}[ht]
\centering
\begin{gather*}
  \NTAx
%  \NTElab \\
%  \NTPatElab
\end{gather*}
\caption{\texttt{Newtype} type directed translation}
\Description{Newtype type directed translation}
\label{fig:nt-elaboration}
\end{figure}

The optimization step, of removing packing and unpacking of values of newtype,
cannot be performed on algebraic datatypes.
The runtime cost characteristics of types declared using
!newtype!s and !data! are different. Due to the newtype definition
!Html! \emph{is a} !String! and there is no runtime cost
for coercing !Html! to !String! and vice versa.
The coercion axiom introduced during the elaboration step of the
newtype declaration makes this zero runtime cost cast possible.
Similar to GADT syntactic soundness, we also have the syntactic
soundness for newtypes:

\begin{theorem}[New types Syntactic Soundness]\label{lem:nt-syntax-soundness}
 If $\Good\TEnv$ and $\NTTranslate {\TEnv} \Tm \tau {\Tm'}$ then, $\manystepsto {\Tm'}
 \Val$ iff $\manystepsto {\Erased\Tm} \Val$ where $\Val$ is a value of
 a ground type.
\end{theorem}

\subsection{Type Computation}
\subsubsection{Associated Types}\label{sec:fc-encodes-assoctypes}
Reconsider the !Con c! typeclass which captures the behavior of
containers from \pref{fig:assoc-types}.
The function !sumCon :: (Con c, Num (Elem c)) => c -> Elem c!
sums up all the elements of the collection !c!.
The predicate !Num (Elem c)! asserts that the elements
of the collection are number like. A reasonable use of !sumCon!
would be at type !List Int!; a list of integers can be folded
into an integer by using a repeated addition operation.
This amounts to instantiating the type parameter !c!
with !List Int! as shown in \pref{fig:sfc-assoc-type}.


\begin{figure}[ht]
  \centering
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
sumCon :: FORALL c. (Con c, Num (Elem c))
       => c -> Elem c
instance Con (List Int) where
  type Elem (List Int) = Int
  ...

sumList :: List Int -> Int
sumList as = sumCon as
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{CenteredBox}
\begin{code}


dnumInt :: Num Int
dconList :: Con (List Int)
coAx :: Elem (List Int) ~ Int


sumList :: List Int -> Int
sumList as = sumCon (List Int) dconList
                    (dnumInt /> sym (<Num>coAx)) as
\end{code}
\end{CenteredBox}
\end{minipage}
\caption{Functions with Associated Types (right) and their elaboration in \SFC (left)}
\Description{Functions with Associated Types (right) and their elaboration in \SFC (left)}
\label{fig:sfc-assoc-type}
\end{figure}

!dnumInt! is the instance dictonary for !Num Int!
and !dconList! is the instance dictonary for !Con (List Int)!.
Type equality axiom !coAx! is obtained due to the associated
type instantiation. It asserts that !Elem (List Int)! is !Int!.
This explicit type equality is used to justify calling !sumCon!
with a !dnumInt! dictonary casted to type !Num (Elem Int)!.

\begin{figure}[ht]
 \centering
 \begin{syntax}
 \text{Class Declarations} &&C_{ls} \bnfeq& \textbf{\texttt{class }} D\App\many\TyVar \textbf{\texttt{ where }} \many{tsig}; \many{vsig}\\
 \text{Instance Declarations} &&I_{nts} \bnfeq& \textbf{\texttt{instance }} D\App\many\tau \textbf{\texttt{ where }} \many{tbnd}; \many{vbnd}\\
 \text{Associated types} &&tsig \bnfeq& \textbf{\texttt{type }} \tau\\
 \text{Method signatures} &&vsig \bnfeq& x\co\tau\\
 \text{Associated type instance} &&tbnd \bnfeq& \textbf{\texttt{type }} \tau = \sigma\\
 \text{Method bindings} &&vbnd \bnfeq& x = \Tm
 \end{syntax}
 \caption[Class Syntax]{Class and Associated Types Surface Syntax}
 \Description[Class Syntax]{Class and Associated Types Surface Syntax}
 \label{fig:assoc-types-syntax}
\end{figure}


Each class declaration introduces a new class predicate name in the
type environment along with its method names. With associated types, a
new ``type function'' name---!Elem c! in the case of !Con c!---is
added to the type environment. Each instance introduces a new axiom
into the typing environment. For the !Con c! typeclass the instance
!Con (List Int)! introduces the coercion !CoCon : Elem (List Int) ~ Int!.
In general, each instance generates an axiom of the form
\begin{CenteredBox}
\begin{code}
co : FORALL $\many{\TyVar\co\star}$. F $\sigma$ $\sim$ $\sigma'$
\end{code}
\end{CenteredBox}

where $\fvs\sigma = \many\TyVar$ and $\fvs{\sigma'} \subseteq \many\TyVar$.
These axioms can also be viewed as type rewrite inducing axioms as it
rewrites the type $F\App\many\sigma$ to the right hand side of the
equation, $\sigma$. However, these type rewrite axioms are indeed type
equivalences, as the typechecker can replace an occurance of $\sigma'$
to $F\App\many\sigma$

$$
\ib{\irule[\trule{subst}]
 {\DTranslate C {D\App\tau} d}
 {\CoKinding C \Co {D\App\tau \sim D\App\tau'}};
 {\DTranslate C {D\App\tau'} {\Cast d \Co}}
}
$$

To formalize the elaboration procedure, the typing rules
\trule{g-$\I C$} and \trule{g-$\E C$} from \pref{fig:encoding-gadts} are reused.
They are now generalized where the constraint set $C$ contain typeclass constraints
along with type equality predicates. The rule \trule{subst} captures the translation
of casting dictonaries as seen in the above example. The judgment $\DTranslate C {D\App\tau} d$
elaborates the predicate $D\App\tau$ to a dictionary $d$ in \SFC.
In the type checker implementation, the typeclass constraint solver
builds the dictonary evidence~\cite{hall_type_1994}.

\begin{theorem}[Associated Type Consistency]
If $\TEnv$ contains type rewrite axioms that are confluent and
terminating, then $\TEnv$ is consistent.
\end{theorem}

For non-overlapping typeclass instances, the rewrite axioms
are indeed confluent and terminating. The soundness
theorem for associate types as it is exactly the same as for GADT soundness.


\subsubsection{Open Type Functions}\label{sec:fc-encodes-opentypefun}
The associated types can also be disassociated from their typeclasses
and have an independent existence. Such types are called type functions or type families.
They are open, meaning, just like class instances, they can be extended. An
example of how type computations are expressed by type functions that
define addition of naturals at type level, shown in \pref{fig:open-type-fun-add}.
\begin{figure}[ht]
\begin{minipage}[ht]{0.4\linewidth}
\begin{code}
data Z
data S n
\end{code}
\end{minipage}%
\begin{minipage}[ht]{0.4\linewidth}
\begin{code}
type family Plus m n
type instance Plus Z n = n
type instance Plus (S m) n = S (Plus m n)
\end{code}
\end{minipage}
\caption{Type level Arithmetic}
\Description{Type level Arithmetic}
\label{fig:open-type-fun-add}
\end{figure}

Each type family instance directly translates to coercion axioms.
The two instances for the !Plus! type family introduces the following axioms:

\begin{CenteredBox}
\begin{code}
coPlusZn :: FORALL n. Plus Z n ~ n
coPlusSmn :: FORALL m n. Plus (S m) n ~ S (Plus m n)
\end{code}
\end{CenteredBox}

There are certain caveats on how these coercion axioms introduced by
type functions can be used by the typechecker to avoid inconsistency.
For example, consider an open type function !F! and two
of its instances that give rise to axioms !coFIB! and !coFBB! respectively.

\begin{minipage}[ht]{0.5\linewidth}
\begin{code}
            type family F a
            type instance F Int = Bool
            type instance F Bool = Bool
\end{code}
\end{minipage}%
\begin{minipage}[ht]{0.5\linewidth}
\begin{code}
      axiom coFIB: F Int ~ Bool
      axiom coFBB: F Bool ~ Bool
\end{code}
\end{minipage}

We can derive a coercion !Int ~ Bool! if we are careless.
Both axioms have !Bool! as their result type, and hence
we can derive !F Int ~ F Bool! by transitivity, and then
we can use the !right! construct to derive !Int ~ Bool!.
The following term

\begin{CenteredBox}
\begin{code}
 right (coFIB  . sym coFBB)
\end{code}
\end{CenteredBox}

has the type !Int ~ Bool!, a blunder$\bang$ It is crucial to use the !left! and !right!
rules only on types that are not applications of type functions as
they can be non-injective. This also influences the surface language
design: the type functions are special and need to be always fully saturated.

\subsection{Observations}
In the current formalization, all the types and coercions are explicit
in the system. While this makes a machine implementation of the system easy
to design and work with, it is difficult for humans to read
and understand the \SFC terms. As an optimization step,
it may be worth while to see if it is possible to elide some of the
explicit coercions and then reconstruct them using a type synthesis
algorithm. We first define a system with implicit coercions: \SFCi.
The key difference between \SFC and \SFCi is that where \SFC has a
coercion type $\Co$ of kind $\tau\sim\tau'$, \SFCi only gives the
equality kind in curly braces $\tau\sim\tau'$.
Hence, for terms
\begin{itemize}
\item Type casts, $\Cast \Tm \Co$, turns into $\Cast \Tm \Set{\tau \sim \tau'}$ and,
\item Coercion applications, $\Tm\App\Co$ turns into $\Tm\App\Set{\tau \sim \tau'}$
\end{itemize}
\begin{theorem}[Undecidability of coercion reconstruction of \SFCi]
 If $\Tm_i$ is an expression in \SFCi and $\TEnv$ is a typing
 environment then, reconstructing a \SFC term $\Tm$
 such that $\Typing \TEnv {\stepsto {\Tm_i} \Tm} \sigma$, where
 $\Typing \TEnv \Tm \sigma$ holds is undecidable.
\end{theorem}
The proof of undecidability amounts to reducing the problem of
coercion reconstruction to A-ground theories in a
semi-Thue system, which known to be
undecidable~\cite{post_recursive_1947}.
If there exists an alternative formulation of \SFCi with fewer
explicit type equalities and is sufficient to encode all the language
features while enjoying decidable type checking is an open question.
This result is not surprising as type synthesis problem for an
arbitrary \SF term is known to be an undecidable
problem~\cite{wells_typability_1999}. The intention of \SFC
is to be used as internal language for the
compiler. The users of the language would never be required to read
the verbose code in the same way we do not expect programmers to
understand x86 assembly code.

The second observation is that the coercions are types, kinds of which
give type equalities. This characterization is novel to \SFC.
The status quo is to express coercions as
terms~\cite{sheard_meta-programming_2008,weirich_type-safe_2000,baars_typing_2002,
neis_non-parametric_2011}.
The goal of the core language is to be practical;
due to all coercions being encoded at type level, they can be erased
at runtime to generate efficient code. Another reason is
that for implementation purposes, the error term, $\bot$ which
trivially just halts the program, by throwing an exception, can be
typed at all types. If equality had been encoded at the level of types
by making coercions a term level entity, we would have an ``error
coercion'' term, $\bot :: \tau \sim \sigma$. This would require
guaranteeing that evaluating the type equality evidences does not lead
to non-termination before we evaluate the term.
Without this evaluation check we cannot use a coercion for casts while
also guaranteeing type soundness. To avoid such complications and maintain
a phase distinction \SFC follows the slogan:
\emph{Kinds are propositions for type equality, proofs are (coercion) types}


\part{III: Extensions of \SFC}\label{part:III}
\section{\SFR}\label{sec:sfr} % R for roles

\begin{figure}[ht]
\centering
\begin{minipage}{0.5\linewidth}
\begin{code}
        newtype Html           = String
        type family F a
        type instance F Html   = Bool
        type instance F String = Char
\end{code}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{flalign*}
coHtml &: \texttt{Html} \sim \texttt{String}\\
coFHS  &: \texttt{F}~\texttt{Html} \sim \texttt{Bool}\\
coFSC  &: \texttt{F}~\texttt{String} \sim \texttt{Char}\\
\end{flalign*}
\end{minipage}
\caption{Type Functions and Newtypes}
\label{fig:nt-tf-example}
\end{figure}

Consider the previously defined newtype data definition:
!newtype HTML!, and a hypothetical open type
function, !F! as shown in~\pref{fig:nt-tf-example}.
The type family instance declarations add
two new type equalities: !F Html ~ Bool! and !F String ~ Char!,
along with the type equality !Html ~ String! due to newtype declaration.
Now, using these three equalities we can derive a type
unsound coercion !Char ~ Bool!. By virtue of the type
function axiom we have !Char ~ F String!, then coercion
lifting derives !F String ~ F Html! (as !String ~ Html!),
and finally, obtain !Char ~ Bool! (by using !F Html ~ Bool!, and !F String ~ Char!):
\begin{gather*}
\texttt{Char} \sim \texttt{F\App\texttt{String}} \sim F\App\texttt{Html} \sim Bool\\
\Trans {\Trans {(\Sym coFSC)} {(F\App (\Sym{coHtml}))}} {coFHS} : Char \sim Bool
\end{gather*}
The reason for this unsound behaviour is the subtle interaction of
the two features: type functions and newtypes.
When viewed separately, as formulated in the previous section,
the consistency criteria is sufficient to guarantee soundness.
\citet{weirich_generative_2011} gives similar type unsoundness behavior
by using GADTs and newtypes. The crux of the problem is
\emph{unconstrained coercion lifting}: the use non-parametric
features (type functions, GADTs) of the language in the context that assumes
parametricity (newtypes).
 \begin{figure}[h]
 \begin{syntax}
 \text{Type Vars} &\TyVar,\beta,\Co &\qquad\text{Type constants} &\TypeConst \\
 \text{Term Vars} &x,y &\qquad\text{Newtypes} &\NType \\
 \text{Coercion Vars} &c &\qquad\text{Type Function Names} &F_n\\
                      &  &\qquad\text{Indices} &i,n \in \mathbb{N}\\
 \end{syntax}
 \begin{syntax}
   \text{Roles} &&\rho \bnfeq& \shl{\texttt{N} \bnfor \texttt{R} \bnfor \texttt{P}}\\
   \text{Kinds} &&\kappa \bnfeq& \star \bnfor \kappa \to \kappa \bnfor \shl{\sigma \sim_\rho \tau}\\
   \text{Types} &&\tau,\sigma \bnfeq& \TyVar \bnfor \mathcal{T} \bnfor
   \tau\App\tau \bnfor \Forall {\TyVar\co\kappa} \tau \bnfor \Co \\
    \text{Type Constants} &&\TypeConst \bnfeq& T \bnfor (\to) \bnfor \NType \bnfor
   F_n\many\tau\\
 \text{Coercions} &&\nu,\Co \bnfeq& c \bnfor \Refl\tau \bnfor \Sym\Co \bnfor \Trans\nu\Co % equiv relation
 \bnfor \Forall {\TyVar\co\kappa} \Co \bnfor \Co\At\tau % abstraction, instantiations
 \bnfor \nu\App\Co \\
                  &&              &\bnfor \Left \Co \bnfor \Right \Co \bnfor \Nth i \Co \bnfor \TypeConst\App\many\Co \bnfor F\many\Co \bnfor \shl{\SubCo \Co} \\  % compose/decompose
 \text{Types/Coercions} && \phi \bnfeq& \tau \bnfor \Co\\
 \text{Patterns} &&P \bnfeq& H\App \many{\beta\co\kappa}\App{\many{x\co\tau}} \\
 \text{Terms} &&M,N \bnfeq& x \bnfor \Lam {x\co\tau} M \bnfor M\App N \bnfor \TLam{\tau\co\kappa} M \bnfor M\App\phi \bnfor H \bnfor \Case M \many{P \to M} \bnfor \Cast \Tm \Co
 \end{syntax}
 \begin{syntax}

 % \text{Role Context} &&\mathcal{R} \bnfeq& \empt \bnfor \mathcal{R},\alpha\co\rho\\
                     &&\roles{\TypeConst} \bnfeq& \List{\rho \mid \alpha\co\rho, \alpha\in\Params{\TypeConst}}\\
                     &&\Params{T} \bnfeq& \List{\alpha \mid T\App\many\alpha\co\star}\\
                     &&\Params{\NType} \bnfeq& \List{\alpha  \mid \NType\App\many\alpha \co \star}\\
                     &&\Params{F_n} \bnfeq& \List{\alpha  \mid F_n\App\many\alpha^n}
 \end{syntax}
 \caption{Excerpt of Syntax of \SFR; extension of \SFC}
 \label{fig:sfr-syntax}
 \end{figure}
The key extension to \SFC
is making the type equality finer grained.
This enriches the type equality by encoding
\emph{how} the two types are equal. In the above case, we see that
we have two flavors of type equality coercions:
(i) nominal equality, which is established
via type function instances (!F String ~ Char!), and
(ii) representational equality which is established
via newtype definitions (!Html ~ String!). The type system
needs to reject unsound coercions like !F (sym coHtml) : F String ~ F Html!.

\subsection{Syntax}\label{sec:sfr-syntax}
The syntax of \SFR\cite{breitner_safe_2014, weirich_generative_2011} in shown \pref{fig:sfr-syntax}.
The highlighted portions are the extensions to \SFC.
The concept of finer grained type equality is captured by \emph{roles}, $\rho$.
Each type parameter to a type constant is decorated with a role along
with its kind. The role annotations
specify at what level the type parameter is to be compared.
The convenience function $\roles{\TypeConst}$ returns the role of
each of the type parameters of a type constant $\TypeConst$ as a sequence, $\List{\rho}$, which
preserves the order in which it occurs in its definition.

\SFR has three different roles for three different flavors of equalities:
\begin{itemize}
\item\textbf{Nominal:} The strictest kind of equality denoted by
  $\teqN$ which holds exactly when the two types are the \emph{same}.
  For example, an type function axiom !F Int = Bool!
  makes !F int $\teqN$ Bool!.
\item\textbf{Representational:} This equality holds when the two types
  have the same runtime representation.
  For example, a new type declarations !newtype Age = Int! makes
  !Age!$\teqR$!Int!
\item\textbf{Phantom:} The weakest kind of equality holds for all
  types: !a $\teqP$ b! is valid at all types !a! and !b!
\end{itemize}

For example, consider the type definitions shown in \pref{fig:datatype-roles}.
In the case of !Maybe a!, the type variable !a! is used parametrically and hence has a role !R!.
In a type function, !F a!, the type variable is used non-parametrically---the type function instances inspect
the instantiated type value---and hence has a role !N!. In the case of !DT1 a! and !DT2 a! the type variable
takes the role !N! as it occurs inside a type function, albeit deeply nested. Further, as expected,
in case of !DT3 a!, the type variable is at role !R!, but in the case of !DT4 a!, the type variable is
at role !N!. Although it is used at role !R! in the first argument to the constructor, it is used at
role !N! in the second. The role of a parameter is the least upper bound
of the role lattice due to the ordering !N < R < P!. Finally, the role of the parameter
in !DT5! is !P!, as it plays no role in the structure of the type definition.
\begin{figure}[h]
\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
data Maybe a = Nothing | Just a
type family F a

data DT1 a = MkDT1 (Maybe (F a))
data DT2 a = MkDT2 (F (Maybe a))
data DT3 a = MkDT3 (Maybe (Maybe a))
data DT4 a = MkDT4 (Maybe a) (F a)
data DT5 a = MkDT5
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
roles(Maybe) = [ R ]
roles(F)     = [ N ]

roles(DT1) = [ N ]
roles(DT2) = [ N ]
roles(DT3) = [ R ]
roles(DT4) = [ N ]
roles(DT5) = [ P ]
\end{code}
\end{CenteredBox}
\end{minipage}
\caption{Type definitions and their respective roles}
\label{fig:datatype-roles}
\end{figure}



\subsection{Static Semantics}\label{sec:sfr-static-sem}
The novel feature of \SFR, ``equality at role $\rho$'', is captured by
the coercion kinding judgements: $\CoKinding \TEnv \Co {\tau\sim_\rho\sigma}$.
It is read as ``in the type environment $\TEnv$
the coercion $\Co$, witness the equality between types $\tau$
and $\sigma$ at role $\rho$''.

\newcommand\CastRN{
  \ib{\irule[\trule{cast}]
    {\Typing \TEnv \Tm \tau}
    {\CoKinding \TEnv \Co {\tau \teqR {\tau'}}};
    {\Typing \TEnv {\Cast \Tm \Co} {\tau'}}
  }
}

\newcommand\KSubCo{
 \ib{\irule[\trule{co-sub}]
 {\CoKinding \TEnv {\Co} {\tau \teq\rho \tau'}}
 {\rho < \rho'};
 {\CoKinding \TEnv {\SubCo \Co} {\tau \teq{\rho'} \tau'}}
 }
}

\newcommand\KCoRefl{
 \ib{\irule[\trule{co-refl}]
 {\TyKinding \TEnv {\tau} {\kappa}};
 {\CoKinding \TEnv {\Refl{\tau}} {\tau \teqN \tau}}
 }
}

\newcommand\KTransCoRho{
 \ib{\irule[\trule{co-trans}]
 {\CoKinding \TEnv {\Co} {\tau \teq\rho \tau'}}
  {\CoKinding \TEnv {\Co'} {{\tau'} \teq\rho \tau''}};
 {\CoKinding \TEnv {\Trans\Co\Co'} {\tau \teq{\rho} {\tau''}}}
 }
}


\newcommand\KNthCo{
 \ib{\irule[\trule{co-nth}]
   {\CoKinding \TEnv {\Co} {T \App \many\sigma \teqR T\App\many{\tau}}}
   {\many\rho = \text{roles}(T)};
   {\CoKinding \TEnv {\Nth i \Co} {\tau_1 \teq{\rho_i} \tau_2}}
 }
}

\newcommand\KLeftCoR{
 \ib{\irule[\trule{co-left}]
 {\CoKinding \TEnv {\Co} {\tau_1 \App \sigma_1 \teqN \tau_2 \App \sigma_2}};
 {\CoKinding \TEnv {\Left \Co} {\tau_1 \teqN \tau_2}}
 }
}

\newcommand\KRightCoR{
 \ib{\irule[\trule{co-right}]
 {\CoKinding \TEnv {\Co} {\tau_1 \App \sigma_1 \teqN \tau_2 \App \sigma_2}};
 {\CoKinding \TEnv {\Right \Co} {\sigma_1 \teqN \sigma_2}}
 }
}

\newcommand\KTyAppCo{
  \ib{\irule[\trule{co-ty-app}]
    {\substack {\mathlarger {\Kinding \TEnv {\tau_1\App\sigma_1} {\kappa}}\\
               {\mathlarger {\Kinding \TEnv {\tau_2\App\sigma_2} {\kappa}}}}}
    {\substack {{\mathlarger{\CoKinding \TEnv {\Co_1} {\tau_1 \teq\rho \tau_2}}}\\
               {\mathlarger {\CoKinding \TEnv {\Co_2} {\sigma_1 \teqN \sigma_2}}}}};
    {\CoKinding \TEnv {\Co_1\App\Co_2} {\tau_1 \sigma_1 \teq\rho \tau_1 \sigma_1}}
  }
}

\newcommand\KFAppCo{
  \ib{\irule[\trule{co-F-app}]
    {F \in \TEnv}
    {\Kinding \TEnv {F\App\many{\tau}} {\kappa}}
    {\Kinding \TEnv {F\App\many{\sigma}} {\kappa}}
    {\many{\CoKinding \TEnv {\Co} {\tau \teqN \sigma}}};
    {\CoKinding \TEnv {F \many\Co} {F \many{\tau} \teqN F \many{\sigma}}}
  }
}

\newcommand\KTyConAppCo{
  \ib{\irule[\trule{co-tycon-app}]
    {\many\rho = \roles{\TypeConst}}
    {\substack {\mathlarger {\Kinding \TEnv {\TypeConst\App\many{\tau}} {\kappa}}\\
               {\mathlarger {\Kinding \TEnv {\TypeConst\App\many{\sigma}} {\kappa}}}}}
    {\many{\CoKinding \TEnv {\Co} {\tau \teq\rho \sigma}}}
    {\TypeConst \in \Set{T, \NType}};
    {\CoKinding \TEnv {\TypeConst \many\Co} {\TypeConst \many{\tau} \teqR \TypeConst\many{\sigma}}}
  }
}


\begin{figure}[ht]
 \centering
 \begin{gather*}
 \fbox{$\CoKinding \TEnv \Co {\tau\teq\rho \sigma}$}\\
 \KCoRefl \rsp \KTransCoRho \rsp \KSubCo \\
 \KNthCo \rsp \KLeftCoR \rsp \KRightCoR \\
 \KTyAppCo \rsp \KFAppCo  \\
 \KTyConAppCo
\end{gather*}
  \begin{gather*}
    \fbox{$\Typing \TEnv M \tau$}\\
    \CastRN
  \end{gather*}

 \caption{Excerpt of Static Semantics of \SFR: Coercion Calculus}
 \label{fig:sfr-typing}
\end{figure}


If two types are nominally equal, they are representationally equal as
well. Similarly, if the two types are representationally equal, they
are also equal at phantom role. This is captured in the rule \trule{co-sub}.
The rule \trule{co-refl} says that a well formed (kinded) type gives rise
to a nominal type equality. The rule \trule{co-trans} says that coercions
can be chained only if they are at the same role level. The construct $\Sym{\Co}$,
has no effect on the role of the type equality of $\Co$.
The rule \trule{co-tycon-app} builds representational type equality for newtypes and datatypes
while \trule{co-F-app} builds a nominal type equality for type functions.
The rule \trule{co-ty-app} builds a coercion between two type applications only if
the argument type, $\sigma_1\teqN\sigma_2$, is at nominal level. The rules \trule{co-left}
and \trule{co-right} work only on nominal type equality for type applications.


The rule \trule{co-nth} is restricted to non-type function types, $T$ and $\NType$.
The application of \trule{co-nth} type functions is unsound as
knowing that $F_n\many\tau \sim F_n\many\sigma$ does not give
any information about the relationship between $\many\tau$ and $\many\sigma$.
Type functions are non-injective. Although newtypes are injective, using
the rule \trule{co-nth} still poses a threat to soundess.
Consider the following definitions using !Any a! and !App f a!:

\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
data Any a = Any
newtype App f a = MkApp (f a)
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{CenteredBox}
\begin{code}
roles{Any} = $\List{P}$
App (f a) $\teqR$ f a
roles{App} = $\List{R, N}$
\end{code}
\end{CenteredBox}
\end{minipage}

Now, due to the rules of the coercion
calculus we can derive the following representational type equality:
\begin{align}\label{eqn:app-any-newtype}
  \texttt{App } \App \texttt{Any}\App \texttt{Int} \teqR \texttt{App}\App\texttt{Any} \App{Bool}\tag{app-co}
\end{align}
This is possible because of the following chain of reasoning:
\begin{align}
  \texttt{App} \App \texttt{Any}\App \texttt{Int}%
  \teqR \texttt{Any}\App \texttt{Int}%
  \teqR \texttt{Any}\App \texttt{Bool}%
  \teqR \texttt{App}\App\texttt{Any} \App{Bool}\nonumber
\end{align}
The first step and the last step of the reasoning chain is valid due to
the instantiations of the coercion axiom,
$\texttt{coApp} : \Forall{f,a}. \texttt{App}\App f\App a \teqR f\App a$.
Using the rule \trule{co-nth} will produce a unsound coercion $\texttt{Int} \teqR
\texttt{Bool}$.

Type safe casts are expressed using the rule
\trule{cast}. It is sufficient to say that the type equality
is at representational role as the terms will have
the same representation in memory at runtime and
thus also have identical behavior.

There is no change in operational semantics. Specifically, the push rules from the previous section
\pref{fig:op-sem-sfc} still hold.

\subsection{Meta-theory}\label{sec:sfr-metatheory}
The proof of progress lemma does not change with respect to \SFC as the only
additional construct is roles, which does not play any part in the
operational semantics of the language. To recall, the proof of
progress is necessary to show that the well typed terms are either
values or they can take a step.
\begin{theorem}[Progress for \SFR]\label{lem:sfr-progress}
 If $\Good \TEnv$ and $\Typing \TEnv \Tm \tau$ then, either $\Tm \in C\Val$ or, $\stepsto \Tm N$
\end{theorem}
The proof of preservation uses the formulation of coercion calculus
extended with roles. The reason for
type unsoundness in \SFC was that we allowed too many coercions with
unrestricted coercion lifting. The coercion lifting lemma in this system
is stated below:

\begin{lemma}[\SFR Coercion Lifting]\label{lem:sfr-coercion-lifting}
 If $\TyKinding {\TEnv,\TyVar\co\kappa'}\phi\kappa$, where $\TyVar$ is free in $\phi$
 and does not appear free in $\TEnv$,
 $\CoKinding\TEnv\Co{\sigma_1\teqN\sigma_2}$, and $\TyKinding\TEnv{\sigma_i}\kappa'$
 then, $\CoKinding\TEnv{\Set{\TyVar\mapsto \Co}\Refl\phi}
 {\Set{\TyVar\mapsto\sigma_1}\phi\teqN\Set{\TyVar\mapsto\sigma_2}\phi}$
\end{lemma}

As a consequence of the refined coercion lifting,
the type system disallows the unsound coercions such as\\
!F (sym coHtml) : F String $\teqN$ F Html!.
The type equality !String $\teqR$ Html! cannot be lifted through the type equality
!sym (F a) : F a $\teqN$ F a!. Finally, types are invariant with respect to the operational
semantics.

\begin{lemma}[Type Preservation for \SFR]\label{lem:sfr-preservation}
If $\Good \TEnv$ and $\Typing \TEnv \Tm \tau$ and $\stepsto \Tm \Tm'$, then $\Typing \TEnv {\Tm'} \tau$
\end{lemma}


\section{\SFK}\label{sec:sfk} % K for kind eq
\begin{figure}[h]
\begin{minipage}[ht]{0.5\linewidth}
\begin{code}
data TyRep :: forall k. k -> Type where
   TyInt  :: TyRep Int
   TyBool :: TyRep Bool
   TyList :: TyRep []
   TyApp  :: TyRep a -> TyRep b -> TyRep (a b)
\end{code}
\end{minipage}%
\begin{minipage}[ht]{0.6\linewidth}
\begin{code}
baseElem :: forall (a :: Type). TyRep a -> a
baseElem TyInt = 0
baseElem TyBool = False
baseElem (TyApp TyList _) = []
\end{code}
\end{minipage}
\caption{Representing Higher Kinded Types}
\label{fig:sfk-example}
\end{figure}
Programmers may want to encode complex constraints via GADTs. For example,
consider the datatype declaration !TyRep! and the function !baseElem!
which accepts !TyRep a! as shown in \pref{fig:sfk-example}.

In this definition of !TyRep!, the constructors !TyInt! and !TyBool! represent the base type !Int!
and !Bool!, !TyList!, represents the list type,
and !TyApp! represents type application. The !TyRep! datatype encodes only well kinded
types. The !baseElem! function takes only those !TyRep a! where !a! is of a base kind $\star$ and returns
a base element of that type. Thus, !baseElem TyBool! returns !False!,
and !(TyApp TyList _)! maps to an empty list ![]!. \SFC is incapable of encoding
the data constructors !TyList! and !TyApp! due to two reasons.
First, the !TyRep! is kind polymorphic, requiring explicit kind abstraction and
application. Second, the function implicitly uses kind equalities. In the case for !TyApp!,
the first argument is inferred to have kind !$\star$ -> $\star$! and the second argument
is inferred to have kind $\star$, making the result to be of kind $\star$.

\subsection{Syntax}\label{sec:sfk-syntax}
\begin{figure}[ht]
 \centering
 \begin{syntax}
 \text{Type Vars} &\TyVar,\beta,\Co &  & \\
 \text{Term Vars} &\TmVar,y &\qquad\text{Indices} &i,n \in \mathbb{N} \\
 \text{Coercion Vars} &c & &
 \end{syntax}
 \begin{syntax}
 \text{Type Constants} &&T \bnfeq& (\to) \bnfor \star \bnfor H\\
 \text{Type level names} &&w \bnfeq& \TyVar \bnfor F_n \bnfor T\\
 \text{Propositions} &&\Prop \bnfeq& \tau\sim\sigma\\
 \text{Types or coercions} &&\TyCo \bnfeq& \tau \bnfor \Co\\
 \text{Types and Kinds} &&\tau,\sigma,\kappa \bnfeq& w \bnfor \tau\App\tau %
 \bnfor \Forall {\TyVar\co\kappa} \tau \bnfor %
 \Forall {c\co\Prop}\tau \bnfor \Cast\tau\Co \bnfor \tau\App\Co\\
 \text{Coercions} &&\MCo,\Co \bnfeq& c \bnfor \Refl\tau \bnfor \Sym\Co \bnfor \Trans\MCo\Co \\ % equiv relation
 && \bnfor& \shl{\ForallC {\MCo} {(\TyVar_1, \TyVar_2, c)} \Co} \bnfor \shl{ \MCo\App(\Co, \Co')} %
 \bnfor \shl{\ForallC {(\MCo_1, \MCo_2)} {(c_1, c_2)} \Co} %
 \bnfor \Co\At\MCo \bnfor \shl{\Co\At(\MCo, \MCo')}\\ % abstraction instanst
 && \bnfor& \MCo\App\Co \bnfor \Left \Co \bnfor \Right \Co %
 \bnfor \Nth i \Co \bnfor \shl{\Kind \Co} \bnfor T\App\many\phi \\  % compose/decompose
 \text{Patterns} &&P \bnfeq& H\App \many{\alpha\co\kappa} \shl{\Telescope}\App{\many{x\co\tau}} \\
 \text{Telescopes} &&\Telescope \bnfeq& \empt \bnfor \Telescope, \TyVar\co\kappa \bnfor \Telescope, c\co\Prop\\
 \text{Terms} &&M,N \bnfeq& x \bnfor \Lam {x\co\tau} M \bnfor M\App N %
 \bnfor \TLam{\alpha\co\kappa} M \bnfor M\App \tau \\
 && \bnfor& \Lam {c\co\Prop} {\Tm} \bnfor \Tm\App\Co %
 \bnfor H \bnfor \Case M \many{P \to M} \bnfor \Cast \Tm \Co
 \end{syntax}
 \begin{syntax}
 \text{Typing Context} &&\TEnv \bnfeq& \empt \bnfor \TEnv,x\co\tau \bnfor \TEnv,\TyVar\co\kappa \bnfor \TEnv,H\co T \bnfor \TEnv, \Co \co \tau\sim\sigma
 % \text{Substitutions} &&\Subst \bnfeq& \empt \bnfor \Set{\many{\TyVar \mapsto \tau}}
 \end{syntax}
\caption{The Syntax of \SFK}\label{fig:sfk-syntax}
\end{figure}

The type of the data constructors in this system are of the form:
\[
    H : \Forall {\many{\alpha\co\kappa}}{\Forall{\shl{\Telescope}}{\many\tau \to T\many\alpha}}
\]
The list $\many{\alpha\co\kappa}$ are the parameters of the data constructors.
All the existential arguments to the data constructor are captured in the telescope $\Telescope$.
The existential arguments can be types or coercions.
In \SFK there is no distinction between types and kinds and thus they
can intermingle freely. The restriction on the language is that the
data constructors can only be prameterized by types which are not coercions.
For example, the type of !TyInt! and and !TyList! will be:
\begin{flalign*}
  \texttt{TyInt} &: \forall (k : \star) ~(t : k).
  \forall (coK : k \sim \star).
  \forall (co : t \sim Int).
  TyRep\App k\App t\\
  \texttt{TyList} &: \forall (k : \star) ~(t : k).
  \forall (coK : k \sim \star \to \star).
  \forall (co : t \sim []).
  TyRep\App k\App t
\end{flalign*}
In the above example, the !TyList! and !TyInt! is parameterized over the variables $k$ and $t$ while
$\Telescope = \Set{coK, co}$. While the language of types and kinds is exactly the same, and there is
no distinction between them, we will informally use the type as a classifier for terms and
kinds as a classifier for types.

\newcommand\TContra{
 \ib{\irule[\trule{t-contra}]
 {\CoKinding \TEnv {\Co} {T\App\many\phi \sim T'\App\many{\phi'}}}
 {T \neq T'}
 {\Kinding \TEnv {\tau} {\star}};
 {\Typing \TEnv {\Contra \Co\tau} {\tau}}
 }
}

\newcommand\KCAppCo{
 \ib{\irule[\trule{co-capp}]
 {\CoKinding \TEnv {\Co} {\tau\sim\tau'}}
 {\Typing \TEnv {\tau\App\MCo} {\kappa}}
 {\Typing \TEnv {\tau'\App\MCo'} {\kappa'}};
 {\CoKinding \TEnv {\Co\App(\MCo, \MCo')} {\tau\App\MCo \sim \tau'\App\MCo'}}
 }
}

\newcommand\KCAllT{
 \ib{\irule[\trule{co-$\I{\forall\tau}$}]
 {\substack{ \mathlarger{\CoKinding {\TEnv,\TyVar\co\kappa,\TyVar'\co\kappa',c\co\TyVar\sim\TyVar'} {\Co} {\tau\sim\tau'}}\\
 \mathlarger{\Kinding \TEnv {\Forall {\TyVar\co\kappa} {\tau}} {\star}}}}
 {\substack{ \mathlarger{\CoKinding \TEnv \MCo {\kappa\sim\kappa'}}\\
 \mathlarger{\Kinding \TEnv {\Forall {\TyVar'\co\kappa'} {\tau'}} {\star}}}};
 {\CoKinding \TEnv {\ForallC\MCo{(\TyVar,\TyVar',c)}{\Co}} {\Forall {\TyVar\co\kappa}{\tau} \sim \Forall {\TyVar'\co\kappa'}{\tau'}}}
 }
}

\newcommand\KCAllC{
 \ib{\irule[\trule{co-$\I{\forall\Co}$}]
 {\substack{\mathlarger{\CoKinding {\TEnv,c\co\Prop,c'\co\Prop'} {\Co} {\tau\sim\tau'}} \\
 \mathlarger{\Kinding \TEnv {\Forall {c\co\Prop} {\tau}} \star}%
 \quad\mathlarger{\Kinding \TEnv {\Forall {c'\co\Prop'} {\tau'}} \star}
 }}
 {\mathlarger{\fresh {\Set{c, c'}}{\Erased\Co}}}
 {\substack{\mathlarger{\CoKinding \TEnv {\MCo_1} {\sigma_1 \sim \sigma_1'}}\\
 \mathlarger{\CoKinding \TEnv {\MCo_2} {\sigma_2 \sim \sigma_2'} }}}
 {\substack{\mathlarger{\Prop = \sigma_1\sim\sigma_2}\\
 \mathlarger{\Prop' = \sigma_1'\sim\sigma_2'}}};
 {\CoKinding \TEnv {\ForallC{(\MCo_1,\MCo_2)}{(c, c')} {\Co}} {\Forall {c\co\Prop}{\tau} \sim \Forall {c'\co\Prop'}{\tau'}}}
 }
 }

\newcommand\KCInstCo{
 \ib{\irule[\trule{co-$\E{\forall\Co}$}]
 {\CoKinding \TEnv {\Co} {\Forall {c\co\Prop} {\tau} \sim \Forall {c'\co\Prop'} {\tau'}}}
 {\CoKinding \TEnv \MCo \Prop}
 {\CoKinding \TEnv {\MCo'} \Prop'};
 {\CoKinding \TEnv {\Co\At(\MCo, \MCo')} {\Set{c\mapsto\MCo}\tau \sim \Set{c'\mapsto\MCo'}\tau'}}
 }
}

\newcommand\KExtCo{
 \ib{\irule[\trule{co-ext}]
 {\CoKinding \TEnv {\Co} {\tau \sim \tau'}}
 {\CoKinding \TEnv \tau \kappa}
 {\CoKinding \TEnv {\tau'} \kappa'};
 {\CoKinding \TEnv {\Kind \Co} {\kappa \sim \kappa'}}
 }
}

\newcommand\KCoCo{
 \ib{\irule[\trule{co-Coh}]
 {\CoKinding \TEnv {\Co} {\tau \sim \tau'}}
 {\Kinding \TEnv {\Cast \tau \Co'} \kappa};
 {\CoKinding \TEnv {\Cast \Co {\Co'}} {\Cast {\tau} {\Co'} \sim \tau'}}
 }
}

\newcommand\KTyCast{
 \ib{\irule[\trule{Ty-Cast}]
 {\TyKinding \TEnv {\tau} \kappa}
 {\CoKinding \TEnv \Co {\kappa \sim \kappa'}}
 {\TyKinding \TEnv {\kappa'} \star};
 {\TyKinding \TEnv {\Cast \tau {\Co}} {\kappa'}}
 }
}

\newcommand\PropEq{
 \ib{\irule[\trule{Prop-Eq}]
 {\Kinding \TEnv \tau   {\kappa}}
 {\Kinding \TEnv \sigma {\kappa'}};
 {\TEnv \vdash_p {\tau \sim \sigma} {\texttt{~ok}}}
 }
}

\newcommand\TyKCo{
\ib{\irule[\trule{Ty-$\forall\Co$}]
{\TyKinding {\TEnv, c\co\phi} {\tau} {\star}}
{\TEnv \vdash_p {\phi} {\texttt{~ok}}};
{\TyKinding \TEnv {\Forall {c\co\phi} \tau} {\star}}
}
}

\newcommand\KTypeInType{
  \ib{\irule[\trule{Ty-star}]
   {};
   {\TyKinding \TEnv \star \star}
  }
}


\subsection{Static Semantics}\label{sfk-static-sem}
\begin{figure}[ht]
 \centering
 \begin{gather*}
   \fbox{$\CoKinding \TEnv \Co {\tau \sim \tau}$}\\
 \KExtCo \rsp \KCoCo\\
 \KCAllT\\
 \KCAllC\\
 \KCAppCo \rsp \KCInstCo
 \end{gather*}
\begin{minipage}{0.5\linewidth}
\begin{gather*}
 \fbox{$\TyKinding \TEnv \tau \kappa$}\\
   \TyKCo \rsp \KTypeInType \\ \KTyCast
 \end{gather*}%
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{gather*}
  \fbox{$\TEnv \vdash_p \Prop \texttt{~ok}$}\\
  \PropEq
\end{gather*}
\end{minipage}
 \caption{Excerpt of Static Semantics of \SFK}
 \label{fig:sfk-typing}
\end{figure}
Coercions are the proof terms which inhabit the propositional type equality kind $\tau \sim \sigma$.
The !kind! construct makes the hetrogenous type equality possible by extracting (or building)
the kind equality coercion from a type equality coercion by $\trule{co-ext}$.
Similar to \SFC the type equality is an equivalence relation and it can also
be decomposed using the $\Nth i \Co$ rules.
The system enforces proof irrelevance by not having any judgement for equality between two coercion proofs.
This enables the system to trivially consider all coercions to be equivalent.
The propositional equality check $\trule{Prop-Eq}$ ensures that the type equality is between two well-formed types.
The coherence rule, $\trule{co-Coh}$, says that kind coercions can be ignored while proving type equality.

The rule \trule{co-$\I\forall$} in \SFC required that the kind of the quantified variable had
to be syntactically equal. In \SFK, as seen in \trule{$co-\I{\forall\tau}$}, that is no longer the case.
It is possible that the variables have different kinds, but there is a coercion that makes them equal.
The rule \trule{co-$\I{\forall\Co}$} is analogus to \trule{$co-\I{\forall\tau}$} but for coercions.
However, due to proof irrelevance, there is no proof witness required to show $c$ and $c'$ are equal.


\subsection{Operational Semantics}\label{sfk-op-sem}
\newcommand\Context[1]{\texttt{context}({#1})}
\newcommand\Extend[1]{\texttt{extend}({#1})}

\newcommand{\HPushSFK}{
 \ib{\irule[\trule{S-KPush}]
 {\substack{\mathlarger{H \co \Forall {\many{\TyVar\co\kappa}}%
               {\Forall \Telescope \many{\sigma} \to T\App\many\TyVar}}\\
            \mathlarger{\phi' = \Psi_2(\dom\Telescope)}\\
             \mathlarger{\many{\tau'} = \Psi_2(\many\TyVar)}
 }}
 {\substack{\mathlarger{\Psi = \Extend{\Context\Co ;\many\phi; \Telescope}}\\
 \mathlarger{\many{\Tm'} = \many{\Cast {\Tm} \Lift{\sigma}}}}};
 {$\stepsto {\Case {(\Cast {H\App \many\tau\App \many\phi\App\many\Tm} \Co)} {\many{\Ptrns \to N}} }
            {\Case {H\App \many{\tau'}\App \many{\phi'}\App\many{\Tm'}} {\many{\Ptrns \to N}} }$}
 }
}

\begin{figure}[ht]
\centering
\begin{gather*}
\HPushSFK
\end{gather*}
\caption{Excerpt of Operational Semantics of \SFK}
\label{fig:sfk-op-sem}
\end{figure}
Most of the operational semantics for \SFK is carried over from \SFC.
The most interesting rule of the system is $\trule{S-KPush}$
which transforms a data constructor applied
to a cast into an ``equivalent'' data constructor by pushing the cercions in the arguments.
This is achieved by using the lifting operation.
\begin{definition}[Lifting operation, $\Lift -$]
The lifting operation is defined inductively on the type structure:
\begin{flalign*}
  \Lift \alpha &= \Co \text{~when~} a\co\kappa \mapsto (\tau_1, \tau_2, \Co) \in \Psi\\
  \Lift \tau &= \Refl\tau \text{~when~} \fresh{\tau}{\dom{\Psi}}\\
  \Lift {\tau\App\sigma} &= \Lift{\tau}\Lift{\sigma}\\
  \Lift {\tau\App\Co} &= \Lift{\tau}(\Psi_1(\Co),\Psi_2(\Co))\\
  \Lift{\Forall {\TyVar\co\kappa}{\tau}} &= \forall_{\Psi(\kappa)}(\alpha_1,\alpha_2, c). \Psi'(\tau)\\
               &\text{where~} \Psi' = \Psi, \alpha\co\kappa \mapsto (a_1, a_2, c) \text{~and~} \fresh{\Set{\alpha_1, \alpha_2, c}}\Psi \\
  \Lift{\Forall {\Co\co\sigma_1\sim\sigma_2}{\tau}} &= \forall_{(\Psi(\sigma_1), \Psi{\sigma_2})}(c_1,c_2). \Psi'(\tau)\\
               &\text{where~} \Psi' = \Psi, \alpha\co\sigma_1\sim\sigma_2 \mapsto (a_1, a_2, c) \text{~and~} \fresh{\Set{c_1, c_2}}\Psi\\
  \Lift{\Cast\tau\Co} &= \Cast{\Lift\tau}{\Cast{\Sym(\Cast{(\Sym\Co)}{\Psi_1(\Co)})}{\Psi_2(\Co)}}
\end{flalign*}
\end{definition}
The lifting operation, $\Lift - $, is a generalized version of lifting
defined to fomalize \SFC (\pref{def:sfc-coercion-lifting}).
The lifting context, $\Psi$, is built using the function $\Context{\Co}$.
\begin{definition}[Lifting Context Creation, $\Context{\Co}$]
If $\CoKinding \TEnv \Co {T\App\many\tau \sim T\App\many\sigma}$, and $T\co\Forall{\many{\alpha\co\kappa}} \co \star \in \TEnv$
then
\[ \Context{\Co} = \many{\alpha_i\co\kappa_i \mapsto (\tau_i, \sigma_i, \Nth i \Co)}\]
\end{definition}

Intuitively, $\Context{\Co}_1(\tau)$ replaces all the occurances of $\alpha$ in $\tau$
with the corresponding ``from'' type and $\Context{\Co}_2(\tau)$ replaces all the occurances of $\alpha$
in $\tau$ with the corresponding ``to'' type. The extend operation, $\Extend{\Psi;\many\phi;\Telescope}$
extends the initial context $\Psi$ with the coercions present in the existential parameters
of the data constructor telescope.
\begin{definition}[Lifting Context Extension, $\Extend{\Psi;\many\phi,\Telescope}$]
\begin{flalign*}
  \Extend{\Psi; \empt; \empt} &=\Psi\\
  \Extend{\Psi; \many\phi,\tau ; \Telescope, \alpha\co\kappa} &= \Psi',\alpha\co\kappa \mapsto (\tau, \Cast \tau \Psi'(\kappa), \Co')\\
                              &\text{where~} \Psi' = \Extend{\Psi; \many\phi; \Telescope},~%
                                \Co' = \Sym(\Cast {\Refl\tau} {\Psi'(\kappa)})
  \\
  \Extend{\Psi; \many\phi,\Co ; \Telescope, c\co\tau\sim\sigma} &= \Psi',c\co\tau\sim\sigma \mapsto (\Co, \Co')\\
                              & \text{where~} \Psi' = \Extend{\Psi; \many\phi; \Telescope},~%
                                \Co' = \Trans{\Sym{(\Psi'(\tau))}} {\Trans \Co {\Psi'(\sigma)}}
\end{flalign*}
\end{definition}


As an illustration of how the lifting context aids the push rule consider the example:

\begin{CenteredBox}
\begin{code}
Cons (T Bool) x xs /> $\Co$
\end{code}
\end{CenteredBox}

where, $\texttt{Cons} \co \Forall {k\co\star, a\co k} {\Forall {co\co k\sim \star}{a \to [a] \to [a]}}$,
!$\Co$ : [T Bool] ~ [Int]!, and !T! is a type constant. The lifting context in this case:
\[\Context\Co = \Set{ a\co\kappa \mapsto (\texttt{T~Bool}, \texttt{Int}, \Nth 1 \Co)}\]
and the extension will be:
\[\Psi = \Extend{\Context\Co} = \Set{a\co\kappa \mapsto (\texttt{T~Bool}, \texttt{Int}, \Nth 1 \Co), co\co\kappa\sim\star \mapsto (coK, \Refl{\star})}\]
 And thus,

\begin{CenteredBox}
\begin{code}
    Cons k (T Bool) coK x xs /> $\Co$
$\stepsto{}{}$ Cons $\star$ Int ($\Refl{\star}$) (x /> $\Psi(a)$) (xs /> $\Psi([a])$)
\end{code}
\end{CenteredBox}

\begin{lemma}[Coercion lifting Lemma]\label{lem:sfk-coercion-lifting}
If $\Psi$ is a valid lifting context for $\TEnv$ and the telescope $\Telescope$,
and $\TyKinding {\TEnv,\Telescope} \tau \kappa$ then
\[ \CoKinding {\TEnv} {\Psi(\tau)} {\Psi_1(\tau) \sim \Psi_2(\tau)} \]
\end{lemma}


\subsection{Meta-theory}\label{sfk-meta-theory}
With all the machinery built to allow kind hetrogenous equalities, it remains to argue whether
the system still enjoys type safety.

\begin{lemma}[Preservation for \SFK]\label{lem:sfk-preservation}
If $\Good\TEnv$, $\Typing \TEnv \Tm \tau$  and $\stepsto \Tm \Tm'$ then $\Typing \TEnv {\Tm'} \tau$
\end{lemma}
The proof is inspection of all the rules and making sure that the operational semantics rules
do not change the type of the reduced term. The push rules are the most interesting rule to analyze.
To ensure the push rules preserve types it is enough to check that erasure of type (an coercion) annotations
from the term has no effect on the operational semantics.

\begin{lemma}[Progress for \SFK]\label{lem:sfk-progress}
If $\Typing \TEnv \Tm \tau$ and $\Tm$ is not $C\Val$, and $\TEnv$ is a closed, consistent context, then
there exists a $\Tm'$ such that $\stepsto \Tm {\Tm'}$
\end{lemma}

The consistency criteria for the typing environment is captured using $\Good\TEnv$ and \SFC. It is
more involved as \SFK is more complex than its predecessor systems.
The proof proceeds in two steps: first, showing that the kind erasure does not interfere with
semantics of types then second, the type erasure does not interfere with term semantics.
There are some types in the system which are equal but cannot be proven so within the system.
For example the two types $\Forall {c_1\co Int \sim b} Int$ and $\Forall {c_2\co Int \sim b} b$ are equal,
but the system cannot prove them to be equal. Such incompleteness is a non-issue as the the surface level
syntax disallows writing type equalities of the form $(Int \sim b) \then Int \sim (Int \sim b) \then b$
and these equalities are quite exotic.

\SFK is a significantly more expressive type system than its predecessors. It achieves this by squashing
the distinction between types and kinds. The judgement $\Kinding \TEnv \star \star$,
or the type in type axiom, is one of the kinding axioms.
It is usually responsible to creep inconsistencies in logics.
However, \SFK is no more inconsistent than \SFC, where all kinds are inhabited.
The typechecking problem for \SFK is decidable and all the terms are explicitly type annotated.
and the type equalities are always accompanied with a finitely sized equality proof.
The system also maintains a distinction between the (equality)
proofs and objects. This allows proofs to be independent of any computational value.

\part{IV: The Path Ahead}\label{part:IV}
\section{Future Work}\label{sec:future-work}
\begin{figure}[ht]
\begin{minipage}{0.4\linewidth}
\begin{CenteredBox}
\begin{code}
class Con e c | c ~> e where
  empty :: FORALL e c. Con e c => c
  extend :: FORALL e c. Con e c => e -> c -> c

instance Con Int [Int] where
  empty = ...
  extend = ...
\end{code}
\end{CenteredBox}
\end{minipage}%
\begin{minipage}{0.6\linewidth}
\begin{CenteredBox}
\begin{code}
type family FDCon c : *
empty : FORALL c. Con (FDCon c) c => c
extend : FORALL c. Con (FDCon c) c => e -> c -> c

axiom coFDConLIntInt : FDCon [Int] ~ Int
empty_[Int]  : Con [Int] (FDCon [Int]) => Int
extend_[Int] : Con [Int] (FDCon [Int]) => Int -> [Int] -> [Int]

\end{code}
\end{CenteredBox}
\end{minipage}
\caption[FunDeps in \SFC]{Elaborating Functional Dependencies into \SFC}
\label{fig:elab-fundeps-sfc}
\end{figure}
Functional dependencies introduce
uniqueness criteria for a subset of the multiparameter type classes.
We may expect obtaining a natural encoding of functional dependencies
via the mechanism of open type functions. In this encoding scheme,
each functional dependency induces a special
type function that relates the determiner of the functional dependency
to the determinant. Each typeclass instance introduces an axiom that
encodes this mapping. Further, every type that mentions the
determinant of the functional dependency gets replaced by the type
function. For example, as shown in \pref{fig:elab-fundeps-sfc},
!Con e c! gets converted to !Con (FCCon c) c!. While this encoding is
sound, and works for simple cases, it does not cover all the use cases.
Consider a specialized case of containers, !UCon con!, for unsorted containers,
where the container does not enforce any ordering on the elements.

\begin{CenteredBox}
\begin{code}
class Con elem con => UCon con
\end{code}
\end{CenteredBox}

Representing the typeclass constraints in a first order predicate logic, we get the following
(seemingly broken) formula as the type variable !elem! is out of scope:
\[
\Forall{con}{\texttt{UCon}\App con \then \texttt{Con}\App elem\App con}
\]
The intended meaning of the class declaration is:
whenever we have an evidence that says the typeclass constraint
!UCon con! is satisfied, we can also assume, or produce, an
evidence for typeclass constraint !Con elem con!.
Although it may seem that the type parameter
!elem! is free in this definition, it is uniquely
determined due to the functional dependency, !con ~> elem!.
The type parameter !con! is existentially
bound, as made explicit in the formula below:
\[
\Forall{con}{\texttt{UCon}\App con \then \Exists{\bang elem}\texttt{Con}\App con\App elem}
\]
To tackle this problem, \citet{karachalias_elaboration_2017} develop an
elaboration scheme for typeclass and instance declarations which
elaborates functional dependencies to type equality axioms in \SFC. However,
their work does not provide an explanation of the general theory of
the simplifying and improvement of types~\cite{jones_simplifying_1995},
as functional dependencies may introduce partial type
refinements. Functional dependencies remain a type inference level
artifact and have no evidence at the level of \SFC.
The consequence of the incomplete encoding of functional
dependencies is reflected in the compiler implementation.
For example, issues with functional dependencies interacting
poorly with type families\footnote{GHC Issue \#11534:
  \url{https://gitlab.haskell.org/ghc/ghc/-/issues/11534}},
GADTs\footnote{GHC Issue \#345:
  \url{https://gitlab.haskell.org/ghc/ghc/-/issues/345}},
and furthermore, causing non-confluence issues in the GHC constraint
solver \footnote{GHC issue \#18851:
  \url{https://gitlab.haskell.org/ghc/ghc/-/issues/18851}}.
These issues degrade the programmer's experience by
obscure type errors, and worse the type checker
is unnecessarily more restrictive than required.

\begin{figure}[ht]
  \centering
\begin{tikzpicture}[->,>=stealth,auto,
roundnode/.style={circle, draw=green!60, fill=green!5, very thick, minimum size=8mm},
squarednode/.style={rectangle, draw=red!60, fill=red!5, very thick, minimum size=8mm},
node distance=1.5cm
]

%Nodes
\node[squarednode]      (centercirc)  {$\substack{Typed\\Intermediate\\ Language}$};
\node[roundnode]        (leftcirc)    [left=of centercirc] {$\substack{Functional\\Dependencies}$};
\node[roundnode]        (rightcirc)   [right=of centercirc] {$\substack{Type\\Functions}$};

%Lines
\draw[dashed, -{Stealth[length=3mm, width=2mm]}] (leftcirc.east)  -- (centercirc.west);
\draw[dashed, -{Stealth[length=3mm, width=2mm]}] (rightcirc.west) -- (centercirc.east);

\draw[-{Stealth[length=3mm, width=2mm]}] (leftcirc.north)  to
[out=30,in=150] (rightcirc.north) node[midway, above=1.6cm] {\cite{karachalias_elaboration_2017}};
\draw[-{Stealth[length=3mm, width=2mm]}] (rightcirc.south) to
[out=210,in=340] (leftcirc.south) node[midway, below=1.6cm] {\cite{jones_language_2008}};
\end{tikzpicture}
  \caption[Open Problem]{Open Problem: Compiling Functional Dependencies and Type
    Functions to a typed Intermediate Language}
  \label{fig:future-work}
\end{figure}


An important research problem is to solve the tension between
functional dependencies and type families by having a uniform
treatment of both in a typed intermediate language as shown in \pref{fig:future-work}.
In the next section we go over language extensions, some of which
are implemented in GHC, while others are proposals to improve the programmer experience.

\section{Related Work}\label{sec:related-work}
%%%%%%%%%
\subsection{Instance Chains}
Instance chains~\cite{morris_instance_2010} enable finer grained
control of which instance should be used to satisfy
a typeclass constraint. The instances for !Show! typeclass defines how
a value can be converted to a string:

\begin{CenteredBox}
\begin{code}
type String = [Char]
class Show a where show :: a -> String
class Show a => Show [a] where show = ...
class Show String where show = ...
\end{code}
\end{CenteredBox}
If we know how to write a !show! function for any value of a particular
type, we can write a generic instance of show on a list of such types.
However, we may want to override this behavior for some specific
instances. For example, the type !String! in GHC is declared as a
type synonym for a list of !Char!---(!type String = [Char]!).
The typechecker now has two ways of resolving the typeclass
constraint !Show String!: it can either use the generic instance via
!Show [Char]!, or it can use the specific instance !Show String!. The
typechecker has no way cannot decide which instance is more appropriate.
Such instances are called \emph{overlapping instances}.
Haskell disallows overlapping instances as this gives rise to
incoherence issues\cite{jones_coherence_1993}.
Instance chains solves this problem by allowing programmers
to specify in what order the the instances can be resolved. It also
subsumes closed typeclasses by providing a capability to express
a default failure clause in an instance chain declaration.

\begin{CenteredBox}
\begin{code}
instance Show String where show s = ...
else instance Show a => [a] where show s = ...
else fail
\end{code}
\end{CenteredBox}

\subsection{Type Functions}\label{sec:rw-type-fun}
\subsubsection{Closed type families}
The programmer may want to write type functions which has a restricted
extension. For example, the previously defined !Add! type
function is defined only on !Z! and !S n! types. Closed type
families~\cite{eisenberg_typefamilies_2014} help in
expressing such use cases. For example, consider the code snippet shown below:

\begin{CenteredBox}
\begin{code}
type family Add m n where
  Add (S m) n = S (Add m n)
  Add _ n = n
\end{code}
\end{CenteredBox}

An additional advantage is that the programmer can also define a
default case handler (!Add _ n = n!) for such type function
definitions. This declaration is inexpressible using open type
functions as the axioms which are introduced by type function
instances are order independent: the order in which the instances
are declared is independent of the order in which they are searched by
the solver. Writing closed type functions is very similar to writing case
statements at term level. The difference is that instead of writing
equations for terms, the user write equations for types. While this
makes the system expressive and helps in making error messages related
to type functions more user friendly, closed type families with
non-linear type patterns---such as, !Add x x!---are reducible to
term rewriting theories\cite{mizuhito_rta_1995}, which are conjectured
to guarantee confluence. The meta-theory needs to appeal to infinitary
unification~\cite{jaffar_efficient_1984} of types to claim
consistency. This is unsatisfactory, as Haskell does not have
infinite types.

\subsubsection{Injective type famililes}
Type functions are non-injective by default. It can be a useful
programming idiom to declare a type function to be injective so that
the typechecker can use this information to rule out programs which
violate the property. Further, the typechecker can also use this
property to refine the type information. For example, consider an
injective type function !F! declared to be injective below:

\begin{CenteredBox}
\begin{code}
type family F a = r | r ~> a
type instance F Int = Char
type instance F Bool = Int
\end{code}
\end{CenteredBox}
This syntax is a direct inspiration from functional dependencies for
typeclasses. The declaration !r ~> a! says that the result of the type
function !r!, can uniquely determine the argument of the type family
!a!. Now, during type checking the instances of type functions, the
typechecker would reject any axiom which would make !F!
non-injective. For example, in the above code, the declaration
!type instance F Char = Char! would be rejected by the typechecker. Further
while trying to solve a wanted type equality constraint such as,
!F a ~ Char!, the typechecker can leverage the fact that !F! is injective,
and hence, there can be only one solution for the equation: !a ~ Int!,
thus aiding the solver with extra information to solve the original
wanted constraint. Injective type families~\cite{stolarek_injective_2015}
can be extended for closed type families as well.
The key change in terms of formalization is to relax the rule \trule{co-nth}
from \pref{fig:sfr-typing} to allow decomposing injective type family applications.
The formalization however, still has to assume that
the type rewriting is terminating for proving consistency.

\newcommand\KNthCoInj{
 \ib{\irule[\trule{co-nth}]
   {\CoKinding \TEnv {\Co} {\mathcal{T} \App \many\sigma \teqR \mathcal{T} \App\many{\tau}}}
   {\mathcal{T} \in \Set{T, F} (\text{F is injective})};
   {\CoKinding \TEnv {\Nth i \Co} {\tau_1 \teq{\rho_i} \tau_2}}
 }
}
\[ \KNthCoInj \]



\subsubsection{Constrained Type Families}
Constrained type families~\cite{morris_typefamilies_2017} allows type
computation to proceed only when the type family application can be
provably reduced to a ground type. This simplifies the meta-theory of
the language significantly. Constrained type families can prove
confluence of type rewriting hence gives stronger type soundness
guarantees. It avoids the pitfall of having to prove consistency by
resorting to the use of infinitary unification and a conjecture to
prove consistency as done in the meta theory of closed type families.
Closed type classes, which otherwise would need
special infrastructure, fall out naturally in this system. The
formalized system however, does not have a corresponding  working
implementation\footnote{GHC Proposal: \url{https://github.com/typedrat/ghc-proposals/blob/constrained-type-families/proposals/0000-simple-constrained-type-families.rst}}.

% \subsubsection{Partial Type Constructors}
% Consider the associated type appearing as type argument within a data
% constructor:

% \begin{CenteredBox}
% \begin{code}
% data E a = MkE (Elem a)
% \end{code}
% \end{CenteredBox}

% GHC designers ignore the question of whether typechecking
% an instance of an element of !E a! should check for satisfaction of
% the associated !Con a! typeclass. This makes the type system restrictive as to
% ensure safety, certain typeclass abstraction machinery cannot be used
% leverage coding patterns such as the constrained monad
% problem~\cite{sculthorpe_constrained-monad_2013} or its generalized
% version, the constrained typeclass problem. Partial type
% constructors~\cite{jones_partial_2019,ingle_partial_2022} explores the language design
% space which takes into consideration such type partiality while
% allowing a simple and elegant solution to the constrained typeclass problem.

\section{Conclusion}\label{sec:conclusion}
\begin{figure}[ht]
 \centering
 \begin{tabular}[ht]{c | c}
 Parametric Features                    & Non-parametric Features \\
 \hline\hline
   \multirow{2}*{Modules~\cite{macqueen_modules_1984}}    & {Typeclasses~\cite{wadler_polymorphism_1989}}\\
                                        & \emph{Functional Dependencies}~\cite{jones_tcfd_2000}\\
   \hline
   ADTs~\cite{burstall_hope_1980}         & \emph{GADTs}~\cite{cheney_first-class_2003}\\
   \hline
   \multirow{3}*{\emph{Newtypes}~\cite{breitner_safe_2014}}
                                        & \emph{Open Type Functions}~\cite{schrijvers_type_2008}\\
                                        & Closed Type Functions~\cite{eisenberg_typefamilies_2014},\\
                                        & \emph{Associated types}~\cite{chakravarty_associated_2005}
 \end{tabular}
 \caption{Features of Haskell}
 \label{fig:haskell-lang-features}
\end{figure}
We surveyed some important language features--the ones which functional
programmers prefer---and seen in depth, a theoretical
foundation of a modern day declarative functional programming
language. The language features are tabulated in the
\pref{fig:haskell-lang-features}.
There are two ways of supporting a new programming language
feature, either via encoding them with the help of libraries or, via
supporting them as a core language feature. In the latter scenario, we
realized that composing different language features is non-trivial and
their subtle interactions can threaten semantic consistency. We
first identified that the three seemingly different language features:
newtypes, generalized algebraic datatypes and type
functions can be encoded using a simple single construct: type
equality. We then showed how non-parametric features
interacting with parametric features of the language that contain
explicit type equalities can cause type unsoundness bugs.
Along the way we saw how the the type system evolved
with different flavors of type equality: \SFC has a primitive notion defining when two
types are equal, but \SFR, and \SFK make the type equality relation
more refined. Taming ad-hoc language features requires
sophisticated proof techniques to formalize and argue about their
correctness. As new programming languages are designed, built and
used, it is not only important to identify and carry over the good design principles
established by theory using the formalization techniques, but also
strengthen the foundational theory of programming languages
by understanding the real requirements of practice.

%\newpage
%%%% Bibliography
\bibliography{comp}%%%%%%%%%


% \part{V: Appendix for Proofs, Definitions, and Thorny Bushes}\label{part:appendix}


% % \begin{theorem}[Coercion Lifting]\label{thm:sfc-coercion-lifting-appendix}
% %  If $\TyKinding {\TEnv,\TyVar\co\kappa'}\phi\kappa$, where $\TyVar$ is free in $\phi$
% %  and does not appear free in $\TEnv$, and
% %  $\CoKinding\TEnv\Co{\sigma_1\sim\sigma_2}$, and $\TyKinding\TEnv{\sigma_i}\kappa'$
% %  then, $\CoKinding\TEnv {\Sub{\TyVar}{\Co}\Refl{\phi}}
% %  {\Set{\TyVar\mapsto\sigma_1}\phi\sim\Set{\TyVar\mapsto\sigma_2}\phi}$
% % \end{theorem}
% \begin{proof}[\pref{thm:sfc-coercion-lifting}]\label{proof:thm-sfc-coercion-lifting}
% By induction on the structure of the derivation of the well kinded
% types we have the following cases:

% \begin{itemize}
% \item[\trule{ty-var}] $\alpha$: It is a well formed type (assumption), the coercion
%   substitution is well formed (assumption), so the claim holds,
%   $\TyKinding \TEnv {\Sub{\alpha}{\Co}\Refl{\alpha}}
%   {\Sub{\alpha}{\sigma_1}\alpha \sim \Sub{\alpha}{\sigma_2}\alpha}$.
%   If the type variable is not $\alpha$, the substitution has no effect
% \item[\trule{ty-con}] $T$ is a constant, so the substitution does not
%   have any effect.
% \item[\trule{ty-fcon}] $F\App{\many\sigma}$: By
%   induction principle application on the well kinded type arguments
%   $\many{\TyKinding \TEnv \sigma \kappa}$
% \item[\trule{ty-all}] $\Forall{\alpha\co\kappa}{\tau}$:
%   after necessary renaming gymnastics to avoid variable capture,
%   induction hypothesis with weakening applies to $\TyKinding {\TEnv,\alpha\co\kappa} \tau \kappa$
% \item[\trule{ty-app}] $\tau\App\sigma$: substitution distributes
%   over the type application and induction on the derivations of
%   $\TyKinding \TEnv \tau {\kappa \to \kappa'}$
%   and $\TyKinding \TEnv \sigma {\kappa}$
% \end{itemize}
% \end{proof}


% \begin{example}
%     Derivation tree for elaborating !Value 0 :: Int!

%    $\TEnv = Value : \Forall {a\co\star} {a \sim Int \then Int \to GAlgExp\App a}$

%   \[\hspace{-10em}
%     \ib{\irule[\trule{$\E\to$}]
%         {\ib{\irule[\trule{g-$\E C$}]
%            {\ib{\irule[\trule{g-$\E\forall$}]
%                 {\ib{\irule[\trule{g-var}]{};
%                     {\GTranslate C \TEnv {Value} {\Forall {a} {a \sim Int \then Int \to GAlgExp\App a}} {Value}}}};
%                 {\GTranslate C \TEnv {Value} {Int \sim Int \then Int \to GAlgExp\App Int} {Value \App Int}}}}
%            {\CoKinding C {\Refl{Int}} {Int \sim Int}};
%            {\GTranslate C \TEnv {Value} {Int \to GAlgExp\App Int} {Value \App Int\App \Refl{Int}}}}};
%         {\GTranslate C \TEnv {Value\App 0} {GAlgExp\App Int} {Value\App Int\App \Refl{Int}\App 0}}}
%   \]
% \end{example}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% eval: (visual-line-mode 1)
%%% eval: (auto-fill-mode 1)
%%% eval: (tex-source-correlate-mode 1)
%%% eval: (flyspell-mode 1)
%%% TeX-command-extra-options: "--synctex=1"
%%% TeX-master: "comp.tex"
%%% TeX-master: t
%%% End:
