\newif\ifcomments\commentstrue

\RequirePackage[svgnames,dvipsnames,prologue,x11names]{xcolor}

\documentclass[manuscript,screen,nonacm]{acmart}

\usepackage{comp}

\title{Practical Functional Programming in \SFC and its extensions}
% \subtitle{Extensions to System F}

\author{Apoorv Ingle}
%\orcid{0000-0002-7399-9762}
\affiliation{%
  \institution{University of Iowa}
  \department{Department of Computer Science}
  \streetaddress{McLean Hall}
  \city{Iowa City}
  \state{Iowa}
  \country{USA}}
% \keywords{typeclass, type family}

\begin{document}
\begin{abstract}
The following report is a juxtaposition of the series of extensions to \SFC and its theoretical developments. We begin with a brief description of \SF in a type intrinsic setting and give some context about its importance and its meta-theoretic properties. We then move on to describe the first extension to \SF, \SFC, that enriches the calculus with explicit type equalities. The repercussions of this extension is extensive as it enables arbitrary type level computation. \SFC is then extended to \SFP with an expressive kind---the type of types---system that enables an even more expressive type level computation. Finally, we discuss \SFK which enables expressing kind level equalities along with existing type level equalities in the system by effectively squashing the distinction between types and kinds.

While the theoretical aspects of each of these systems are of academic importance, for these systems to be useful as a practical programming language, we want to expose this power to the programmers---the end users of these systems---, without compromising on saftey and a usability. We describe a framework \HMX that parameterizes over the feature domain X such that for each of the systems described above we get a type inference algorithm for free, meaning, we do not have to redesign and reimplement them.

We conclude the report with some open problems in the area.
\end{abstract}
\maketitle

% \pagestyle{plain}

\newcommand\STLC{\textbf{STLC}\xspace}
\newcommand\cy[1]{[\citeyear{#1}]}
\section{\SF}
\subsection{History and Inception}
Simply typed lambda calculus (\STLC) was devised by \citet{church_formulation_1940} to avoid the paradoxes that are possible in untyped lambda calculus. \STLC, in its bare form has three constructs: Variables, lambda abstractions and applications. Lambda abstractions and applications are devices to model functions and function calls respectively. Simple types, however, makes the system too restrictive. Consider an identity function that takes an argument of some base type, say $i$, and returns it unchanged.
$$
id_\alpha = \Lam {x\co \alpha} x
$$
In \STLC, although the function behavior is the same at each base type, there would be a different identity function for each such base type. Further, if a new base type is introduced in the system, we would have to define a new identity function for it. Functions, such as identity, are said to be parametrically polymorphic\cite{strachey_fundamental_2000} when their behavior does not change depending on the type of the arguments.

To give a better account for such parametric functions, \citet{reynolds_towards_1974} proposed an extension of \STLC which later famously became \SF. Reynolds extension to \STLC is straightforward. It contains two extra syntactic constructs: type abstractions and type applications. This extension is simple enough to express parametric functions. For example, the identity function will be expressed as follows:
$$
id = \TLam \alpha \Lam {x\co\alpha}. x
$$
\begin{figure}[ht]
  \centering
  \begin{syntax}
    \text{Type Vars} &&\alpha,\beta,\gamma \\
    \text{Term Vars} &&x,y          \\
  \end{syntax}
  \begin{syntax}
    \text{Kinds}     &&\kappa       &::= \star \mid \kappa \to \kappa\\
    \text{Types}     &&\tau,\sigma  &::= \alpha \mid T \mid \tau \to \tau \mid \tau\App\tau \mid \syntaxhl{\Forall {\alpha\co\kappa} \tau}\\
    \text{Terms}     &&\Tm,N          &::= x \mid  H \mid \Lam {x\co\tau} M \mid M\App N \mid \syntaxhl{\TLam{\tau\co\kappa} M \mid M\App \tau}\\
  \end{syntax}
  \begin{syntax}
    \text{Typing Context} &&\TEnv &::= \empt \mid \TEnv,x\co\tau \mid \TEnv,\alpha\co\kappa \mid \TEnv,H\co T\\
    \text{Substitutions}  &&\Subst
  \end{syntax}
  \caption{\SF as an extension of \STLC with kinds}
  \label{fig:system-f-syntax}
\end{figure}

\newcommand\KVar{
  \ib{\irule[\trule{k-var}]
    {\alpha\co\kappa \in \TEnv};
    {\Kinding \TEnv \alpha \kappa}}
}

\newcommand\KVarCo{
  \ib{\irule[\trule{co-var}]
    {c \co \sigma\sim\tau \in \TEnv};
    {\Kinding \TEnv c \sigma\sim\tau}}
}


\newcommand\KConst{
  \ib{\irule[\trule{k-const}]
    {T\co\kappa \in \TEnv};
    {\Kinding \TEnv T \kappa}}
}

\newcommand\KTApp{
  \ib{\irule[\trule{k-tapp}]
    {\Kinding \TEnv {\tau_1} {\kappa_1 \to \kappa}}
    {\Kinding \TEnv {\tau_2} {\kappa_1}};
    {\Kinding \TEnv {\tau_1\App \tau_2} \kappa}}
}


\newcommand\TVar{
  \ib{\irule[\trule{var}]
    {x\co\tau \in \TEnv}
    {\Kinding \TEnv \tau \kappa};
    {\Typing \TEnv x \tau}}
}

\newcommand\TConst{
  \ib{\irule[\trule{const}]
    {H\co T \in \TEnv};
    {\Typing \TEnv H T}}
}

\newcommand\TAbs{
  \ib{\irule[\trule{$\I\to$}]
    {\Typing {\TEnv, x\co\tau_1} {\Tm} {\tau_2}};
    {\Typing \TEnv {\Lam x \Tm} {\tau_1 \to \tau_2}}}
}

\newcommand\TApp{
  \ib{\irule[\trule{$\E\to$}]
    {\Typing \TEnv {\Tm_1} {\tau_2 \to \tau}}
    {\Typing \TEnv {\Tm_2} {\tau_2}};
    {\Typing \TEnv {\Tm_1\App\Tm_2} {\tau}}}
}

\newcommand\TForallI{
  \ib{\irule[\trule{$\I\forall$}]
    {\Typing {\TEnv,\alpha\co\kappa} \Tm \tau}
    {\alpha \not\in \dom\TEnv};
    {\Typing \TEnv {\TLam {\alpha\co\kappa} \Tm} {\Forall{\alpha\co\kappa}\tau}}
  }
}

\newcommand\TForallE{
  \ib{\irule[\trule{$\E\forall$}]
    {\Typing \TEnv \Tm {\Forall{\alpha\co\kappa}\sigma}}
    {\Kinding \TEnv \tau \kappa}
    {\Subst = \Sub \alpha \tau};
    {\Typing \TEnv {\Tm\App\tau} {\Subst\sigma}}
  }
}

\begin{figure}[ht]
  \begin{gather*}
    \fbox{$\Kinding \KEnv \tau \kappa$}\\
    \KVar \rsp \KConst \rsp \KTApp
  \end{gather*}

  \centering
  \begin{gather*}
    \fbox{$\Typing \TEnv \Tm \tau$}\\
    \TVar \rsp \TConst\\
    \TAbs \rsp \TApp\\
    \TForallI \rsp \TForallE
  \end{gather*}

  \caption{Static Semantics of \SF}
  \label{fig:sf-typing}
\end{figure}

\newcommand{\SOPL}{P$_2$\xspace}
This extension from \STLC makes the semantics extremely powerful. \citet{girard_interpretation_1972}, about two years before Reynolds, proved the Representation theorm ($\mathcal{G}$), that says: all total functions on natural numbers in the second order propositional logic (\SOPL) can be expressed in \SF. \citet{reynolds_types_1983} formulated the Abstraction theorem ($\mathcal{R}$) that proves \SF is an embedding of \SOPL and \citet{wadler_girard-reynolds_2001} later showed that the abstraction followed by embedding is an identity transformation.

\begin{figure}[ht]
  \centering
    \begin{tikzpicture}
    \draw (0, 0) circle [x radius=0.5, y radius=1];
    \node [label=above:\SF] (f2) at (0, 2) {};

    \begin{scope}[xshift=3cm]
      \draw (0, 0) circle [x radius=0.7, y radius=1.5];
      \draw[dotted] (0, 0) circle [x radius=0.5, y radius=1];
      \node [label=above:\SOPL] (p2) at (0, 2) {};
    \end{scope}
  \end{tikzpicture}
  \caption{Relationship between \SF and \SOPL}
  \label{fig:sf-p2-relation}
\end{figure}


\section{Features of Typed Functional Programming Languages}\label{sec:language-features}
\subsection{User Defined Datatypes}
Organizing data into a logical fashion is important aspect of any programming language. The domain elements are mapped on to structures that store information. The business logic of the domain is then just transformations of the structures from one form to the other. In functional programming languages, algebraic datatypes are the essential way to define new structures.

\subsubsection{Algebraic Datatypes}
Algebraic Datatypes (ADT) can be viewed as a composite datatype. They are composed of named sums of products. They enhance the expressivity of the language by allowing users to declare their own structures and aid in organizing data. For example, a balanced binary tree in Haskell can be declared as follows:

\begin{code}
  data Tree c = Leaf c | Branch (Tree c, Tree c)
\end{code}

The keyword \lstinline{data} introduces a user defined type with name \lstinline{Tree} parameterized over any type !c!. A value of type !Tree c! can be defined using either a !Leaf! or a !Branch!, and in the case of !Branch!, it consists of a pair of !Tree!s. !Leaf! and !Branch! are called as data constructors, while !Tree! is called as a type constructor. It is important to observe that the structure the datatype does not dependent on the type parameter !c!, i.e. it is used parametrically. More specifically, the structure of !Tree Int! and !Tree Float! will be the same.

\subsubsection{Generalized Algebraic Datatypes}
As the name suggests, they are generalizations of algebraic datatypes where the structure of the type can depend on the type arguments. We use the term type index for GADTs rather than type parameter in algebraic datatype. They were first introduced by \citep{cheney_first-class_2003} as first class phantom types and later studied under different name such as guarded recursive datatypes\cite{xi_guarded_2003}. Such Their utility is in modelling domain specific languages where certain constraints can be enforced by the type checker. Consider an example to model a generic !Trie k v! datatype that represents a finite mapping from keys of type !k! to values of type !v!.

\begin{figure}[ht]
  \centering
  \begin{minipage}[ht]{0.4\linewidth}
    \begin{code}
      data Trie k v where
          TSingle :: Maybe v -> Trie () v
          TSum    :: Trie k1 v -> Trie k2 v
                  -> Trie (Either k1 k2) v
          TProd   :: Trie k1 (Trie k2 v)



    \end{code}
  \end{minipage}%
  \begin{minipage}[ht]{0.5\linewidth}
    \begin{code}
      lookup :: Trie k v -> k -> Maybe v
      lookup (TSingle m) ()         = m
      lookup (TSum ta tb) (Left a)  = lookup ta a
      lookup (TSum ta tb) (Right b) = lookup tb b
      lookup (TProd ta) (a, b)      = case (lookup ta a) of
                                         Nothing -> Nothing
                                         Just b -> lookup tb b
    \end{code}
  \end{minipage}
  \caption{Trie datatype as GADT}
  \label{fig:gadt-example}
\end{figure}


\begin{figure}[ht]
  \centering
  \begin{minipage}[ht]{0.5\linewidth}
    \begin{code}
data LamTm a where
  Var :: String -> LamTm a
  Lam :: (LamTm a -> LamTm b) -> LamTm (a -> b)
  App :: LamTm (a -> b) -> LamTm a -> LamTm b
    \end{code}
  \end{minipage}%
  \begin{minipage}[ht]{0.5\linewidth}
    \begin{code}
      eval :: LamTm a -> LamTm a
      eval (App (Lam f) a) = f a

      
    \end{code}
  \end{minipage}
  \caption{Expressing Lambda Terms as GADT}
  \label{fig:gadt-example}
\end{figure}
Writing an !eval! function for a !LamTm a! would be impossible if it were not for the constrainted type arguments of data constructors !Lam! and !App!. The only way of 

\subsubsection{Generative Types}
\subsection{From Parametric Polymorphism to Ad-hoc Polymorphism}
In contrast to the term \lstinline{id}, consider the following two terms:
\begin{code}
    t1 :: Int = 1 + 2
    t2 :: Float = 1.1 + 2.3
\end{code}

In the first case we see that the operator \lstinline{+} is applied to two integers, but in the second case it is applied to two floating point numbers. Although the programmer uses the same symbol, the meanings of each of the programs is completely different. One adds two \lstinline{Int} and returns an \lstinline{Int} while the other adds two \lstinline{Float} and returns a \lstinline{Float}. Further, the compiled code for each would also be different. The runtime code would make a call to two different built in constructs. Such kind of function reuse, which is dependent on the context or the type of arguments, is called as ad-hoc polymorphism\cite{strachey_fundamental_2000}. Implicit operator overloading is a general mechanism to impliment ad-hoc polymorphism where the compiler resolves the overloaded operator to the actual operator.

To make implicit overloading practical \citet{wadler_polymorphism_1989} proposed a dictonary passing style by using a mechanism. This technique became the foundation for Haskell\cite{haskell_2010} typeclasses. Kaes\cy{kaes_parametric_1988} had similar ideas related to implimentation aspects of ad-hoc polymorphism before Wadler et al. ML and its varients\cite{milner_definition_1997,leroy_ocaml_2023} takes a more restricted approach and refuses to allow operator overloading by design.

Implicit objects\cite{oliveira_typeclasses_2010} provide a mechanism for users to choose the intended behavior instance if there are multiple available options. This pushes the burden of choosing the right instance on programmer whenever the typechecker cannot figure out the right option or when the user wants to force the typechecker to resolve it to a specific instance.

Various attempts\cite{dreyer_modular_2007, wehr_ml_2008, white_modular_2014} have been made to enable a happy co-existence of parametric and implicit ad-hoc polymorphism together in a language by encoding typeclasses as modules and vice versa. However, in presense of modularity to support separate code compilation, it becomes impossible to avoid incoherence without cripling the language expressibility.

\subsection{Typeclasses}
\subsubsection{Operator overoading}
Typeclasses can be viewed as relations over types and every instance declaration extends that relation. Consider a typeclass \lstinline{Ord a} shown in \pref{fig:tc-ord}. It represents a unary relation for the types whose values can be compared. Instances of the typeclass \lstinline{Ord} are written \lstinline{Ord Int} and \lstinline{Ord Float} say that \lstinline{Float} and \lstinline{Int} belong to the unary relation \lstinline{Ord}.

%% Something about methods

\begin{figure}[ht]
  \centering
  \begin{minipage}[ht]{0.3\linewidth}
    \begin{code}
      class Ord a where
         (<)  :: a -> a -> Bool
         (<=) :: a -> a -> Bool
    \end{code}
  \end{minipage}%
  \begin{minipage}[ht]{0.3\linewidth}
    \begin{code}
      class Ord Int where
         (<)  = int_le
         (<=) = int_leq
    \end{code}
  \end{minipage}%
  \begin{minipage}[ht]{0.3\linewidth}
    \begin{code}
      class Ord Float where
         (<)  = le_float
         (<=) = leq_float
    \end{code}
  \end{minipage}
  \caption{\lstinline{Ord} typeclass and instances}
  \label{fig:tc-ord}
\end{figure}
\subsubsection{Multi-Parameter Typeclasses and Functional Dependencies}
A straightforward generalization of single parameter typeclases is multiparameter typeclasses. It naturally extends the idea of having n-ary propositions or relations over types. Such relations can be useful to express properties such as containment relations. For example, following\cite{jones_tcfd_2000}, a typeclass to unify different containers under a single interface can be defined using a !Coll e c! typeclass, as shown in \pref{fig:tc-collection}. One can imagine having instances for such a typeclass as \lstinline{Coll Int [Int]}, \lstinline{Coll Float (BST Float)} etc. Speaking in terms of relations, we say that \lstinline{(Int, [Int]) $\in$ Coll} and similarly \lstinline{(Float, BST Float) $\in$ Coll}.

\begin{figure}[ht]
  \centering
  \begin{minipage}[ht]{0.3\linewidth}
    \begin{code}
      class Coll e c
      where
         empty :: c
         insert :: e -> c -> c
    \end{code}
  \end{minipage}%
  \begin{minipage}[ht]{0.3\linewidth}
    \begin{code}
      class Coll Int [Int]
      where
         empty = ...
         insert = ...
    \end{code}
  \end{minipage}%
  \begin{minipage}[ht]{0.3\linewidth}
    \begin{code}
      class Coll Float (BST Float)
      where
         empty = ...
         insert = ...
    \end{code}
  \end{minipage}
  \caption[Collection typeclass]{\lstinline{Collection} typeclass and its instances}
  \label{fig:tc-collection}
\end{figure}

The use of \lstinline{empty} in a polymorphic setting however interferes with the compilation decision. It is not enough to determine what the type of \lstinline{e} should be just by knowing the type \lstinline{c}. Such types are called ambiguous types. Formally speaking, if a type variable only appears in the constraints of the type it is called an ambiguous type. The type of !empty!, !FORALL e c. Coll e c => c!, is ambiguous due to the occurance of !e! only the constraint. Such types do not have a well defined semantics as the compiler cannot make a unique choice of what the compiled code should be. The problem is here is that the typeclasses are relations and hence are too general for this use case. To make typeclasses behave in a more constrained way, Jones introduced functional dependencies\cite{jones_tcfd_2000}. The insight is to be able to specify the functional nature of relations, i.e. to be able to say if we \emph{know} certain type parameters of the typeclass, we can \emph{determine} the other type parameters as well.

\begin{figure}[ht]
  \begin{center}
    \begin{code}
      class Coll e c | c ~> e where
          empty :: c
          extend :: e -> c -> c
    \end{code}
  \end{center}
  \caption[Collection typeclass]{\lstinline{Collection} Typeclass with Functional Dependency}
  \label{fig:tc-collection-fd}
\end{figure}

The extra annotation !c ~> e! on the typeclass !Coll e c! as shown in \pref{fig:tc-collection-fd} says that !e! can be uniquely determined for given a !c!.
We call !c! to be the determiner and !e! to be the determinant of the functional dependency.

% improvement, simplification
%

\subsection{Type Functions}
\subsubsection{Associated Types}
The main reason to have multiparameter type classes with functional dependencies was to enable the type system to express type functions. In other words, if the determiner type variables of the functional dependency determine the determinant type variables, then it would be syntactically pleasing to write them in a function form.
Using our previous !Coll c e! example, if !c ~> e! then, it would be more obvious to the programmers to instead write !Elem c! instead of !e!, where !Elem c! is a special type function that takes in a type and returns a type. This effectively gives an alternative route to express functional dependencies.
\begin{figure}[ht]
  \begin{center}
    \begin{minipage}[ht]{0.4\linewidth}
      \begin{code}
        class Coll c where
           type Elem c
           empty :: c
           extend :: Elem c -> c -> c
      \end{code}
    \end{minipage}%
    \begin{minipage}[ht]{0.4\linewidth}
      \begin{code}
        instance Coll [Int] where
           type Elem [Int] = Int
           empty = ...
           extend = ...
      \end{code}
    \end{minipage}
  \end{center}
  \caption[Collection typeclass]{\lstinline{Coll} Typeclass with Type Function}
  \label{fig:type-fam}
\end{figure}

In \pref{fig:type-fam}, the typeclass !Coll! has an associated type function !Elem! that depends on the type parameter !c! of the typeclass. 

\subsubsection{Open Type Functions}
There is nothing special about type functions to only be associated with classes. Type functions are able to express complex type level computations. Further, they are also open, meaning, just like class instances, the open type functions can be extended. An example of how type computations is expressed by type functions that define addition of naturals at type level, shown in \pref{fig:open-type-fun-add}
\begin{figure}[ht]
  \begin{minipage}[ht]{0.4\linewidth}
    \begin{code}
      data Z
      data S n
    \end{code}
  \end{minipage}%
  \begin{minipage}[ht]{0.4\linewidth}
    \begin{code}
      type family Add m n
      type instance Add Z n = n
      type instance Add (S m) n = S (Add m n)
    \end{code}
  \end{minipage}
  \caption{Addition with type functions}
  \label{fig:open-type-fun-add}
\end{figure}
Open type functions thus give type computation a flavor of rewrite rules.
\subsubsection{Closed Type Functions}
There maybe cases where the type functions have to be restricted extensions. For example The previously defined
!Add! type function is supposed to be defined only on !Z! and !S n! types. Closed type families help in this situtation. 
\begin{figure}[ht]
  \begin{minipage}[ht]{0.4\linewidth}
    \begin{code}
      type family Add m n where
          Add Z n = n
          Add (S m) n = S (Add m n)
    \end{code}
  \end{minipage}
  \caption{Addition with type functions}
  \label{fig:closed-type-fun-add}
\end{figure}

\subsection{Modules and Packages}
Modularity in code is essential to maintain separation of concerns. It is a good sofware practice organize related things together, while unrelated things separate. Modules are a way to do that. 

\subsection{Intrinsic Typing vs Extrinsic Typing} % Principal typing
Intrinsic typing: When the type is tied together with its term. This makes typechecking easy as there is not really any inference bit to peform but makes terms ``rigid''. This rigidity has philosophical implications.
Extrinsic: The type is loosly tied with the term.

Principal typing: Given a term one can infer the most general type for that term.
as a decision problem, infering a principal type for a term in general is undecidable.
System F has undecidable type inference\cite{wells_typability_1999}.

But not all hope is lost. Hindley-Milner (HM) type system, which is a restriction of System F, has a decidable type inference algorithm. HM is expressive enough for most practical programming purposes; ML and Haskell are all based on HM type systems.
Various works have tried to find the sweat spot of what is the minimal type annotation needed for the type inference.
The idea is that we need to reduce the programmer burden of writing down the types where it is ``obvious''.
Philosophically, if the system has a principal typing property then the distinction between intrinsic types and extrinsic types disappers as we can use an algorithm to infer the type of the term and decorate the original term with the infered types to recover the intrinsic term. In a sense, there is a galois connection between the intrinsic term and its extrinsic counterpart. The type inference mapping takes an term from extrinsic to an intrinsic while type erasure mapping takes an extrinsicly typed term to intrinsicly typed term

% \subsection{Treatment of Equalities}
% There are two ways of remembering type equalities that the typechecker would have proved or the ones provided by the user: Store them as terms or store them as types. Both of them seem to be equally attractive however they have significant computational differences

% Storing them as term makes the type equality coercions explicit in the code, helps type checking. For a proof assistant it would be an attractive feature, but for a programming language it would mean that we carry such
% type equality proofs into the compiled language. Dynamic type dispatch is a an important application for being able to carry proofs about type equalities.

% Storing them as types has an advantage that we can erase the equality proofs before compiling it to a more efficient runtime representation. After all, type equalities are only really needed by the type checker to prove that nothing will go wrong at runtime. At runtime we don't need it.
%  Intensional vs extensional % Intensional vs Extensional typing


\section{\SFC}\label{sec:sfc}
The Glasgow Haskell Compiler (GHC)\cite{ghc_2020}, is a widely used Haskell\cite{haskell_2010} compiler. Its inception was a result of a lack of a test bed for lazy strongly typed functional programming languages. It is an industry grade compiler, meaning the compiler generated code can perform with efficiency comparable to other language compilers like Java or C++. The original core language of GHC was based on \SF. However, it soon became clear that with the addition of GADTs and generative types, using pure \SF would be too cumbersome, if not impossible to express in some constructs. For example consider a generative type declaration
\begin{code}
  newtype Fun = MkFun (Fun -> Fun)
\end{code}
The intension of this declaration is to make !Fun! and !Fun -> Fun! be isomorphic, however, it there was no good way to encode this in pure \SF. GHC relied on a hack to express this in the core language.
\SFC\cite{sulzmann_system_2007} was desiged and implimented to solve this problem. In the following sections we take a look of the core language, followed by how it can be used to encode all the features discussed in \pref{sec:language-features}. 
% In one statment: \SFC is an intensional intrinsically typed programming language.
% It is intensional, meaning each term encodes its typing derivation, and it is intrinsically typed, meaning all the terms are index by types.

% Some key points to cover:

% Store the equality between types explicitly in the AST during type checking.

% New feature: coercion is a type and its kind tells us what types does the coercion equate.

% Features that can be directly expressed in \SFC: New types or generative types, associated types, functional dependencies, generalized algebraic datatypes (GADTs).

% Brand new feature user defined open type functions.

% Makes type rewriting complicated. But makes the type system more expressive by making it extensible.
% Proving type soundness is a bit more involved now.

% why don't we have a rule that says: if $\sigma_1 \sim \sigma_2$ then

\subsubsection{Syntax}
\begin{figure}[ht]
  \centering
  \begin{syntax}
    \text{Type Vars} &\alpha,\beta,\gamma  &\text{Type constants} &T \\
    \text{Term Vars} &x,y                  & & \\
    \text{Coercion Vars} &c & &
  \end{syntax}
  \begin{syntax}
    \text{Kinds}     &&\kappa       &::= ... \mid \sigma \sim \tau\\
    \text{Types}     &&\tau,\sigma  &::= ... \mid F_n\\
    \text{Coercions} &&\nu,\Co      &::= c \mid \refl\tau \mid \sym\Co \mid \trans\nu\Co % equiv relation
                                        \mid \Forall {\alpha\co\kappa} \Co \mid \Co\At\tau % abstraction instanst
                                        \mid \nu\App\Co \mid \left \Co \mid \right \Co \\  % compose/decompose
    \text{Types and Coercions} && \phi &::= \tau \mid \Co\\
    \text{Terms}     &&M,N  &::= ... \mid \Case K \overline{P} \mid \Cast \Tm \Co\\
    \text{Patterns}  &&P    &::= x \to M
    \end{syntax}
    \begin{syntax}
    \text{Typing Context} &&\TEnv &::= \empt \mid \TEnv,x\co\tau \mid \TEnv,\alpha\co\kappa \mid \TEnv,H\co T \mid \TEnv, \gamma \co \tau\sim\sigma\\
    \text{Substitutions}  &&\Subst
    \end{syntax}
  \caption{\SFC as an extension of \SF}
  \label{fig:system-fc-syntax}
\end{figure}
\SFC is impredicative; there is no stratification between polytypes and monotypes. Unlike \SFw, there are no lambdas at type level this makes the type level calculus less expressive by disallowing certain types such as $\Lam a (a, a)$. The system does allow higher kinded types---which can be built in or user defined---that can be used by the type application form $\tau\App\tau$. \AI{what is the difference between $\Forall a (a, a)$ and $\Lam a. (a, a)$?} The value type constructors $T$ ranges over built-in types such as !Int! and user defined types such as algebraic datatypes. Declaration of algebraic datatypes also introduces data constructors $H$, the types of which are of the form:
$$
H \co \Forall {\overline{\alpha\co\kappa}\overline{\beta\co\kappa}} \overline{\sigma} \to T \overline\alpha
$$
Here the type variables $\overline\alpha$ appear in the same order as in the algebraic datatype delcarations,  and type variables $\overline\beta$ are the existential, that do not appear in the return type, but may appear in the argument types $\overline\sigma$. The existential type variables $\overline\beta$ play a useful in encoding GADTs.

The type equality coercion, $\gamma$, is the essential additional construct. Coercions are types and have a ``cannonical'' form of $\tau\sim\sigma$. They can be constructed, applied, passed around as arguments using the special coercion infrastructure at the level of types. They appear at term level in the form of casts $\Cast M \gamma$. For type theory enthusiasts, type coercions should be thought of as extensional type equality, meaning, if a term $M$ has a type $\tau$ and we have a type coercion $\tau\sim\sigma$, then the type cast $\Cast M  {\tau\sim\sigma}$ says that $M$ can be treated as if it has type $\sigma$. The soundness property of the type system guarantees that after the types (including casts) have been erased, the program will not crash or get stuck. Unlike other regular types, however, coercions do not classify values, i.e. there are no term level constructs that have a type $\tau\sim\sigma$. This is similar to how in \SFw there are no values of a type that has a kind $\STAR\to\STAR$.

\SFC supports a full fledged coercion calculus where each syntactic construct corresponds to a logical equation. The most basic type of coercion can be produced by using the reflexivity construct $\refl\tau$. It says that the type $\tau$ witness the (obvious) fact that it is equal to itself. The other constructs on coercions are symmetry '$\sym\gamma$', transitivity '$\trans {\gamma_1}{\gamma_2}$', which together with $\refl\tau$, makes type equality an equivalence class. Coercions can also be composed and decomposed using the '$\Co_1\Co_2$', and '$\leftc\Co$' and '$\rightc\Co$' constructs respectively, Finally, coercion abstraction '$\Forall {\alpha\co\kappa}\tau$' and coercion application '$\Co\At\tau$' aids equality reasoning on polytypes.

\subsection{Static Semantics}

\newcommand\TCast{
  \ib{\irule[\trule{cast}]
    {\Typing \TEnv {\Tm} {\tau}}
    {\Typing \TEnv \gamma {\tau \sim \sigma}};
    {\Typing \TEnv {\Cast \Tm \gamma} {\sigma}}
  }
}

\newcommand\KReflCo{
  \ib{\irule[\trule{co-refl}]
    {\Typing \TEnv \tau \kappa};
    {\Typing \TEnv {\refl \tau} {\tau \sim \tau}}
  }
}

\newcommand\KSymCo{
  \ib{\irule[\trule{co-sym}]
    {\Typing \TEnv \gamma {\tau \sim \sigma}};
    {\Typing \TEnv {\sym \gamma} {\sigma \sim \tau}}
  }
}

\newcommand\KTransCo{
  \ib{\irule[\trule{co-trans}]
    {\Typing\TEnv {\gamma_1} {\tau \sim \tau_2}}
    {\Typing\TEnv {\gamma_2} {\tau_2 \sim \sigma}};
    {\Typing\TEnv {\trans {\gamma_1} \gamma_2} {\tau \sim \sigma}}
  }
}

\newcommand\KInstCo{
  \ib{\irule[\trule{co-$\E\forall$}]
    {\Typing\TEnv \gamma {\Forall\alpha\tau_1 \sim \Forall\beta\tau_2}}
    {\Subst_1 = \Sub\alpha\sigma}{\Subst_2 = \Sub\beta\sigma};
    {\Typing\TEnv {\gamma\At\sigma} {\Subst_1\tau_1 \sim \Subst_2\tau_2}}
  }
}

\newcommand\KForallCo{
  \ib{\irule[\trule{co-$\I\forall$}]
    {\Typing {\TEnv,\alpha\co\kappa} \gamma {\tau_1 \sim \tau_2}}{\alpha \# \TEnv};
    {\Typing \TEnv {\Forall {\alpha\co\kappa} \gamma} {\Forall {\alpha\co\kappa}\tau_1 \sim \Forall {\alpha\co\kappa}\tau_2}}
  }
}


\newcommand\KCoComp{
  \ib{\irule[\trule{co-comp}]
    {\Typing \TEnv {\gamma_1} {\tau_1 \sim \tau_2}}
    {\Typing \TEnv {\gamma_2} {\sigma_1 \sim \sigma_2}}
    {\Typing \TEnv {\tau_i \sigma_i} \kappa};
    {\Typing \TEnv {\gamma_1 \gamma_2} {\tau_1 \sigma_1 \sim \tau_2 \sigma_2}}
  }
}

\newcommand\KLeftCo{
  \ib{\irule[\trule{co-left}]
    {\Typing \TEnv {\gamma} {\tau_1 \App \sigma_1 \sim \tau_2 \App \sigma_2}};
    {\Typing \TEnv {\left \gamma} {\tau_1 \sim \tau_2}}
  }
}

\newcommand\KRightCo{
  \ib{\irule[\trule{co-right}]
    {\Typing \TEnv {\gamma} {\tau_1 \App \sigma_1 \sim \tau_2 \App \sigma_2}};
    {\Typing \TEnv {\right \gamma} {\sigma_1 \sim \sigma_2}}
  }
}

\newcommand\KCastCo{
  \ib{\irule[\trule{co-leftc}]
    {\Typing \TEnv \gamma {\kappa_1 \then \tau_1 \sim \kappa_2 \then \tau_2}};
    {\Typing \TEnv {\Cast {\gamma_1} \gamma_2} {\tau_1 \sim \tau_2}}
  }
}

\newcommand\KCoAx{
  \ib{\irule[\trule{co-ax}]
    {\Typing \TEnv \gamma {\kappa_1 \then \tau_1 \sim \kappa_2 \then \tau_2}};
    {\Typing \TEnv {\Cast {\gamma_1} \gamma_2} {\tau_1 \sim \tau_2}}
  }
}


\begin{figure}[t]
  \centering

  \begin{gather*}
    \fbox{$\Typing \TEnv M \tau$}\\
    \TCast
  \end{gather*}

  
  \begin{gather*}
    \fbox{$\Kinding \KEnv \tau \kappa$}\\
    \KReflCo \rsp \KSymCo \rsp \KTransCo \\
    \KForallCo \rsp \KInstCo \\
    \KCoComp \\
    \KLeftCo \rsp \KRightCo \\
  \end{gather*}

  \caption{Excerpt of Static Semantics of \SFC}
  \label{fig:sf-typing}
\end{figure}

\newcommand{\Beta}{
  \ib{\irule[\trule{$\beta$}]
    {};
    {$\stepsto {(\Lam {x\co\tau} M) \App N} {\Set{x\mapsto N}M}$}
  }
}
\newcommand{\TBeta}{
  \ib{\irule[\trule{Ty-$\beta$}]
    {};
    {$\stepsto {(\TLam \alpha M) \App \tau} {\Set{\alpha\mapsto \tau}M}$}
  }
}
\newcommand{\CaseE}{
  \ib{\irule[\trule{case}]
    {asdf};
    {asdf}
  }
}
\newcommand{\CoTransE}{
  \ib{\irule[\trule{Co-Trans}]
    {};
    {$\stepsto {\Cast {(\Cast \Val \Co)} {\nu}} {\Cast \Val {(\trans{\Co} {\nu})}}$}
  }
}

\newcommand{\TPush}{
  \ib{\irule[\trule{ty-push}];
    % {\Co : {\Forall {c\co\kappa} \tau} \sim \Forall {c\co\kappa} \tau'};
    {$\stepsto {(\Cast{\TLam {\alpha\co\kappa} M}\Co)\App \tau} {({\TLam {\alpha\co\kappa} (\Cast M {\Co\At\alpha})})\App \tau}$}
  }
}

\newcommand{\CoPush}{
  \ib{\irule[\trule{co-push}]
    {\LARGE\substack {\nu\co \sigma_1' \sim \sigma_2'\\
                      \Co_1 : \sigma_1 \sim \sigma_1' = \left {(\left \Co)}}}
    {\LARGE\substack {\Co\co (\sigma_1 \sim \sigma_2 \then \sigma_3) \sim (\sigma_1' \sim \sigma_2' \then \sigma_3')\\
                     {\Co_2: \sigma_2 \sim \sigma_2' = \right{(\left\Co)}\quad{\Co_3:\sigma_3\sim\sigma_3' = \right\Co}}}};
    {$\stepsto {(\Cast{\TLam {\alpha\co(\sigma_1\sim\sigma_2)} M}\Co)\App \nu} {\Cast {(\TLam {\alpha\co(\sigma_1\sim\sigma_2)} M)\App (\Co_1 \circ \nu \circ \sym \Co_2)} {\Co_3}} $}
  }
}

\newcommand{\Push}{
  \ib{\irule[\trule{push}]
    {\Co : \tau_1 \to \tau_2 \sim \tau_1' \to \tau_2'}
    {\Co_1 = \right (\left \Co)}
    {\Co_2 = \right \Co};
    {$\stepsto {({\Cast {\Lam x M} {\Co}}) \App N} {\Cast {(({\Lam x M})\App {(\Cast N {\sym \Co_1})})} \Co_2}$}
  }
}

\newcommand{\KPush}{
  \ib{\irule[\trule{h-push}]
    {};
    {$\stepsto {\Cast {(\Cast \Val \Co_1)} {\Co_2}} {\Cast \Val {\trans{\Co_1} {\Co_2}}}$}
  }
}



\begin{figure}[ht]
  \centering
  \begin{syntax}
    \text{Plain Values} && \Val  &::= \Lam {x\co\tau} M \mid \Forall {\alpha\co\kappa} M \mid H\\
    \text{CValues}      && C\Val &::= \Val \mid \Cast \Val \Co\\

    \text{Evaluation Contexts} &&  \EvalCtxt &::= \EvalCtxtHole{-} \mid \EvalCtxt\App M \mid \EvalCtxt \tau \mid \Cast \EvalCtxt \Co \mid \Case \EvalCtxt {\overline{P}}\\
  \end{syntax}

  \begin{gather*}
    \fbox{$\stepsto M N$}\\
    \Beta \rsp \TBeta\\
    \CaseE \rsp \CoTransE\\
    \TPush \rsp \CoPush\\
    \Push \rsp \KPush
  \end{gather*}

  \caption{Operational Semantics of \SFC}
  \label{fig:op-sem-sfc}
\end{figure}


To formalize our intuitions of how the coercions ought to behave, we provide static semantics in the form of standard typing and kinding rules in \pref{fig:sf-typing}. To start off the \trule{cast} transforms a term $M\co\tau$ to a term $M\co\sigma$ with a witness coercion $\Co\co\tau\sim\sigma$

As all the coercions are types such that their kinds give us the type equality, the coercion calculus is part of the kinding rules. The typing rules \trule{co-refl}, \trule{co-sym}  and \trule{co-trans} makes equality of types an equivalence relation. The rule \trule{co-comp} enables lifting coercions for higher kinded types and reason equalities between them. As a simple example of why coercion composition is useful, consider a higher kinded algebraic type !Tree! and a coercion $\Co\co\sigma_1\sim\sigma_2$, then using $\tau_1$ and $\tau_2$ to be equal to !Tree!, we have that $\refl{\texttt{Tree}} \App\Co : \texttt{Tree}\App\sigma_1 \sim \texttt{Tree}\App\sigma_2$.
On the other hand, if we have a coercion $\texttt{Tree}\App\sigma_1 \sim \texttt{Tree}\App\sigma_1$ then we can recover the coercion components using the \trule{co-left} and \trule{co-right}, for the higher kinded type and its arguments repectively. In full generality, we can state the lifting property formally in \SFC using \pref{thm:sfc-coercion-lifting}.

\begin{theorem}[Coercion Lifting]\label{thm:sfc-coercion-lifting}
  If $\Typing {\TEnv,\alpha\co\kappa'} \phi \kappa$, where $\alpha$ is free in $\phi$
  and does not appear free in $\TEnv$, and
  $\Typing \TEnv \Co {\sigma_1\co\kappa' \sim   \sigma_2\co\kappa'}$
  then, $\Typing \TEnv {\Set{\alpha\mapsto \Co}\refl\phi} {\Set{\alpha\mapsto\sigma_1}\phi \sim \Set{\alpha\mapsto\sigma_2}\phi}$
\end{theorem}
\begin{proof}[Proof Sketch of \pref{thm:sfc-coercion-lifting}]
  Starting with a $\phi$ that is a well kinded type, we have a derivation that $\Typing {\TEnv, \alpha\co\kappa} \phi \kappa$. Then using \trule{co-refl} we obtain $\Typing {\TEnv, \alpha\co\kappa} {\refl\phi} {\phi \sim \phi}$.
\end{proof}

The \trule{co-$\I\forall$} and \trule{co-$\E\forall$} justify coercions between polytypes and their instantations or in other words, if two types are equal, then their instantiations with equal types are also equal. 

\subsubsection{Consistency} we want to make sure that we can never derive anything obviouly wrong such as !Int ~ Bool! in our language.

\subsection{Encoding Language Features}

Armed with the new coercion infrastructure, it is now possible to encode most of the features discussed in \pref{sec:language-features}. \SFC is a conservative extension of \SF, so type classes and algebraic datatypes can be encoded in \SFC as is.

\subsubsection{GADTs}
Each GADT data constructor is elaborated with equality coercions as implicit existential arguments.
For the !App! case in !Lam a! the data constructor will be elaborated as
\begin{code}
  App : FORALL a:* b:*. FORALL co: c ~ (a -> b). Lam c -> Lam a -> Lam b
  Lam : FORALL a:* b:*. FORALL co. c ~ (a -> b). Lam a -> Lam b -> Lam c
\end{code}

\subsubsection{Newtypes}
Newtypes introduce a new coercion axiom in the system. For the generative type !newtype Fun = MkFun (Fun -> Fun)!
the associated coercion axiom will be !CoFun : Fun ~ (Fun -> Fun)!. In general, for any generative type declaration of the form !newtype T $\overline\alpha$ = MkT $\tau$! will be of the form !CoT : T $\overline\alpha$ ~ $\tau$! where $\tau$ may contain $\overline\alpha$ as free type variables.

\subsubsection{Associated Types}
Each instance introduces a new axiom into the type system. For the !Coll c! typeclass the instance !Coll [Int]! introduces the coercion !CoColl : Elem [Int] ~ Int!

\subsubsection{Open Type Functions}
Each type family instance directly translates to axioms. Thus for !Add m n! type function, the two associated instances would introduce the following axioms !CoAddZ : Add Z n ~ n! and !CoAddSmn : Add (S m) n ~ S (Add m n)!

\subsection{Operational Semantics}
We will use call by name semantics as GHC uses lazy evaluation. Adjusting the operational semantics to call by value will not change the analysis in any significant manner.


\subsection{Soundness}
So do the static semantics effectively weed out all the programs that may fail at runtime?
  


\section{\SFR}\label{sec:sfr} % R for roles

Feature of type safe generative types aka newtypes

The problem is mixing parametricity and type level dispatch.

Type families don't mix well with newtypes as type families make a distinction between types
even if they have the same representations.


\begin{figure}[ht]
  \centering
  \begin{syntax}
    \text{Type Vars} &&\alpha,\beta,\gamma \\
    \text{Term Vars} &&x,y          \\
    \text{Kinds}     &&\kappa                  &::= \star \mid \kappa \to \kappa \mid \syntaxhl{\tau \sim \sigma}\\
    \text{Types}     &&\tau,\sigma,\gamma,\nu  &::= \alpha \mid T \mid \syntaxhl{F} \mid \tau \to \tau \mid \Forall {\alpha\co\kappa} \tau\\
    &&                        &\syntaxhl{\mid \sym \Co \mid \trans \nu \Co \mid \Co\At\tau \mid \left \Co \mid \right \Co} \\
    &&                        &\syntaxhl{\mid \leftc \Co \mid \rightc \Co \mid \Cast \Co \Co}\\
    \text{Terms}     &&M,N                     &::= x \mid H \mid \Lam {x\co\tau} M \mid M\App N \mid \TLam{\tau\co\kappa} M \mid M\App \tau
  \end{syntax}
  \caption{Terms and Types of \SFR as an extension of \SFC}
  \label{fig:system-fcr-syntax}
\end{figure}

\begin{figure}[ht]
  \centering
  \begin{gather*}
    \fbox{$\Typing \TEnv M \tau$}
  \end{gather*}
  \caption{Static Semantics of \SFR}
  \label{fig:sfr-typing}
\end{figure}




\section{\SFP}\label{sec:sfp} % P for promotion
We want to promote datatypes to kinds. What does it take?
\begin{figure}[ht]
  \centering
  \begin{syntax}
    \text{Type Vars} &&\alpha,\beta,\gamma \\
    \text{Term Vars} &&x,y          \\
    \text{Kinds}     &&\kappa                  &::= \star \mid \kappa \to \kappa \mid \syntaxhl{\tau \sim \sigma}\\
    \text{Types}     &&\tau,\sigma,\gamma,\nu  &::= \alpha \mid T \mid \syntaxhl{F} \mid \tau \to \tau \mid \Forall {\alpha\co\kappa} \tau\\
    &&                        &\syntaxhl{\mid \sym \Co \mid \trans \nu \Co \mid \Co\At\tau \mid \left \Co \mid \right \Co} \\
    &&                        &\syntaxhl{\mid \leftc \Co \mid \rightc \Co \mid \Cast \Co \Co}\\
    \text{Terms}     &&M,N                     &::= x \mid H \mid \Lam {x\co\tau} M \mid M\App N \mid \TLam{\tau\co\kappa} M \mid M\App \tau
  \end{syntax}
  \caption{Terms and Types of \SFP as an extension of \SFC}
  \label{fig:system-fcp-syntax}
\end{figure}


\begin{figure}[ht]
  \centering
  \begin{gather*}
    \fbox{$\Typing \TEnv M \tau$}
  \end{gather*}
  \caption{Static Semantics of \SFP}
  \label{fig:sfp-typing}
\end{figure}





\section{\SFK}\label{sec:sfk} % K for kind eq
We have type equalities, why not kind equalities?
But we would then have two kinds of equalities: type and kind.
So why not just squish types and kinds together, making it truly impredicative

\begin{figure}[ht]
  \centering
  \begin{syntax}
    \text{Type Vars} &&\alpha,\beta,\gamma \\
    \text{Term Vars} &&x,y          \\
    \text{Kinds}     &&\kappa                  &::= \star \mid \kappa \to \kappa \mid \syntaxhl{\tau \sim \sigma}\\
    \text{Types}     &&\tau,\sigma,\gamma,\nu  &::= \alpha \mid T \mid \syntaxhl{F} \mid \tau \to \tau \mid \Forall {\alpha\co\kappa} \tau\\
    &&                        &\syntaxhl{\mid \sym \Co \mid \trans \nu \Co \mid \Co\At\tau \mid \left \Co \mid \right \Co} \\
    &&                        &\syntaxhl{\mid \leftc \Co \mid \rightc \Co \mid \Cast \Co \Co}\\
    \text{Terms}     &&M,N                     &::= x \mid H \mid \Lam {x\co\tau} M \mid M\App N \mid \TLam{\tau\co\kappa} M \mid M\App \tau
  \end{syntax}
  \caption{Terms and Types of \SFK as an extension of \SFC}
  \label{fig:system-fck-syntax}
\end{figure}


\begin{figure}[ht]
  \centering
  \begin{gather*}
    \fbox{$\Typing \TEnv M \tau$}
  \end{gather*}
  \caption{Static Semantics of \SFK}
  \label{fig:sfk-typing}
\end{figure}


\begin{figure}[ht]
  \centering
  \begin{tabular}[ht]{c | c}
    Parametric Features & Non-parametric Features \\
    \hline
    Modules             & Typeclasses (with Functional Dependencies)\\
    Algebriac Datatypes & Generalized Algebraic Datatypes\\
                        & Type Families (Open, Closed, Associated types)\\
                        & Generative Types (newtypes)
  \end{tabular}
  \caption{Features of Haskell}
  \label{fig:haskell-lang-features}
\end{figure}

\section{Conclusion and Future work}\label{sec:conclusion}
% \begin{figure}[ht]
%   \centering
%   \begin{tabular}[ht]{c | c | c | c | c | c | c}
%     Language & Decidable Type checking & ADTs & GADTs & Open/Closed Type functions & Generative Types & Kind Functions\\
%     \hline
%     \SF  & & & & &\\
%     \SFC & & & & &\\
%     \SFP & & & & &\\
%     \SFK & & & & &\\
%   \end{tabular}
%   \caption{Core languages and their Capabilities}
%   \label{fig:language-features}
% \end{figure}

%%%% Bibliography
\newpage
\bibliography{comp}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% eval: (visual-line-mode 1)
%%% eval: (auto-fill-mode 0)
%%% TeX-master: t
%%% TeX-command-extra-options: "--synctex=1"
%%% End: